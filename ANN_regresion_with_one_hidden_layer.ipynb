{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_regresion_with_one_hidden_layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkwO6zJSMrTAIc+36vtp45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/SimpleNeuralNet/blob/master/ANN_regresion_with_one_hidden_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK3JCgAhHwR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on https://github.com/nageshsinghc4/Artificial-Neural-Network-from-scratch-python/blob/master/ANN_with_one_hidden_layer.py\n",
        "# M. Wolter, May 2020\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores=[]\n",
        "lossV=[]\n",
        "iterV=[]\n",
        "\n",
        "num_passes=200000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z07kAJ7U9Fwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Config:\n",
        "    nn_input_dim = 1  # input layer dimensionality\n",
        "###    nn_output_dim = 2  # output layer dimensionality\n",
        "    nn_output_dim = 1  # output layer dimensionality\n",
        "     # Gradient descent parameters (I picked these by hand)\n",
        "    epsilon = 0.01  # learning rate for gradient descent\n",
        "    reg_lambda = 0.000000001  # regularization strength\n",
        "\n",
        "    num_hidden_nodes = 60\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw8xP_zn9Jj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def generate_data():\n",
        "    np.random.seed(0)\n",
        "    ##X, y = datasets.make_moons(200, noise=0.20)\n",
        "    \n",
        "    X = np.zeros((200,1), dtype=float)\n",
        "    y = np.zeros((200,), dtype=float)\n",
        "    for i in range(0,200):\n",
        "      X[i] = float(i)/25.\n",
        "      y[i] = -np.cos(X[i,0])/5.+np.random.normal(0.,0.1)\n",
        "      \n",
        "      X[i] = X[i]/8.\n",
        "\n",
        "    from sklearn.utils import shuffle\n",
        "    X,  y = shuffle(X,  y, random_state=0)  \n",
        "\n",
        "    #print(X, y)\n",
        "    return X, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lumlMz_k9Ksd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def visualize(X, y, model):\n",
        "\n",
        "  \n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "\n",
        "    plt.title(\"Fit to experimental data\",fontsize=16) \n",
        "    plt.scatter(X,y,s=10)\n",
        "\n",
        "    XX = np.linspace(min(X), max(X), num=50)\n",
        "    plt.plot(XX,predict(model,XX),linewidth=3,color='orange',linestyle='solid', label=\"final fit\")\n",
        "    for k in range(0,len(scores)):\n",
        "       if k % 5000 == 0 or k<4:\n",
        "         plt.scatter(X,scores[k],s=1,label='iter='+str(k*10))\n",
        "         #plt.scatter(X,scores[k],s=1,label='loss='+str(lossV[k]))\n",
        "\n",
        "    #plt.plot(coo,res,c='red',label='dopasowanie')\n",
        "    #plt.plot(coo,exact,c='black',label='dokÅ‚adna funkcja')\n",
        "\n",
        "    plt.legend(prop={'size':14})\n",
        "\n",
        "    plt.xlabel('$x$',fontsize=15)\n",
        "    plt.ylabel('$y$',fontsize=15);\n",
        "\n",
        "    \n",
        "    plt.show()\n",
        "    #plot_decision_boundary(lambda x:predict(model,x), X, y)\n",
        "    #plt.title(\"Logistic Regression\")\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "\n",
        "    plt.title(\"Loss\",fontsize=16) \n",
        "    plt.plot(iterV,lossV, color='green', marker='', linestyle='dashed', linewidth=2, markersize=12)\n",
        "    plt.ylim(0.,2.0*sum(lossV)/len(lossV))\n",
        "\n",
        "    plt.xlabel('$iter$',fontsize=15)\n",
        "    plt.ylabel('$Loss$',fontsize=15);\n",
        "\n",
        "    \n",
        "    plt.show()   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we033mD99MF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_decision_boundary(pred_func, X, y):\n",
        "    # Set min and max values and give it some padding\n",
        "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "    h = 0.01\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    # Predict the function value for the whole gid\n",
        "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # Plot the contour and training examples\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnXU7u9n9M2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Helper function to evaluate the total loss on the dataset\n",
        "def calculate_loss(model, X, y):\n",
        "    num_examples = len(X)  # training set size\n",
        "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
        "    # Forward propagation to calculate our predictions\n",
        "    z1 = X.dot(W1) + b1\n",
        "    a1 = np.tanh(z1)\n",
        "    z2 = a1.dot(W2) + b2\n",
        "    exp_scores = z2 #np.exp(z2)\n",
        "      \n",
        "    scores.append(exp_scores)\n",
        "\n",
        "###    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "    probs = exp_scores \n",
        "   # Calculating the loss\n",
        "###    corect_logprobs = -np.log(probs[range(num_examples), y])\n",
        "###    data_loss = np.sum(corect_logprobs)\n",
        "    chi2 = (probs-y)*(probs-y)\n",
        "    data_loss = np.sum(chi2)\n",
        "\n",
        "    # Add regulatization term to loss (optional)\n",
        "    ###data_loss += Config.reg_lambda / 2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
        "    return 1. / num_examples * data_loss\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv4KSoMG9Nsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict(model, x):\n",
        "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
        "    # Forward propagation\n",
        "    z1 = x.dot(W1) + b1\n",
        "    a1 = np.tanh(z1)\n",
        "    z2 = a1.dot(W2) + b2\n",
        "    exp_scores = z2 #np.exp(z2)\n",
        "    probs = exp_scores #/ np.sum(exp_scores, axis=1, keepdims=True)\n",
        "    #return np.argmax(probs, axis=1)\n",
        "    print(\"exp_scores predict \",exp_scores[0:10,])\n",
        "    return probs\n",
        "\n",
        "\n",
        "# This function learns parameters for the neural network and returns the model.\n",
        "# - nn_hdim: Number of nodes in the hidden layer\n",
        "# - num_passes: Number of passes through the training data for gradient descent\n",
        "# - print_loss: If True, print the loss every 1000 iterations\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L98VbrL09O_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_model(X, y, nn_hdim, num_passes=10000, print_loss=False):\n",
        "    # Initialize the parameters to random values. We need to learn these.\n",
        "    num_examples = len(X)\n",
        "    np.random.seed(0)\n",
        "    W1 = np.random.randn(Config.nn_input_dim, nn_hdim) / np.sqrt(Config.nn_input_dim)\n",
        "    b1 = np.zeros((1, nn_hdim))\n",
        "    W2 = np.random.randn(nn_hdim, Config.nn_output_dim) / np.sqrt(nn_hdim)\n",
        "    b2 = np.zeros((1, Config.nn_output_dim))\n",
        "\n",
        "    # This is what we return at the end\n",
        "    model = {}\n",
        "\n",
        "    # Gradient descent. For each batch...\n",
        "    for i in range(0, num_passes):\n",
        "        batch_len=20\n",
        "        Xb=np.zeros((batch_len,1))\n",
        "        yb=np.zeros((batch_len,))\n",
        "        rr = np.random.randint(0,len(X),batch_len)\n",
        "        for k in range(batch_len):\n",
        "          Xb[k] = X[rr[k]]\n",
        "          yb[k] = y[rr[k]]\n",
        "\n",
        "        # Forward propagation\n",
        "        #print(Xb,W1)\n",
        "        #print(Xb.dot(W1))\n",
        "        z1 = Xb.dot(W1) + b1\n",
        "        a1 = np.tanh(z1)\n",
        "        z2 = a1.dot(W2) + b2\n",
        "        exp_scores = z2 #np.exp(z2)\n",
        "#        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "        probs = exp_scores \n",
        "\n",
        "\n",
        "        #print(\"exp_scores \",exp_scores)\n",
        "        #print(\"y \",yb)\n",
        "        ###print(np.sum(exp_scores, axis=1, keepdims=True))\n",
        "        # Backpropagation\n",
        "        delta3 = probs\n",
        "        for j in range(0,len(yb)):\n",
        "          #print(j)\n",
        "          delta3[j] = -yb[j]+delta3[j]\n",
        "#        delta3[range(num_examples), y] -= 1\n",
        "        #print(\"delta3 \",delta3[0:10,])\n",
        "\n",
        "        dW2 = (a1.T).dot(delta3)\n",
        "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
        "        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
        "        dW1 = np.dot(Xb.T, delta2)\n",
        "        db1 = np.sum(delta2, axis=0)\n",
        "\n",
        "        # Add regularization terms (b1 and b2 don't have regularization terms)\n",
        "        ###MW dW2 += Config.reg_lambda * W2\n",
        "        ###MW dW1 += Config.reg_lambda * W1\n",
        "\n",
        "        # Gradient descent parameter update\n",
        "        #print(\"W1 \",W1.shape)\n",
        "        #print(\"W2 \",W2.shape)\n",
        "        #print(\"W1 \",W1,dW1)\n",
        "        #print(\"W2 \",W2,dW2)\n",
        "        #print('b1 ',b1,db1)\n",
        "        #print('b2 ',b2,db2)\n",
        "        W1 += -Config.epsilon * dW1\n",
        "        b1 += -Config.epsilon * db1\n",
        "        W2 += -Config.epsilon * dW2\n",
        "        b2 += -Config.epsilon * db2\n",
        "\n",
        "        # Assign new parameters to the model\n",
        "        model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
        "\n",
        "        # Optionally print the loss.\n",
        "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
        "        if print_loss and i % 10 == 0:\n",
        "            loss = calculate_loss(model, X, y)\n",
        "            print(\"Loss after iteration %i: %f\" % (i, loss))\n",
        "            lossV.append(loss)\n",
        "            iterV.append(i)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cEh1mjy9QjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def classify(X, y):\n",
        "    # clf = linear_model.LogisticRegressionCV()\n",
        "    # clf.fit(X, y)\n",
        "    # return clf\n",
        "\n",
        "    pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqwqx78n9Rif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c63b9590-de15-41be-b211-43a15e090b3f"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "X, y = generate_data()\n",
        "model = build_model(X, y, Config.num_hidden_nodes,  num_passes, print_loss=True)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Loss after iteration 150010: 9.319753\n",
            "Loss after iteration 150020: 9.552977\n",
            "Loss after iteration 150030: 9.670718\n",
            "Loss after iteration 150040: 9.553589\n",
            "Loss after iteration 150050: 10.115018\n",
            "Loss after iteration 150060: 9.329151\n",
            "Loss after iteration 150070: 9.790316\n",
            "Loss after iteration 150080: 9.682113\n",
            "Loss after iteration 150090: 9.980759\n",
            "Loss after iteration 150100: 9.853672\n",
            "Loss after iteration 150110: 9.335125\n",
            "Loss after iteration 150120: 9.346194\n",
            "Loss after iteration 150130: 9.661355\n",
            "Loss after iteration 150140: 9.631805\n",
            "Loss after iteration 150150: 9.248519\n",
            "Loss after iteration 150160: 9.525438\n",
            "Loss after iteration 150170: 10.093976\n",
            "Loss after iteration 150180: 9.236752\n",
            "Loss after iteration 150190: 9.678302\n",
            "Loss after iteration 150200: 9.385839\n",
            "Loss after iteration 150210: 10.292235\n",
            "Loss after iteration 150220: 9.582055\n",
            "Loss after iteration 150230: 9.189459\n",
            "Loss after iteration 150240: 9.098656\n",
            "Loss after iteration 150250: 9.222195\n",
            "Loss after iteration 150260: 10.232304\n",
            "Loss after iteration 150270: 9.396345\n",
            "Loss after iteration 150280: 9.496815\n",
            "Loss after iteration 150290: 9.479179\n",
            "Loss after iteration 150300: 10.002877\n",
            "Loss after iteration 150310: 9.219205\n",
            "Loss after iteration 150320: 9.562973\n",
            "Loss after iteration 150330: 9.649785\n",
            "Loss after iteration 150340: 9.175644\n",
            "Loss after iteration 150350: 10.010868\n",
            "Loss after iteration 150360: 9.144138\n",
            "Loss after iteration 150370: 10.064245\n",
            "Loss after iteration 150380: 9.332852\n",
            "Loss after iteration 150390: 9.386785\n",
            "Loss after iteration 150400: 9.466053\n",
            "Loss after iteration 150410: 9.290544\n",
            "Loss after iteration 150420: 10.403385\n",
            "Loss after iteration 150430: 9.551909\n",
            "Loss after iteration 150440: 9.158467\n",
            "Loss after iteration 150450: 9.500888\n",
            "Loss after iteration 150460: 9.342165\n",
            "Loss after iteration 150470: 10.057125\n",
            "Loss after iteration 150480: 9.263568\n",
            "Loss after iteration 150490: 9.506661\n",
            "Loss after iteration 150500: 9.994234\n",
            "Loss after iteration 150510: 9.656480\n",
            "Loss after iteration 150520: 9.245742\n",
            "Loss after iteration 150530: 9.693178\n",
            "Loss after iteration 150540: 9.539900\n",
            "Loss after iteration 150550: 9.234502\n",
            "Loss after iteration 150560: 9.288905\n",
            "Loss after iteration 150570: 9.375681\n",
            "Loss after iteration 150580: 9.263380\n",
            "Loss after iteration 150590: 9.861143\n",
            "Loss after iteration 150600: 9.584312\n",
            "Loss after iteration 150610: 9.403069\n",
            "Loss after iteration 150620: 9.649998\n",
            "Loss after iteration 150630: 10.308830\n",
            "Loss after iteration 150640: 9.737798\n",
            "Loss after iteration 150650: 10.397237\n",
            "Loss after iteration 150660: 9.555113\n",
            "Loss after iteration 150670: 9.732756\n",
            "Loss after iteration 150680: 9.961863\n",
            "Loss after iteration 150690: 9.668032\n",
            "Loss after iteration 150700: 9.933631\n",
            "Loss after iteration 150710: 9.527441\n",
            "Loss after iteration 150720: 9.412437\n",
            "Loss after iteration 150730: 9.736662\n",
            "Loss after iteration 150740: 9.663009\n",
            "Loss after iteration 150750: 9.043241\n",
            "Loss after iteration 150760: 9.193758\n",
            "Loss after iteration 150770: 9.419800\n",
            "Loss after iteration 150780: 10.298985\n",
            "Loss after iteration 150790: 9.205221\n",
            "Loss after iteration 150800: 9.299383\n",
            "Loss after iteration 150810: 9.367843\n",
            "Loss after iteration 150820: 10.281834\n",
            "Loss after iteration 150830: 9.616680\n",
            "Loss after iteration 150840: 8.899093\n",
            "Loss after iteration 150850: 8.908229\n",
            "Loss after iteration 150860: 9.570047\n",
            "Loss after iteration 150870: 11.237524\n",
            "Loss after iteration 150880: 9.595503\n",
            "Loss after iteration 150890: 9.738763\n",
            "Loss after iteration 150900: 9.299310\n",
            "Loss after iteration 150910: 9.627105\n",
            "Loss after iteration 150920: 9.798927\n",
            "Loss after iteration 150930: 9.845706\n",
            "Loss after iteration 150940: 10.473160\n",
            "Loss after iteration 150950: 9.176145\n",
            "Loss after iteration 150960: 9.424074\n",
            "Loss after iteration 150970: 10.241305\n",
            "Loss after iteration 150980: 9.239137\n",
            "Loss after iteration 150990: 9.338644\n",
            "Loss after iteration 151000: 9.589369\n",
            "Loss after iteration 151010: 10.039729\n",
            "Loss after iteration 151020: 9.430703\n",
            "Loss after iteration 151030: 9.180624\n",
            "Loss after iteration 151040: 11.084779\n",
            "Loss after iteration 151050: 9.817222\n",
            "Loss after iteration 151060: 9.527845\n",
            "Loss after iteration 151070: 9.776807\n",
            "Loss after iteration 151080: 9.364516\n",
            "Loss after iteration 151090: 9.367041\n",
            "Loss after iteration 151100: 8.913599\n",
            "Loss after iteration 151110: 9.099584\n",
            "Loss after iteration 151120: 8.917481\n",
            "Loss after iteration 151130: 9.262013\n",
            "Loss after iteration 151140: 9.593574\n",
            "Loss after iteration 151150: 9.457344\n",
            "Loss after iteration 151160: 9.066374\n",
            "Loss after iteration 151170: 9.135660\n",
            "Loss after iteration 151180: 9.249557\n",
            "Loss after iteration 151190: 9.778100\n",
            "Loss after iteration 151200: 9.740759\n",
            "Loss after iteration 151210: 9.104417\n",
            "Loss after iteration 151220: 10.152695\n",
            "Loss after iteration 151230: 10.123554\n",
            "Loss after iteration 151240: 9.691364\n",
            "Loss after iteration 151250: 9.674312\n",
            "Loss after iteration 151260: 9.344632\n",
            "Loss after iteration 151270: 9.659506\n",
            "Loss after iteration 151280: 9.177647\n",
            "Loss after iteration 151290: 9.110241\n",
            "Loss after iteration 151300: 9.404647\n",
            "Loss after iteration 151310: 9.704664\n",
            "Loss after iteration 151320: 9.189658\n",
            "Loss after iteration 151330: 9.162949\n",
            "Loss after iteration 151340: 9.248424\n",
            "Loss after iteration 151350: 9.997098\n",
            "Loss after iteration 151360: 9.528561\n",
            "Loss after iteration 151370: 9.397858\n",
            "Loss after iteration 151380: 9.721534\n",
            "Loss after iteration 151390: 10.564655\n",
            "Loss after iteration 151400: 9.445321\n",
            "Loss after iteration 151410: 9.854676\n",
            "Loss after iteration 151420: 9.259980\n",
            "Loss after iteration 151430: 9.406445\n",
            "Loss after iteration 151440: 11.226405\n",
            "Loss after iteration 151450: 9.404543\n",
            "Loss after iteration 151460: 9.123737\n",
            "Loss after iteration 151470: 9.818260\n",
            "Loss after iteration 151480: 9.494204\n",
            "Loss after iteration 151490: 9.754953\n",
            "Loss after iteration 151500: 8.930536\n",
            "Loss after iteration 151510: 9.577780\n",
            "Loss after iteration 151520: 9.276538\n",
            "Loss after iteration 151530: 9.094218\n",
            "Loss after iteration 151540: 9.438595\n",
            "Loss after iteration 151550: 9.310854\n",
            "Loss after iteration 151560: 9.047342\n",
            "Loss after iteration 151570: 9.403544\n",
            "Loss after iteration 151580: 9.447301\n",
            "Loss after iteration 151590: 9.840084\n",
            "Loss after iteration 151600: 9.356317\n",
            "Loss after iteration 151610: 9.831637\n",
            "Loss after iteration 151620: 9.792607\n",
            "Loss after iteration 151630: 9.452765\n",
            "Loss after iteration 151640: 9.425580\n",
            "Loss after iteration 151650: 9.236672\n",
            "Loss after iteration 151660: 9.395392\n",
            "Loss after iteration 151670: 9.538720\n",
            "Loss after iteration 151680: 9.167737\n",
            "Loss after iteration 151690: 9.185732\n",
            "Loss after iteration 151700: 9.404624\n",
            "Loss after iteration 151710: 9.824413\n",
            "Loss after iteration 151720: 9.712723\n",
            "Loss after iteration 151730: 9.237113\n",
            "Loss after iteration 151740: 8.872836\n",
            "Loss after iteration 151750: 9.301137\n",
            "Loss after iteration 151760: 9.314831\n",
            "Loss after iteration 151770: 9.108111\n",
            "Loss after iteration 151780: 9.541398\n",
            "Loss after iteration 151790: 9.511886\n",
            "Loss after iteration 151800: 9.557829\n",
            "Loss after iteration 151810: 9.628195\n",
            "Loss after iteration 151820: 9.706762\n",
            "Loss after iteration 151830: 9.336069\n",
            "Loss after iteration 151840: 9.329824\n",
            "Loss after iteration 151850: 10.115605\n",
            "Loss after iteration 151860: 9.608872\n",
            "Loss after iteration 151870: 9.790959\n",
            "Loss after iteration 151880: 9.770889\n",
            "Loss after iteration 151890: 9.606635\n",
            "Loss after iteration 151900: 10.010784\n",
            "Loss after iteration 151910: 9.654027\n",
            "Loss after iteration 151920: 9.797698\n",
            "Loss after iteration 151930: 9.555099\n",
            "Loss after iteration 151940: 9.505572\n",
            "Loss after iteration 151950: 9.760111\n",
            "Loss after iteration 151960: 9.681467\n",
            "Loss after iteration 151970: 9.827282\n",
            "Loss after iteration 151980: 10.073155\n",
            "Loss after iteration 151990: 9.621746\n",
            "Loss after iteration 152000: 9.426689\n",
            "Loss after iteration 152010: 10.203176\n",
            "Loss after iteration 152020: 9.965831\n",
            "Loss after iteration 152030: 10.513881\n",
            "Loss after iteration 152040: 9.347021\n",
            "Loss after iteration 152050: 10.066420\n",
            "Loss after iteration 152060: 9.802345\n",
            "Loss after iteration 152070: 9.324076\n",
            "Loss after iteration 152080: 9.291509\n",
            "Loss after iteration 152090: 10.183317\n",
            "Loss after iteration 152100: 9.937073\n",
            "Loss after iteration 152110: 9.839685\n",
            "Loss after iteration 152120: 9.684978\n",
            "Loss after iteration 152130: 9.415911\n",
            "Loss after iteration 152140: 9.481023\n",
            "Loss after iteration 152150: 9.554075\n",
            "Loss after iteration 152160: 9.743044\n",
            "Loss after iteration 152170: 9.197303\n",
            "Loss after iteration 152180: 9.588479\n",
            "Loss after iteration 152190: 10.160449\n",
            "Loss after iteration 152200: 9.194643\n",
            "Loss after iteration 152210: 9.601453\n",
            "Loss after iteration 152220: 9.387661\n",
            "Loss after iteration 152230: 9.131526\n",
            "Loss after iteration 152240: 9.836997\n",
            "Loss after iteration 152250: 9.285591\n",
            "Loss after iteration 152260: 9.349242\n",
            "Loss after iteration 152270: 9.801550\n",
            "Loss after iteration 152280: 10.031267\n",
            "Loss after iteration 152290: 10.366878\n",
            "Loss after iteration 152300: 9.864678\n",
            "Loss after iteration 152310: 10.924097\n",
            "Loss after iteration 152320: 9.760900\n",
            "Loss after iteration 152330: 9.819788\n",
            "Loss after iteration 152340: 9.667038\n",
            "Loss after iteration 152350: 9.837137\n",
            "Loss after iteration 152360: 9.504320\n",
            "Loss after iteration 152370: 9.764735\n",
            "Loss after iteration 152380: 9.748315\n",
            "Loss after iteration 152390: 9.208676\n",
            "Loss after iteration 152400: 9.342183\n",
            "Loss after iteration 152410: 9.896112\n",
            "Loss after iteration 152420: 10.537519\n",
            "Loss after iteration 152430: 9.527307\n",
            "Loss after iteration 152440: 9.746832\n",
            "Loss after iteration 152450: 10.742811\n",
            "Loss after iteration 152460: 9.758279\n",
            "Loss after iteration 152470: 9.980928\n",
            "Loss after iteration 152480: 10.491539\n",
            "Loss after iteration 152490: 9.611396\n",
            "Loss after iteration 152500: 9.940107\n",
            "Loss after iteration 152510: 10.058389\n",
            "Loss after iteration 152520: 10.558191\n",
            "Loss after iteration 152530: 9.809909\n",
            "Loss after iteration 152540: 9.569074\n",
            "Loss after iteration 152550: 9.897105\n",
            "Loss after iteration 152560: 10.034201\n",
            "Loss after iteration 152570: 9.425550\n",
            "Loss after iteration 152580: 9.581387\n",
            "Loss after iteration 152590: 9.645544\n",
            "Loss after iteration 152600: 9.598798\n",
            "Loss after iteration 152610: 10.263102\n",
            "Loss after iteration 152620: 9.289190\n",
            "Loss after iteration 152630: 10.265005\n",
            "Loss after iteration 152640: 9.295009\n",
            "Loss after iteration 152650: 9.234986\n",
            "Loss after iteration 152660: 9.774742\n",
            "Loss after iteration 152670: 9.126746\n",
            "Loss after iteration 152680: 9.104446\n",
            "Loss after iteration 152690: 9.677846\n",
            "Loss after iteration 152700: 9.292289\n",
            "Loss after iteration 152710: 9.970380\n",
            "Loss after iteration 152720: 9.190372\n",
            "Loss after iteration 152730: 9.203216\n",
            "Loss after iteration 152740: 9.496758\n",
            "Loss after iteration 152750: 9.835597\n",
            "Loss after iteration 152760: 9.686717\n",
            "Loss after iteration 152770: 9.160268\n",
            "Loss after iteration 152780: 9.038180\n",
            "Loss after iteration 152790: 9.568032\n",
            "Loss after iteration 152800: 9.426337\n",
            "Loss after iteration 152810: 9.615400\n",
            "Loss after iteration 152820: 10.078474\n",
            "Loss after iteration 152830: 9.527275\n",
            "Loss after iteration 152840: 10.064439\n",
            "Loss after iteration 152850: 9.607314\n",
            "Loss after iteration 152860: 10.004935\n",
            "Loss after iteration 152870: 9.750397\n",
            "Loss after iteration 152880: 9.754895\n",
            "Loss after iteration 152890: 10.921924\n",
            "Loss after iteration 152900: 10.287070\n",
            "Loss after iteration 152910: 9.442837\n",
            "Loss after iteration 152920: 9.376565\n",
            "Loss after iteration 152930: 9.614026\n",
            "Loss after iteration 152940: 10.280609\n",
            "Loss after iteration 152950: 9.907042\n",
            "Loss after iteration 152960: 9.297176\n",
            "Loss after iteration 152970: 9.246477\n",
            "Loss after iteration 152980: 9.380852\n",
            "Loss after iteration 152990: 9.349771\n",
            "Loss after iteration 153000: 10.347172\n",
            "Loss after iteration 153010: 10.115501\n",
            "Loss after iteration 153020: 9.059878\n",
            "Loss after iteration 153030: 9.277865\n",
            "Loss after iteration 153040: 10.875497\n",
            "Loss after iteration 153050: 9.280183\n",
            "Loss after iteration 153060: 9.556213\n",
            "Loss after iteration 153070: 9.422561\n",
            "Loss after iteration 153080: 9.676591\n",
            "Loss after iteration 153090: 9.844675\n",
            "Loss after iteration 153100: 10.043842\n",
            "Loss after iteration 153110: 10.256718\n",
            "Loss after iteration 153120: 9.552588\n",
            "Loss after iteration 153130: 9.620155\n",
            "Loss after iteration 153140: 9.560970\n",
            "Loss after iteration 153150: 9.592816\n",
            "Loss after iteration 153160: 9.646586\n",
            "Loss after iteration 153170: 9.601534\n",
            "Loss after iteration 153180: 9.684718\n",
            "Loss after iteration 153190: 9.292983\n",
            "Loss after iteration 153200: 9.218197\n",
            "Loss after iteration 153210: 9.507940\n",
            "Loss after iteration 153220: 9.729611\n",
            "Loss after iteration 153230: 9.589688\n",
            "Loss after iteration 153240: 9.384899\n",
            "Loss after iteration 153250: 9.674252\n",
            "Loss after iteration 153260: 9.312204\n",
            "Loss after iteration 153270: 9.766033\n",
            "Loss after iteration 153280: 9.845765\n",
            "Loss after iteration 153290: 9.975824\n",
            "Loss after iteration 153300: 9.423303\n",
            "Loss after iteration 153310: 9.322766\n",
            "Loss after iteration 153320: 9.866650\n",
            "Loss after iteration 153330: 9.459985\n",
            "Loss after iteration 153340: 9.837715\n",
            "Loss after iteration 153350: 9.222265\n",
            "Loss after iteration 153360: 9.339730\n",
            "Loss after iteration 153370: 9.790614\n",
            "Loss after iteration 153380: 9.950869\n",
            "Loss after iteration 153390: 9.775801\n",
            "Loss after iteration 153400: 9.609069\n",
            "Loss after iteration 153410: 9.626218\n",
            "Loss after iteration 153420: 9.521600\n",
            "Loss after iteration 153430: 9.204262\n",
            "Loss after iteration 153440: 9.562623\n",
            "Loss after iteration 153450: 9.884096\n",
            "Loss after iteration 153460: 9.201615\n",
            "Loss after iteration 153470: 9.276303\n",
            "Loss after iteration 153480: 9.348620\n",
            "Loss after iteration 153490: 9.513710\n",
            "Loss after iteration 153500: 10.168555\n",
            "Loss after iteration 153510: 9.504200\n",
            "Loss after iteration 153520: 8.875616\n",
            "Loss after iteration 153530: 9.397227\n",
            "Loss after iteration 153540: 9.948341\n",
            "Loss after iteration 153550: 9.515787\n",
            "Loss after iteration 153560: 9.129497\n",
            "Loss after iteration 153570: 9.181400\n",
            "Loss after iteration 153580: 9.374337\n",
            "Loss after iteration 153590: 9.906483\n",
            "Loss after iteration 153600: 9.998610\n",
            "Loss after iteration 153610: 9.330569\n",
            "Loss after iteration 153620: 9.469684\n",
            "Loss after iteration 153630: 9.410208\n",
            "Loss after iteration 153640: 9.997238\n",
            "Loss after iteration 153650: 9.931925\n",
            "Loss after iteration 153660: 10.062827\n",
            "Loss after iteration 153670: 9.973570\n",
            "Loss after iteration 153680: 9.186745\n",
            "Loss after iteration 153690: 9.766904\n",
            "Loss after iteration 153700: 9.393355\n",
            "Loss after iteration 153710: 9.435535\n",
            "Loss after iteration 153720: 9.577849\n",
            "Loss after iteration 153730: 9.475276\n",
            "Loss after iteration 153740: 9.619871\n",
            "Loss after iteration 153750: 9.217658\n",
            "Loss after iteration 153760: 9.378064\n",
            "Loss after iteration 153770: 10.326477\n",
            "Loss after iteration 153780: 9.374335\n",
            "Loss after iteration 153790: 9.586286\n",
            "Loss after iteration 153800: 9.335732\n",
            "Loss after iteration 153810: 9.460801\n",
            "Loss after iteration 153820: 10.217689\n",
            "Loss after iteration 153830: 9.610009\n",
            "Loss after iteration 153840: 9.907843\n",
            "Loss after iteration 153850: 9.516435\n",
            "Loss after iteration 153860: 9.621173\n",
            "Loss after iteration 153870: 9.509505\n",
            "Loss after iteration 153880: 9.284237\n",
            "Loss after iteration 153890: 9.447600\n",
            "Loss after iteration 153900: 9.043999\n",
            "Loss after iteration 153910: 9.215319\n",
            "Loss after iteration 153920: 9.285241\n",
            "Loss after iteration 153930: 9.975528\n",
            "Loss after iteration 153940: 9.659117\n",
            "Loss after iteration 153950: 9.429888\n",
            "Loss after iteration 153960: 9.097332\n",
            "Loss after iteration 153970: 9.129578\n",
            "Loss after iteration 153980: 9.542719\n",
            "Loss after iteration 153990: 9.615918\n",
            "Loss after iteration 154000: 9.520362\n",
            "Loss after iteration 154010: 9.432979\n",
            "Loss after iteration 154020: 9.329717\n",
            "Loss after iteration 154030: 9.241916\n",
            "Loss after iteration 154040: 9.879404\n",
            "Loss after iteration 154050: 9.511632\n",
            "Loss after iteration 154060: 9.844401\n",
            "Loss after iteration 154070: 9.252792\n",
            "Loss after iteration 154080: 9.979203\n",
            "Loss after iteration 154090: 10.581438\n",
            "Loss after iteration 154100: 9.668052\n",
            "Loss after iteration 154110: 9.412526\n",
            "Loss after iteration 154120: 9.454644\n",
            "Loss after iteration 154130: 9.329839\n",
            "Loss after iteration 154140: 9.336263\n",
            "Loss after iteration 154150: 9.570615\n",
            "Loss after iteration 154160: 9.308072\n",
            "Loss after iteration 154170: 9.459529\n",
            "Loss after iteration 154180: 9.582676\n",
            "Loss after iteration 154190: 9.215642\n",
            "Loss after iteration 154200: 10.058740\n",
            "Loss after iteration 154210: 9.142020\n",
            "Loss after iteration 154220: 9.282439\n",
            "Loss after iteration 154230: 9.298716\n",
            "Loss after iteration 154240: 9.385260\n",
            "Loss after iteration 154250: 9.745248\n",
            "Loss after iteration 154260: 9.865507\n",
            "Loss after iteration 154270: 10.234757\n",
            "Loss after iteration 154280: 10.369698\n",
            "Loss after iteration 154290: 9.570843\n",
            "Loss after iteration 154300: 9.569390\n",
            "Loss after iteration 154310: 9.692399\n",
            "Loss after iteration 154320: 9.953079\n",
            "Loss after iteration 154330: 9.616242\n",
            "Loss after iteration 154340: 9.495097\n",
            "Loss after iteration 154350: 9.525996\n",
            "Loss after iteration 154360: 9.675756\n",
            "Loss after iteration 154370: 9.583761\n",
            "Loss after iteration 154380: 9.888212\n",
            "Loss after iteration 154390: 9.493176\n",
            "Loss after iteration 154400: 9.598112\n",
            "Loss after iteration 154410: 9.332844\n",
            "Loss after iteration 154420: 9.205660\n",
            "Loss after iteration 154430: 9.380192\n",
            "Loss after iteration 154440: 9.720966\n",
            "Loss after iteration 154450: 9.821135\n",
            "Loss after iteration 154460: 9.392078\n",
            "Loss after iteration 154470: 9.655873\n",
            "Loss after iteration 154480: 9.271778\n",
            "Loss after iteration 154490: 9.345634\n",
            "Loss after iteration 154500: 9.749940\n",
            "Loss after iteration 154510: 9.907683\n",
            "Loss after iteration 154520: 10.128005\n",
            "Loss after iteration 154530: 9.824454\n",
            "Loss after iteration 154540: 9.928964\n",
            "Loss after iteration 154550: 9.644112\n",
            "Loss after iteration 154560: 9.643411\n",
            "Loss after iteration 154570: 10.101169\n",
            "Loss after iteration 154580: 9.677115\n",
            "Loss after iteration 154590: 10.200658\n",
            "Loss after iteration 154600: 10.210994\n",
            "Loss after iteration 154610: 9.249772\n",
            "Loss after iteration 154620: 9.742545\n",
            "Loss after iteration 154630: 9.808190\n",
            "Loss after iteration 154640: 10.249196\n",
            "Loss after iteration 154650: 10.010007\n",
            "Loss after iteration 154660: 10.916613\n",
            "Loss after iteration 154670: 9.464402\n",
            "Loss after iteration 154680: 9.997556\n",
            "Loss after iteration 154690: 9.217728\n",
            "Loss after iteration 154700: 9.566316\n",
            "Loss after iteration 154710: 9.192272\n",
            "Loss after iteration 154720: 9.483763\n",
            "Loss after iteration 154730: 9.790398\n",
            "Loss after iteration 154740: 9.939929\n",
            "Loss after iteration 154750: 9.496556\n",
            "Loss after iteration 154760: 10.730649\n",
            "Loss after iteration 154770: 9.605956\n",
            "Loss after iteration 154780: 9.486035\n",
            "Loss after iteration 154790: 9.420576\n",
            "Loss after iteration 154800: 9.998201\n",
            "Loss after iteration 154810: 11.048251\n",
            "Loss after iteration 154820: 10.082237\n",
            "Loss after iteration 154830: 9.948130\n",
            "Loss after iteration 154840: 9.815011\n",
            "Loss after iteration 154850: 9.831549\n",
            "Loss after iteration 154860: 9.793146\n",
            "Loss after iteration 154870: 9.312513\n",
            "Loss after iteration 154880: 10.106202\n",
            "Loss after iteration 154890: 9.731907\n",
            "Loss after iteration 154900: 9.370679\n",
            "Loss after iteration 154910: 9.451647\n",
            "Loss after iteration 154920: 9.450176\n",
            "Loss after iteration 154930: 10.352922\n",
            "Loss after iteration 154940: 10.523283\n",
            "Loss after iteration 154950: 10.233693\n",
            "Loss after iteration 154960: 10.649730\n",
            "Loss after iteration 154970: 9.589912\n",
            "Loss after iteration 154980: 9.841402\n",
            "Loss after iteration 154990: 10.239396\n",
            "Loss after iteration 155000: 9.656394\n",
            "Loss after iteration 155010: 9.846531\n",
            "Loss after iteration 155020: 9.283072\n",
            "Loss after iteration 155030: 9.689747\n",
            "Loss after iteration 155040: 10.868478\n",
            "Loss after iteration 155050: 9.728171\n",
            "Loss after iteration 155060: 9.466308\n",
            "Loss after iteration 155070: 9.231782\n",
            "Loss after iteration 155080: 9.415641\n",
            "Loss after iteration 155090: 9.717449\n",
            "Loss after iteration 155100: 9.704608\n",
            "Loss after iteration 155110: 10.297693\n",
            "Loss after iteration 155120: 9.296957\n",
            "Loss after iteration 155130: 9.714646\n",
            "Loss after iteration 155140: 9.495973\n",
            "Loss after iteration 155150: 9.184643\n",
            "Loss after iteration 155160: 9.562043\n",
            "Loss after iteration 155170: 9.344668\n",
            "Loss after iteration 155180: 9.509098\n",
            "Loss after iteration 155190: 9.507661\n",
            "Loss after iteration 155200: 10.249350\n",
            "Loss after iteration 155210: 10.150030\n",
            "Loss after iteration 155220: 9.412686\n",
            "Loss after iteration 155230: 10.277671\n",
            "Loss after iteration 155240: 9.594272\n",
            "Loss after iteration 155250: 9.314153\n",
            "Loss after iteration 155260: 9.610996\n",
            "Loss after iteration 155270: 9.742233\n",
            "Loss after iteration 155280: 9.219246\n",
            "Loss after iteration 155290: 9.671109\n",
            "Loss after iteration 155300: 9.556855\n",
            "Loss after iteration 155310: 9.681413\n",
            "Loss after iteration 155320: 9.877250\n",
            "Loss after iteration 155330: 9.611769\n",
            "Loss after iteration 155340: 10.447191\n",
            "Loss after iteration 155350: 9.748477\n",
            "Loss after iteration 155360: 9.319451\n",
            "Loss after iteration 155370: 9.448560\n",
            "Loss after iteration 155380: 9.313948\n",
            "Loss after iteration 155390: 9.444981\n",
            "Loss after iteration 155400: 9.481645\n",
            "Loss after iteration 155410: 9.549833\n",
            "Loss after iteration 155420: 10.396416\n",
            "Loss after iteration 155430: 9.149214\n",
            "Loss after iteration 155440: 9.400490\n",
            "Loss after iteration 155450: 9.105072\n",
            "Loss after iteration 155460: 9.190238\n",
            "Loss after iteration 155470: 9.305350\n",
            "Loss after iteration 155480: 9.560752\n",
            "Loss after iteration 155490: 9.223830\n",
            "Loss after iteration 155500: 9.112246\n",
            "Loss after iteration 155510: 9.665875\n",
            "Loss after iteration 155520: 9.289100\n",
            "Loss after iteration 155530: 9.724843\n",
            "Loss after iteration 155540: 9.464160\n",
            "Loss after iteration 155550: 9.419145\n",
            "Loss after iteration 155560: 9.600024\n",
            "Loss after iteration 155570: 9.668297\n",
            "Loss after iteration 155580: 8.927605\n",
            "Loss after iteration 155590: 9.418244\n",
            "Loss after iteration 155600: 9.904590\n",
            "Loss after iteration 155610: 9.380798\n",
            "Loss after iteration 155620: 9.697104\n",
            "Loss after iteration 155630: 9.635114\n",
            "Loss after iteration 155640: 10.535878\n",
            "Loss after iteration 155650: 9.849499\n",
            "Loss after iteration 155660: 9.876474\n",
            "Loss after iteration 155670: 9.167162\n",
            "Loss after iteration 155680: 9.831350\n",
            "Loss after iteration 155690: 10.290861\n",
            "Loss after iteration 155700: 9.252940\n",
            "Loss after iteration 155710: 9.280425\n",
            "Loss after iteration 155720: 10.087545\n",
            "Loss after iteration 155730: 9.562059\n",
            "Loss after iteration 155740: 9.314468\n",
            "Loss after iteration 155750: 10.700937\n",
            "Loss after iteration 155760: 9.368477\n",
            "Loss after iteration 155770: 9.125365\n",
            "Loss after iteration 155780: 9.514323\n",
            "Loss after iteration 155790: 9.319105\n",
            "Loss after iteration 155800: 10.013179\n",
            "Loss after iteration 155810: 8.979089\n",
            "Loss after iteration 155820: 9.081273\n",
            "Loss after iteration 155830: 9.230048\n",
            "Loss after iteration 155840: 9.489547\n",
            "Loss after iteration 155850: 9.524029\n",
            "Loss after iteration 155860: 9.803306\n",
            "Loss after iteration 155870: 9.660507\n",
            "Loss after iteration 155880: 9.562332\n",
            "Loss after iteration 155890: 9.334243\n",
            "Loss after iteration 155900: 9.418937\n",
            "Loss after iteration 155910: 9.449827\n",
            "Loss after iteration 155920: 9.832097\n",
            "Loss after iteration 155930: 9.415395\n",
            "Loss after iteration 155940: 10.033593\n",
            "Loss after iteration 155950: 9.337898\n",
            "Loss after iteration 155960: 9.403747\n",
            "Loss after iteration 155970: 9.986777\n",
            "Loss after iteration 155980: 9.363464\n",
            "Loss after iteration 155990: 9.617317\n",
            "Loss after iteration 156000: 9.603701\n",
            "Loss after iteration 156010: 9.843681\n",
            "Loss after iteration 156020: 9.729074\n",
            "Loss after iteration 156030: 9.973661\n",
            "Loss after iteration 156040: 9.180086\n",
            "Loss after iteration 156050: 10.767122\n",
            "Loss after iteration 156060: 9.642383\n",
            "Loss after iteration 156070: 9.788436\n",
            "Loss after iteration 156080: 9.521679\n",
            "Loss after iteration 156090: 10.922988\n",
            "Loss after iteration 156100: 9.451412\n",
            "Loss after iteration 156110: 9.615476\n",
            "Loss after iteration 156120: 9.982833\n",
            "Loss after iteration 156130: 9.479035\n",
            "Loss after iteration 156140: 9.285559\n",
            "Loss after iteration 156150: 9.185825\n",
            "Loss after iteration 156160: 9.576396\n",
            "Loss after iteration 156170: 9.401547\n",
            "Loss after iteration 156180: 9.741797\n",
            "Loss after iteration 156190: 9.491542\n",
            "Loss after iteration 156200: 9.354149\n",
            "Loss after iteration 156210: 9.498117\n",
            "Loss after iteration 156220: 9.791440\n",
            "Loss after iteration 156230: 9.997170\n",
            "Loss after iteration 156240: 9.429045\n",
            "Loss after iteration 156250: 10.064360\n",
            "Loss after iteration 156260: 9.955571\n",
            "Loss after iteration 156270: 9.798784\n",
            "Loss after iteration 156280: 9.470335\n",
            "Loss after iteration 156290: 9.109885\n",
            "Loss after iteration 156300: 9.745901\n",
            "Loss after iteration 156310: 9.551460\n",
            "Loss after iteration 156320: 8.972362\n",
            "Loss after iteration 156330: 9.587662\n",
            "Loss after iteration 156340: 10.043697\n",
            "Loss after iteration 156350: 9.407325\n",
            "Loss after iteration 156360: 9.355609\n",
            "Loss after iteration 156370: 9.881783\n",
            "Loss after iteration 156380: 10.454690\n",
            "Loss after iteration 156390: 9.680290\n",
            "Loss after iteration 156400: 9.366084\n",
            "Loss after iteration 156410: 9.874425\n",
            "Loss after iteration 156420: 9.785581\n",
            "Loss after iteration 156430: 9.845094\n",
            "Loss after iteration 156440: 9.626470\n",
            "Loss after iteration 156450: 9.912990\n",
            "Loss after iteration 156460: 9.500075\n",
            "Loss after iteration 156470: 9.460458\n",
            "Loss after iteration 156480: 9.436439\n",
            "Loss after iteration 156490: 9.975802\n",
            "Loss after iteration 156500: 9.495630\n",
            "Loss after iteration 156510: 9.427043\n",
            "Loss after iteration 156520: 10.158904\n",
            "Loss after iteration 156530: 10.539816\n",
            "Loss after iteration 156540: 9.520270\n",
            "Loss after iteration 156550: 9.850055\n",
            "Loss after iteration 156560: 9.352072\n",
            "Loss after iteration 156570: 9.648032\n",
            "Loss after iteration 156580: 9.513267\n",
            "Loss after iteration 156590: 9.496853\n",
            "Loss after iteration 156600: 9.485828\n",
            "Loss after iteration 156610: 9.621095\n",
            "Loss after iteration 156620: 9.678340\n",
            "Loss after iteration 156630: 9.733939\n",
            "Loss after iteration 156640: 10.408776\n",
            "Loss after iteration 156650: 9.472288\n",
            "Loss after iteration 156660: 9.384226\n",
            "Loss after iteration 156670: 9.461593\n",
            "Loss after iteration 156680: 10.146087\n",
            "Loss after iteration 156690: 9.364991\n",
            "Loss after iteration 156700: 10.512610\n",
            "Loss after iteration 156710: 9.528917\n",
            "Loss after iteration 156720: 9.708445\n",
            "Loss after iteration 156730: 9.966724\n",
            "Loss after iteration 156740: 9.424473\n",
            "Loss after iteration 156750: 9.497983\n",
            "Loss after iteration 156760: 9.353171\n",
            "Loss after iteration 156770: 9.871139\n",
            "Loss after iteration 156780: 10.011047\n",
            "Loss after iteration 156790: 10.092574\n",
            "Loss after iteration 156800: 9.205711\n",
            "Loss after iteration 156810: 9.779390\n",
            "Loss after iteration 156820: 9.225637\n",
            "Loss after iteration 156830: 9.569805\n",
            "Loss after iteration 156840: 9.330517\n",
            "Loss after iteration 156850: 9.085446\n",
            "Loss after iteration 156860: 9.332462\n",
            "Loss after iteration 156870: 9.063206\n",
            "Loss after iteration 156880: 9.437669\n",
            "Loss after iteration 156890: 9.428728\n",
            "Loss after iteration 156900: 9.186427\n",
            "Loss after iteration 156910: 9.853344\n",
            "Loss after iteration 156920: 9.494326\n",
            "Loss after iteration 156930: 10.150172\n",
            "Loss after iteration 156940: 9.749574\n",
            "Loss after iteration 156950: 9.528554\n",
            "Loss after iteration 156960: 9.475568\n",
            "Loss after iteration 156970: 9.288056\n",
            "Loss after iteration 156980: 9.204453\n",
            "Loss after iteration 156990: 10.141762\n",
            "Loss after iteration 157000: 9.790514\n",
            "Loss after iteration 157010: 10.186087\n",
            "Loss after iteration 157020: 9.403414\n",
            "Loss after iteration 157030: 9.906797\n",
            "Loss after iteration 157040: 9.755282\n",
            "Loss after iteration 157050: 9.232901\n",
            "Loss after iteration 157060: 9.598979\n",
            "Loss after iteration 157070: 9.945143\n",
            "Loss after iteration 157080: 9.830503\n",
            "Loss after iteration 157090: 9.368775\n",
            "Loss after iteration 157100: 9.227615\n",
            "Loss after iteration 157110: 10.392927\n",
            "Loss after iteration 157120: 9.476320\n",
            "Loss after iteration 157130: 9.772843\n",
            "Loss after iteration 157140: 9.529178\n",
            "Loss after iteration 157150: 10.045635\n",
            "Loss after iteration 157160: 9.513994\n",
            "Loss after iteration 157170: 9.412739\n",
            "Loss after iteration 157180: 9.284485\n",
            "Loss after iteration 157190: 9.594821\n",
            "Loss after iteration 157200: 10.055710\n",
            "Loss after iteration 157210: 9.664858\n",
            "Loss after iteration 157220: 9.323735\n",
            "Loss after iteration 157230: 10.052641\n",
            "Loss after iteration 157240: 9.862187\n",
            "Loss after iteration 157250: 10.032173\n",
            "Loss after iteration 157260: 10.020534\n",
            "Loss after iteration 157270: 9.615025\n",
            "Loss after iteration 157280: 9.606262\n",
            "Loss after iteration 157290: 9.510930\n",
            "Loss after iteration 157300: 9.878198\n",
            "Loss after iteration 157310: 9.829717\n",
            "Loss after iteration 157320: 9.521638\n",
            "Loss after iteration 157330: 9.757110\n",
            "Loss after iteration 157340: 9.667976\n",
            "Loss after iteration 157350: 9.345263\n",
            "Loss after iteration 157360: 9.677360\n",
            "Loss after iteration 157370: 10.170337\n",
            "Loss after iteration 157380: 9.649718\n",
            "Loss after iteration 157390: 9.487863\n",
            "Loss after iteration 157400: 9.597944\n",
            "Loss after iteration 157410: 9.816099\n",
            "Loss after iteration 157420: 9.994125\n",
            "Loss after iteration 157430: 10.057110\n",
            "Loss after iteration 157440: 10.250618\n",
            "Loss after iteration 157450: 10.032066\n",
            "Loss after iteration 157460: 9.252045\n",
            "Loss after iteration 157470: 9.549295\n",
            "Loss after iteration 157480: 9.533800\n",
            "Loss after iteration 157490: 9.543199\n",
            "Loss after iteration 157500: 9.193684\n",
            "Loss after iteration 157510: 10.067232\n",
            "Loss after iteration 157520: 9.343103\n",
            "Loss after iteration 157530: 9.903687\n",
            "Loss after iteration 157540: 9.326936\n",
            "Loss after iteration 157550: 10.085379\n",
            "Loss after iteration 157560: 10.061277\n",
            "Loss after iteration 157570: 10.260025\n",
            "Loss after iteration 157580: 9.682087\n",
            "Loss after iteration 157590: 9.602811\n",
            "Loss after iteration 157600: 9.595190\n",
            "Loss after iteration 157610: 10.031210\n",
            "Loss after iteration 157620: 9.209635\n",
            "Loss after iteration 157630: 9.558300\n",
            "Loss after iteration 157640: 9.619023\n",
            "Loss after iteration 157650: 9.659948\n",
            "Loss after iteration 157660: 9.319561\n",
            "Loss after iteration 157670: 9.265602\n",
            "Loss after iteration 157680: 9.611689\n",
            "Loss after iteration 157690: 9.960566\n",
            "Loss after iteration 157700: 10.080263\n",
            "Loss after iteration 157710: 9.768382\n",
            "Loss after iteration 157720: 9.565862\n",
            "Loss after iteration 157730: 9.422956\n",
            "Loss after iteration 157740: 9.303638\n",
            "Loss after iteration 157750: 9.555467\n",
            "Loss after iteration 157760: 9.381651\n",
            "Loss after iteration 157770: 9.755983\n",
            "Loss after iteration 157780: 9.415370\n",
            "Loss after iteration 157790: 9.588028\n",
            "Loss after iteration 157800: 9.570186\n",
            "Loss after iteration 157810: 10.767564\n",
            "Loss after iteration 157820: 9.967592\n",
            "Loss after iteration 157830: 9.752189\n",
            "Loss after iteration 157840: 9.132318\n",
            "Loss after iteration 157850: 9.247358\n",
            "Loss after iteration 157860: 10.608858\n",
            "Loss after iteration 157870: 9.864141\n",
            "Loss after iteration 157880: 9.303373\n",
            "Loss after iteration 157890: 9.251075\n",
            "Loss after iteration 157900: 9.274917\n",
            "Loss after iteration 157910: 9.095053\n",
            "Loss after iteration 157920: 10.244423\n",
            "Loss after iteration 157930: 9.029536\n",
            "Loss after iteration 157940: 9.682758\n",
            "Loss after iteration 157950: 9.374722\n",
            "Loss after iteration 157960: 10.251088\n",
            "Loss after iteration 157970: 10.111379\n",
            "Loss after iteration 157980: 10.259914\n",
            "Loss after iteration 157990: 10.193901\n",
            "Loss after iteration 158000: 10.136734\n",
            "Loss after iteration 158010: 9.477654\n",
            "Loss after iteration 158020: 9.291603\n",
            "Loss after iteration 158030: 9.898793\n",
            "Loss after iteration 158040: 9.633920\n",
            "Loss after iteration 158050: 9.563289\n",
            "Loss after iteration 158060: 9.527079\n",
            "Loss after iteration 158070: 10.044859\n",
            "Loss after iteration 158080: 10.653689\n",
            "Loss after iteration 158090: 9.519699\n",
            "Loss after iteration 158100: 9.652018\n",
            "Loss after iteration 158110: 9.548341\n",
            "Loss after iteration 158120: 9.663964\n",
            "Loss after iteration 158130: 9.773244\n",
            "Loss after iteration 158140: 9.922513\n",
            "Loss after iteration 158150: 9.737131\n",
            "Loss after iteration 158160: 9.928890\n",
            "Loss after iteration 158170: 9.564731\n",
            "Loss after iteration 158180: 9.754695\n",
            "Loss after iteration 158190: 9.541801\n",
            "Loss after iteration 158200: 9.577935\n",
            "Loss after iteration 158210: 9.642385\n",
            "Loss after iteration 158220: 9.799060\n",
            "Loss after iteration 158230: 9.593686\n",
            "Loss after iteration 158240: 10.011298\n",
            "Loss after iteration 158250: 9.731342\n",
            "Loss after iteration 158260: 9.778189\n",
            "Loss after iteration 158270: 10.154716\n",
            "Loss after iteration 158280: 9.287909\n",
            "Loss after iteration 158290: 9.960552\n",
            "Loss after iteration 158300: 9.167969\n",
            "Loss after iteration 158310: 9.547578\n",
            "Loss after iteration 158320: 9.323624\n",
            "Loss after iteration 158330: 10.385237\n",
            "Loss after iteration 158340: 9.739991\n",
            "Loss after iteration 158350: 10.610124\n",
            "Loss after iteration 158360: 9.773494\n",
            "Loss after iteration 158370: 9.149205\n",
            "Loss after iteration 158380: 9.251146\n",
            "Loss after iteration 158390: 9.238250\n",
            "Loss after iteration 158400: 9.555241\n",
            "Loss after iteration 158410: 9.581773\n",
            "Loss after iteration 158420: 9.945585\n",
            "Loss after iteration 158430: 9.180151\n",
            "Loss after iteration 158440: 9.169498\n",
            "Loss after iteration 158450: 10.094375\n",
            "Loss after iteration 158460: 9.457925\n",
            "Loss after iteration 158470: 9.850409\n",
            "Loss after iteration 158480: 9.601965\n",
            "Loss after iteration 158490: 9.392826\n",
            "Loss after iteration 158500: 9.877002\n",
            "Loss after iteration 158510: 9.428124\n",
            "Loss after iteration 158520: 9.068512\n",
            "Loss after iteration 158530: 9.449888\n",
            "Loss after iteration 158540: 9.722639\n",
            "Loss after iteration 158550: 10.285142\n",
            "Loss after iteration 158560: 9.239887\n",
            "Loss after iteration 158570: 9.714614\n",
            "Loss after iteration 158580: 9.519682\n",
            "Loss after iteration 158590: 9.381161\n",
            "Loss after iteration 158600: 9.198681\n",
            "Loss after iteration 158610: 9.619560\n",
            "Loss after iteration 158620: 9.554891\n",
            "Loss after iteration 158630: 9.543581\n",
            "Loss after iteration 158640: 9.301455\n",
            "Loss after iteration 158650: 9.919883\n",
            "Loss after iteration 158660: 9.913732\n",
            "Loss after iteration 158670: 9.421872\n",
            "Loss after iteration 158680: 9.474373\n",
            "Loss after iteration 158690: 9.630694\n",
            "Loss after iteration 158700: 9.464025\n",
            "Loss after iteration 158710: 10.586685\n",
            "Loss after iteration 158720: 9.694588\n",
            "Loss after iteration 158730: 9.687857\n",
            "Loss after iteration 158740: 9.968538\n",
            "Loss after iteration 158750: 9.756843\n",
            "Loss after iteration 158760: 9.752870\n",
            "Loss after iteration 158770: 10.516102\n",
            "Loss after iteration 158780: 9.492631\n",
            "Loss after iteration 158790: 9.933134\n",
            "Loss after iteration 158800: 10.184182\n",
            "Loss after iteration 158810: 9.357987\n",
            "Loss after iteration 158820: 9.546898\n",
            "Loss after iteration 158830: 9.260084\n",
            "Loss after iteration 158840: 9.561735\n",
            "Loss after iteration 158850: 9.866491\n",
            "Loss after iteration 158860: 9.419996\n",
            "Loss after iteration 158870: 9.588325\n",
            "Loss after iteration 158880: 9.009647\n",
            "Loss after iteration 158890: 9.294962\n",
            "Loss after iteration 158900: 10.619346\n",
            "Loss after iteration 158910: 9.506480\n",
            "Loss after iteration 158920: 9.419165\n",
            "Loss after iteration 158930: 10.413901\n",
            "Loss after iteration 158940: 9.387929\n",
            "Loss after iteration 158950: 9.503879\n",
            "Loss after iteration 158960: 9.813533\n",
            "Loss after iteration 158970: 9.264869\n",
            "Loss after iteration 158980: 9.935166\n",
            "Loss after iteration 158990: 9.430959\n",
            "Loss after iteration 159000: 9.465027\n",
            "Loss after iteration 159010: 9.856513\n",
            "Loss after iteration 159020: 9.372515\n",
            "Loss after iteration 159030: 9.350669\n",
            "Loss after iteration 159040: 9.734707\n",
            "Loss after iteration 159050: 9.425039\n",
            "Loss after iteration 159060: 9.534153\n",
            "Loss after iteration 159070: 9.789337\n",
            "Loss after iteration 159080: 9.512422\n",
            "Loss after iteration 159090: 9.745878\n",
            "Loss after iteration 159100: 9.315725\n",
            "Loss after iteration 159110: 10.099207\n",
            "Loss after iteration 159120: 9.338831\n",
            "Loss after iteration 159130: 9.414307\n",
            "Loss after iteration 159140: 9.198981\n",
            "Loss after iteration 159150: 9.632255\n",
            "Loss after iteration 159160: 9.695040\n",
            "Loss after iteration 159170: 9.269373\n",
            "Loss after iteration 159180: 9.396808\n",
            "Loss after iteration 159190: 9.299497\n",
            "Loss after iteration 159200: 9.124342\n",
            "Loss after iteration 159210: 10.026984\n",
            "Loss after iteration 159220: 9.811578\n",
            "Loss after iteration 159230: 9.556716\n",
            "Loss after iteration 159240: 9.673109\n",
            "Loss after iteration 159250: 9.171238\n",
            "Loss after iteration 159260: 9.252547\n",
            "Loss after iteration 159270: 9.966380\n",
            "Loss after iteration 159280: 9.292618\n",
            "Loss after iteration 159290: 9.730432\n",
            "Loss after iteration 159300: 9.540080\n",
            "Loss after iteration 159310: 9.584369\n",
            "Loss after iteration 159320: 9.547242\n",
            "Loss after iteration 159330: 9.392431\n",
            "Loss after iteration 159340: 9.906572\n",
            "Loss after iteration 159350: 10.352952\n",
            "Loss after iteration 159360: 10.254948\n",
            "Loss after iteration 159370: 9.486337\n",
            "Loss after iteration 159380: 9.654403\n",
            "Loss after iteration 159390: 10.081805\n",
            "Loss after iteration 159400: 10.022747\n",
            "Loss after iteration 159410: 9.922688\n",
            "Loss after iteration 159420: 10.252863\n",
            "Loss after iteration 159430: 10.129012\n",
            "Loss after iteration 159440: 10.107339\n",
            "Loss after iteration 159450: 10.080450\n",
            "Loss after iteration 159460: 9.929537\n",
            "Loss after iteration 159470: 9.835134\n",
            "Loss after iteration 159480: 9.454606\n",
            "Loss after iteration 159490: 9.923028\n",
            "Loss after iteration 159500: 9.823510\n",
            "Loss after iteration 159510: 9.630816\n",
            "Loss after iteration 159520: 9.579606\n",
            "Loss after iteration 159530: 9.628096\n",
            "Loss after iteration 159540: 9.925233\n",
            "Loss after iteration 159550: 10.113894\n",
            "Loss after iteration 159560: 9.392118\n",
            "Loss after iteration 159570: 9.441208\n",
            "Loss after iteration 159580: 9.887393\n",
            "Loss after iteration 159590: 9.564741\n",
            "Loss after iteration 159600: 9.694466\n",
            "Loss after iteration 159610: 9.719994\n",
            "Loss after iteration 159620: 10.225807\n",
            "Loss after iteration 159630: 9.445052\n",
            "Loss after iteration 159640: 9.906122\n",
            "Loss after iteration 159650: 9.227407\n",
            "Loss after iteration 159660: 9.458876\n",
            "Loss after iteration 159670: 10.389139\n",
            "Loss after iteration 159680: 9.622406\n",
            "Loss after iteration 159690: 9.167283\n",
            "Loss after iteration 159700: 10.957667\n",
            "Loss after iteration 159710: 9.670461\n",
            "Loss after iteration 159720: 9.143291\n",
            "Loss after iteration 159730: 9.071087\n",
            "Loss after iteration 159740: 10.310789\n",
            "Loss after iteration 159750: 9.318834\n",
            "Loss after iteration 159760: 9.179478\n",
            "Loss after iteration 159770: 9.258895\n",
            "Loss after iteration 159780: 10.008772\n",
            "Loss after iteration 159790: 10.030505\n",
            "Loss after iteration 159800: 9.406080\n",
            "Loss after iteration 159810: 9.429410\n",
            "Loss after iteration 159820: 9.150734\n",
            "Loss after iteration 159830: 9.350263\n",
            "Loss after iteration 159840: 9.635507\n",
            "Loss after iteration 159850: 9.087518\n",
            "Loss after iteration 159860: 9.273767\n",
            "Loss after iteration 159870: 9.463252\n",
            "Loss after iteration 159880: 10.032289\n",
            "Loss after iteration 159890: 9.559309\n",
            "Loss after iteration 159900: 9.672388\n",
            "Loss after iteration 159910: 10.455536\n",
            "Loss after iteration 159920: 9.656666\n",
            "Loss after iteration 159930: 9.472292\n",
            "Loss after iteration 159940: 10.494894\n",
            "Loss after iteration 159950: 9.338254\n",
            "Loss after iteration 159960: 10.095584\n",
            "Loss after iteration 159970: 10.171910\n",
            "Loss after iteration 159980: 9.858177\n",
            "Loss after iteration 159990: 10.059901\n",
            "Loss after iteration 160000: 9.608072\n",
            "Loss after iteration 160010: 9.798659\n",
            "Loss after iteration 160020: 9.134042\n",
            "Loss after iteration 160030: 10.241084\n",
            "Loss after iteration 160040: 9.598666\n",
            "Loss after iteration 160050: 10.773286\n",
            "Loss after iteration 160060: 9.220574\n",
            "Loss after iteration 160070: 9.549266\n",
            "Loss after iteration 160080: 9.506225\n",
            "Loss after iteration 160090: 9.169934\n",
            "Loss after iteration 160100: 10.022120\n",
            "Loss after iteration 160110: 10.085193\n",
            "Loss after iteration 160120: 9.278405\n",
            "Loss after iteration 160130: 9.719196\n",
            "Loss after iteration 160140: 9.610450\n",
            "Loss after iteration 160150: 9.532607\n",
            "Loss after iteration 160160: 9.812626\n",
            "Loss after iteration 160170: 9.456208\n",
            "Loss after iteration 160180: 9.628509\n",
            "Loss after iteration 160190: 9.089573\n",
            "Loss after iteration 160200: 9.572304\n",
            "Loss after iteration 160210: 9.594120\n",
            "Loss after iteration 160220: 9.149608\n",
            "Loss after iteration 160230: 9.628744\n",
            "Loss after iteration 160240: 9.594613\n",
            "Loss after iteration 160250: 9.327733\n",
            "Loss after iteration 160260: 9.367331\n",
            "Loss after iteration 160270: 9.352925\n",
            "Loss after iteration 160280: 9.215645\n",
            "Loss after iteration 160290: 9.297329\n",
            "Loss after iteration 160300: 9.165864\n",
            "Loss after iteration 160310: 9.791766\n",
            "Loss after iteration 160320: 9.992851\n",
            "Loss after iteration 160330: 9.407255\n",
            "Loss after iteration 160340: 9.654407\n",
            "Loss after iteration 160350: 9.291918\n",
            "Loss after iteration 160360: 9.216465\n",
            "Loss after iteration 160370: 9.251488\n",
            "Loss after iteration 160380: 9.423596\n",
            "Loss after iteration 160390: 10.333376\n",
            "Loss after iteration 160400: 9.156079\n",
            "Loss after iteration 160410: 9.158404\n",
            "Loss after iteration 160420: 9.885917\n",
            "Loss after iteration 160430: 10.172057\n",
            "Loss after iteration 160440: 9.461899\n",
            "Loss after iteration 160450: 9.941748\n",
            "Loss after iteration 160460: 9.429220\n",
            "Loss after iteration 160470: 9.721985\n",
            "Loss after iteration 160480: 9.406271\n",
            "Loss after iteration 160490: 9.843245\n",
            "Loss after iteration 160500: 9.652845\n",
            "Loss after iteration 160510: 9.763353\n",
            "Loss after iteration 160520: 9.904728\n",
            "Loss after iteration 160530: 10.930480\n",
            "Loss after iteration 160540: 9.831276\n",
            "Loss after iteration 160550: 8.987657\n",
            "Loss after iteration 160560: 9.818914\n",
            "Loss after iteration 160570: 9.364159\n",
            "Loss after iteration 160580: 9.767772\n",
            "Loss after iteration 160590: 9.361545\n",
            "Loss after iteration 160600: 10.220654\n",
            "Loss after iteration 160610: 9.335445\n",
            "Loss after iteration 160620: 10.033399\n",
            "Loss after iteration 160630: 11.866139\n",
            "Loss after iteration 160640: 9.399051\n",
            "Loss after iteration 160650: 9.536810\n",
            "Loss after iteration 160660: 10.137239\n",
            "Loss after iteration 160670: 9.450407\n",
            "Loss after iteration 160680: 9.144389\n",
            "Loss after iteration 160690: 9.448765\n",
            "Loss after iteration 160700: 9.478364\n",
            "Loss after iteration 160710: 9.352886\n",
            "Loss after iteration 160720: 9.497565\n",
            "Loss after iteration 160730: 9.368628\n",
            "Loss after iteration 160740: 9.904747\n",
            "Loss after iteration 160750: 10.496202\n",
            "Loss after iteration 160760: 10.373467\n",
            "Loss after iteration 160770: 10.258295\n",
            "Loss after iteration 160780: 9.318348\n",
            "Loss after iteration 160790: 10.561894\n",
            "Loss after iteration 160800: 9.831778\n",
            "Loss after iteration 160810: 9.919542\n",
            "Loss after iteration 160820: 10.446222\n",
            "Loss after iteration 160830: 9.440762\n",
            "Loss after iteration 160840: 9.593361\n",
            "Loss after iteration 160850: 9.999774\n",
            "Loss after iteration 160860: 9.484960\n",
            "Loss after iteration 160870: 9.486933\n",
            "Loss after iteration 160880: 9.400976\n",
            "Loss after iteration 160890: 9.872983\n",
            "Loss after iteration 160900: 10.113523\n",
            "Loss after iteration 160910: 9.499774\n",
            "Loss after iteration 160920: 9.500287\n",
            "Loss after iteration 160930: 9.340374\n",
            "Loss after iteration 160940: 9.746729\n",
            "Loss after iteration 160950: 9.385038\n",
            "Loss after iteration 160960: 9.725420\n",
            "Loss after iteration 160970: 9.731571\n",
            "Loss after iteration 160980: 9.611145\n",
            "Loss after iteration 160990: 11.247649\n",
            "Loss after iteration 161000: 10.317690\n",
            "Loss after iteration 161010: 9.676378\n",
            "Loss after iteration 161020: 9.534659\n",
            "Loss after iteration 161030: 10.004401\n",
            "Loss after iteration 161040: 9.543520\n",
            "Loss after iteration 161050: 9.358754\n",
            "Loss after iteration 161060: 9.601905\n",
            "Loss after iteration 161070: 9.344139\n",
            "Loss after iteration 161080: 9.581231\n",
            "Loss after iteration 161090: 9.754558\n",
            "Loss after iteration 161100: 9.239227\n",
            "Loss after iteration 161110: 9.239689\n",
            "Loss after iteration 161120: 9.627232\n",
            "Loss after iteration 161130: 9.768659\n",
            "Loss after iteration 161140: 9.724192\n",
            "Loss after iteration 161150: 10.225328\n",
            "Loss after iteration 161160: 9.629956\n",
            "Loss after iteration 161170: 9.721967\n",
            "Loss after iteration 161180: 9.839234\n",
            "Loss after iteration 161190: 9.820326\n",
            "Loss after iteration 161200: 9.504100\n",
            "Loss after iteration 161210: 9.285529\n",
            "Loss after iteration 161220: 10.109577\n",
            "Loss after iteration 161230: 10.092401\n",
            "Loss after iteration 161240: 9.789660\n",
            "Loss after iteration 161250: 9.326640\n",
            "Loss after iteration 161260: 9.451908\n",
            "Loss after iteration 161270: 9.255368\n",
            "Loss after iteration 161280: 9.743801\n",
            "Loss after iteration 161290: 9.178478\n",
            "Loss after iteration 161300: 10.131283\n",
            "Loss after iteration 161310: 9.846830\n",
            "Loss after iteration 161320: 9.494067\n",
            "Loss after iteration 161330: 9.312622\n",
            "Loss after iteration 161340: 9.440207\n",
            "Loss after iteration 161350: 9.807556\n",
            "Loss after iteration 161360: 9.785119\n",
            "Loss after iteration 161370: 10.154601\n",
            "Loss after iteration 161380: 9.720698\n",
            "Loss after iteration 161390: 9.639664\n",
            "Loss after iteration 161400: 9.913800\n",
            "Loss after iteration 161410: 9.502492\n",
            "Loss after iteration 161420: 9.453910\n",
            "Loss after iteration 161430: 9.932569\n",
            "Loss after iteration 161440: 9.396341\n",
            "Loss after iteration 161450: 9.684602\n",
            "Loss after iteration 161460: 10.253576\n",
            "Loss after iteration 161470: 9.559867\n",
            "Loss after iteration 161480: 9.447780\n",
            "Loss after iteration 161490: 9.984594\n",
            "Loss after iteration 161500: 9.817561\n",
            "Loss after iteration 161510: 9.509318\n",
            "Loss after iteration 161520: 10.384132\n",
            "Loss after iteration 161530: 9.471043\n",
            "Loss after iteration 161540: 9.824099\n",
            "Loss after iteration 161550: 9.239316\n",
            "Loss after iteration 161560: 9.523754\n",
            "Loss after iteration 161570: 9.386996\n",
            "Loss after iteration 161580: 9.627337\n",
            "Loss after iteration 161590: 9.691810\n",
            "Loss after iteration 161600: 9.450302\n",
            "Loss after iteration 161610: 9.745175\n",
            "Loss after iteration 161620: 10.508034\n",
            "Loss after iteration 161630: 11.495705\n",
            "Loss after iteration 161640: 9.700661\n",
            "Loss after iteration 161650: 9.691798\n",
            "Loss after iteration 161660: 9.419894\n",
            "Loss after iteration 161670: 9.523556\n",
            "Loss after iteration 161680: 9.597590\n",
            "Loss after iteration 161690: 9.720072\n",
            "Loss after iteration 161700: 9.580617\n",
            "Loss after iteration 161710: 9.085248\n",
            "Loss after iteration 161720: 9.762523\n",
            "Loss after iteration 161730: 9.445055\n",
            "Loss after iteration 161740: 9.609569\n",
            "Loss after iteration 161750: 9.708458\n",
            "Loss after iteration 161760: 9.823601\n",
            "Loss after iteration 161770: 9.975965\n",
            "Loss after iteration 161780: 10.002188\n",
            "Loss after iteration 161790: 9.572756\n",
            "Loss after iteration 161800: 9.751482\n",
            "Loss after iteration 161810: 9.396275\n",
            "Loss after iteration 161820: 10.176503\n",
            "Loss after iteration 161830: 10.472993\n",
            "Loss after iteration 161840: 10.298636\n",
            "Loss after iteration 161850: 10.457722\n",
            "Loss after iteration 161860: 10.529838\n",
            "Loss after iteration 161870: 10.050201\n",
            "Loss after iteration 161880: 9.809442\n",
            "Loss after iteration 161890: 9.855489\n",
            "Loss after iteration 161900: 9.969317\n",
            "Loss after iteration 161910: 10.143410\n",
            "Loss after iteration 161920: 9.967112\n",
            "Loss after iteration 161930: 10.148293\n",
            "Loss after iteration 161940: 10.038057\n",
            "Loss after iteration 161950: 9.612276\n",
            "Loss after iteration 161960: 10.234943\n",
            "Loss after iteration 161970: 9.711880\n",
            "Loss after iteration 161980: 9.493080\n",
            "Loss after iteration 161990: 9.410339\n",
            "Loss after iteration 162000: 9.247343\n",
            "Loss after iteration 162010: 9.731824\n",
            "Loss after iteration 162020: 9.599137\n",
            "Loss after iteration 162030: 9.699562\n",
            "Loss after iteration 162040: 10.230736\n",
            "Loss after iteration 162050: 9.725014\n",
            "Loss after iteration 162060: 9.892431\n",
            "Loss after iteration 162070: 9.630867\n",
            "Loss after iteration 162080: 9.908057\n",
            "Loss after iteration 162090: 10.939225\n",
            "Loss after iteration 162100: 10.188444\n",
            "Loss after iteration 162110: 9.738908\n",
            "Loss after iteration 162120: 9.492604\n",
            "Loss after iteration 162130: 9.809103\n",
            "Loss after iteration 162140: 9.464336\n",
            "Loss after iteration 162150: 9.661542\n",
            "Loss after iteration 162160: 9.558631\n",
            "Loss after iteration 162170: 9.525927\n",
            "Loss after iteration 162180: 8.984342\n",
            "Loss after iteration 162190: 9.116327\n",
            "Loss after iteration 162200: 9.304188\n",
            "Loss after iteration 162210: 10.376685\n",
            "Loss after iteration 162220: 9.441775\n",
            "Loss after iteration 162230: 9.924273\n",
            "Loss after iteration 162240: 9.585809\n",
            "Loss after iteration 162250: 9.962995\n",
            "Loss after iteration 162260: 9.715757\n",
            "Loss after iteration 162270: 10.072072\n",
            "Loss after iteration 162280: 9.648504\n",
            "Loss after iteration 162290: 9.667121\n",
            "Loss after iteration 162300: 10.881474\n",
            "Loss after iteration 162310: 10.011471\n",
            "Loss after iteration 162320: 9.882002\n",
            "Loss after iteration 162330: 9.658814\n",
            "Loss after iteration 162340: 9.793400\n",
            "Loss after iteration 162350: 9.936068\n",
            "Loss after iteration 162360: 9.670800\n",
            "Loss after iteration 162370: 9.425727\n",
            "Loss after iteration 162380: 9.809499\n",
            "Loss after iteration 162390: 9.558865\n",
            "Loss after iteration 162400: 9.715023\n",
            "Loss after iteration 162410: 10.798881\n",
            "Loss after iteration 162420: 9.883687\n",
            "Loss after iteration 162430: 9.430844\n",
            "Loss after iteration 162440: 9.330375\n",
            "Loss after iteration 162450: 9.776539\n",
            "Loss after iteration 162460: 9.609782\n",
            "Loss after iteration 162470: 9.875469\n",
            "Loss after iteration 162480: 9.410483\n",
            "Loss after iteration 162490: 10.011509\n",
            "Loss after iteration 162500: 9.588838\n",
            "Loss after iteration 162510: 9.949581\n",
            "Loss after iteration 162520: 9.730517\n",
            "Loss after iteration 162530: 9.354375\n",
            "Loss after iteration 162540: 9.818142\n",
            "Loss after iteration 162550: 9.909057\n",
            "Loss after iteration 162560: 9.675231\n",
            "Loss after iteration 162570: 9.548542\n",
            "Loss after iteration 162580: 9.605678\n",
            "Loss after iteration 162590: 10.050189\n",
            "Loss after iteration 162600: 9.518830\n",
            "Loss after iteration 162610: 10.152156\n",
            "Loss after iteration 162620: 10.328876\n",
            "Loss after iteration 162630: 9.532349\n",
            "Loss after iteration 162640: 9.904955\n",
            "Loss after iteration 162650: 9.814808\n",
            "Loss after iteration 162660: 9.672364\n",
            "Loss after iteration 162670: 9.723162\n",
            "Loss after iteration 162680: 9.691283\n",
            "Loss after iteration 162690: 9.354888\n",
            "Loss after iteration 162700: 10.100874\n",
            "Loss after iteration 162710: 9.318315\n",
            "Loss after iteration 162720: 9.595787\n",
            "Loss after iteration 162730: 10.047108\n",
            "Loss after iteration 162740: 9.665806\n",
            "Loss after iteration 162750: 9.321774\n",
            "Loss after iteration 162760: 10.103388\n",
            "Loss after iteration 162770: 9.647941\n",
            "Loss after iteration 162780: 9.477902\n",
            "Loss after iteration 162790: 9.962165\n",
            "Loss after iteration 162800: 9.106901\n",
            "Loss after iteration 162810: 9.320982\n",
            "Loss after iteration 162820: 9.675127\n",
            "Loss after iteration 162830: 9.580636\n",
            "Loss after iteration 162840: 9.728165\n",
            "Loss after iteration 162850: 9.975298\n",
            "Loss after iteration 162860: 9.890502\n",
            "Loss after iteration 162870: 9.450942\n",
            "Loss after iteration 162880: 9.411939\n",
            "Loss after iteration 162890: 9.557554\n",
            "Loss after iteration 162900: 9.594835\n",
            "Loss after iteration 162910: 10.123266\n",
            "Loss after iteration 162920: 9.511746\n",
            "Loss after iteration 162930: 9.314683\n",
            "Loss after iteration 162940: 10.054026\n",
            "Loss after iteration 162950: 9.548056\n",
            "Loss after iteration 162960: 9.414901\n",
            "Loss after iteration 162970: 9.748735\n",
            "Loss after iteration 162980: 9.849906\n",
            "Loss after iteration 162990: 9.386759\n",
            "Loss after iteration 163000: 10.101595\n",
            "Loss after iteration 163010: 9.716065\n",
            "Loss after iteration 163020: 9.480331\n",
            "Loss after iteration 163030: 9.279271\n",
            "Loss after iteration 163040: 9.553089\n",
            "Loss after iteration 163050: 9.399998\n",
            "Loss after iteration 163060: 9.908586\n",
            "Loss after iteration 163070: 9.369874\n",
            "Loss after iteration 163080: 9.268772\n",
            "Loss after iteration 163090: 10.281567\n",
            "Loss after iteration 163100: 9.387164\n",
            "Loss after iteration 163110: 9.615620\n",
            "Loss after iteration 163120: 10.565953\n",
            "Loss after iteration 163130: 9.879213\n",
            "Loss after iteration 163140: 9.485128\n",
            "Loss after iteration 163150: 10.161639\n",
            "Loss after iteration 163160: 10.423074\n",
            "Loss after iteration 163170: 10.427825\n",
            "Loss after iteration 163180: 10.120330\n",
            "Loss after iteration 163190: 9.532987\n",
            "Loss after iteration 163200: 9.314317\n",
            "Loss after iteration 163210: 9.551858\n",
            "Loss after iteration 163220: 9.554436\n",
            "Loss after iteration 163230: 9.613738\n",
            "Loss after iteration 163240: 9.409920\n",
            "Loss after iteration 163250: 9.645113\n",
            "Loss after iteration 163260: 9.932656\n",
            "Loss after iteration 163270: 9.815340\n",
            "Loss after iteration 163280: 10.738770\n",
            "Loss after iteration 163290: 9.869007\n",
            "Loss after iteration 163300: 10.075158\n",
            "Loss after iteration 163310: 9.224675\n",
            "Loss after iteration 163320: 9.365862\n",
            "Loss after iteration 163330: 9.501925\n",
            "Loss after iteration 163340: 10.067234\n",
            "Loss after iteration 163350: 9.234757\n",
            "Loss after iteration 163360: 9.184397\n",
            "Loss after iteration 163370: 10.057571\n",
            "Loss after iteration 163380: 9.514946\n",
            "Loss after iteration 163390: 9.988096\n",
            "Loss after iteration 163400: 9.628163\n",
            "Loss after iteration 163410: 9.234869\n",
            "Loss after iteration 163420: 9.605644\n",
            "Loss after iteration 163430: 9.775009\n",
            "Loss after iteration 163440: 9.081036\n",
            "Loss after iteration 163450: 9.172252\n",
            "Loss after iteration 163460: 9.389109\n",
            "Loss after iteration 163470: 9.246009\n",
            "Loss after iteration 163480: 9.746068\n",
            "Loss after iteration 163490: 9.558942\n",
            "Loss after iteration 163500: 10.556108\n",
            "Loss after iteration 163510: 9.596035\n",
            "Loss after iteration 163520: 9.521697\n",
            "Loss after iteration 163530: 10.135636\n",
            "Loss after iteration 163540: 9.735449\n",
            "Loss after iteration 163550: 9.698296\n",
            "Loss after iteration 163560: 9.458338\n",
            "Loss after iteration 163570: 9.614263\n",
            "Loss after iteration 163580: 9.343566\n",
            "Loss after iteration 163590: 9.567293\n",
            "Loss after iteration 163600: 9.979462\n",
            "Loss after iteration 163610: 10.092516\n",
            "Loss after iteration 163620: 9.231222\n",
            "Loss after iteration 163630: 9.951483\n",
            "Loss after iteration 163640: 9.514366\n",
            "Loss after iteration 163650: 9.751137\n",
            "Loss after iteration 163660: 9.211890\n",
            "Loss after iteration 163670: 9.314487\n",
            "Loss after iteration 163680: 9.852165\n",
            "Loss after iteration 163690: 9.220624\n",
            "Loss after iteration 163700: 10.345964\n",
            "Loss after iteration 163710: 9.540343\n",
            "Loss after iteration 163720: 9.494143\n",
            "Loss after iteration 163730: 9.831771\n",
            "Loss after iteration 163740: 9.830874\n",
            "Loss after iteration 163750: 9.295039\n",
            "Loss after iteration 163760: 10.307494\n",
            "Loss after iteration 163770: 10.535192\n",
            "Loss after iteration 163780: 9.351077\n",
            "Loss after iteration 163790: 9.630046\n",
            "Loss after iteration 163800: 9.343823\n",
            "Loss after iteration 163810: 9.452189\n",
            "Loss after iteration 163820: 9.574369\n",
            "Loss after iteration 163830: 9.296963\n",
            "Loss after iteration 163840: 9.590831\n",
            "Loss after iteration 163850: 9.912511\n",
            "Loss after iteration 163860: 9.794347\n",
            "Loss after iteration 163870: 10.160391\n",
            "Loss after iteration 163880: 9.264347\n",
            "Loss after iteration 163890: 9.240792\n",
            "Loss after iteration 163900: 9.300913\n",
            "Loss after iteration 163910: 10.352287\n",
            "Loss after iteration 163920: 9.580492\n",
            "Loss after iteration 163930: 10.017534\n",
            "Loss after iteration 163940: 12.610279\n",
            "Loss after iteration 163950: 9.787970\n",
            "Loss after iteration 163960: 10.227364\n",
            "Loss after iteration 163970: 10.642272\n",
            "Loss after iteration 163980: 9.247253\n",
            "Loss after iteration 163990: 9.968401\n",
            "Loss after iteration 164000: 9.656827\n",
            "Loss after iteration 164010: 9.401860\n",
            "Loss after iteration 164020: 9.593278\n",
            "Loss after iteration 164030: 9.239192\n",
            "Loss after iteration 164040: 9.697244\n",
            "Loss after iteration 164050: 9.251164\n",
            "Loss after iteration 164060: 9.534107\n",
            "Loss after iteration 164070: 9.339991\n",
            "Loss after iteration 164080: 9.447624\n",
            "Loss after iteration 164090: 9.404828\n",
            "Loss after iteration 164100: 10.599479\n",
            "Loss after iteration 164110: 9.412458\n",
            "Loss after iteration 164120: 9.568408\n",
            "Loss after iteration 164130: 9.506984\n",
            "Loss after iteration 164140: 9.716426\n",
            "Loss after iteration 164150: 9.676401\n",
            "Loss after iteration 164160: 9.747046\n",
            "Loss after iteration 164170: 9.484016\n",
            "Loss after iteration 164180: 9.659948\n",
            "Loss after iteration 164190: 9.735440\n",
            "Loss after iteration 164200: 9.413012\n",
            "Loss after iteration 164210: 9.794263\n",
            "Loss after iteration 164220: 9.390545\n",
            "Loss after iteration 164230: 9.454300\n",
            "Loss after iteration 164240: 9.930962\n",
            "Loss after iteration 164250: 9.604323\n",
            "Loss after iteration 164260: 9.931390\n",
            "Loss after iteration 164270: 9.725093\n",
            "Loss after iteration 164280: 9.548580\n",
            "Loss after iteration 164290: 9.439213\n",
            "Loss after iteration 164300: 9.632114\n",
            "Loss after iteration 164310: 9.385774\n",
            "Loss after iteration 164320: 9.436811\n",
            "Loss after iteration 164330: 9.337162\n",
            "Loss after iteration 164340: 9.535385\n",
            "Loss after iteration 164350: 9.977386\n",
            "Loss after iteration 164360: 9.571922\n",
            "Loss after iteration 164370: 9.988511\n",
            "Loss after iteration 164380: 9.506801\n",
            "Loss after iteration 164390: 10.110828\n",
            "Loss after iteration 164400: 9.511561\n",
            "Loss after iteration 164410: 10.264928\n",
            "Loss after iteration 164420: 10.694922\n",
            "Loss after iteration 164430: 9.706480\n",
            "Loss after iteration 164440: 10.519793\n",
            "Loss after iteration 164450: 9.900318\n",
            "Loss after iteration 164460: 9.274250\n",
            "Loss after iteration 164470: 9.334523\n",
            "Loss after iteration 164480: 9.531526\n",
            "Loss after iteration 164490: 9.371447\n",
            "Loss after iteration 164500: 9.334198\n",
            "Loss after iteration 164510: 8.994818\n",
            "Loss after iteration 164520: 9.432735\n",
            "Loss after iteration 164530: 9.170095\n",
            "Loss after iteration 164540: 9.492335\n",
            "Loss after iteration 164550: 9.699909\n",
            "Loss after iteration 164560: 9.758423\n",
            "Loss after iteration 164570: 9.423053\n",
            "Loss after iteration 164580: 9.476790\n",
            "Loss after iteration 164590: 10.160563\n",
            "Loss after iteration 164600: 9.267719\n",
            "Loss after iteration 164610: 9.512914\n",
            "Loss after iteration 164620: 9.975508\n",
            "Loss after iteration 164630: 9.377354\n",
            "Loss after iteration 164640: 9.524864\n",
            "Loss after iteration 164650: 10.184621\n",
            "Loss after iteration 164660: 10.072958\n",
            "Loss after iteration 164670: 9.311524\n",
            "Loss after iteration 164680: 9.711159\n",
            "Loss after iteration 164690: 9.707686\n",
            "Loss after iteration 164700: 9.912476\n",
            "Loss after iteration 164710: 10.027094\n",
            "Loss after iteration 164720: 9.519088\n",
            "Loss after iteration 164730: 9.517120\n",
            "Loss after iteration 164740: 9.976743\n",
            "Loss after iteration 164750: 9.942422\n",
            "Loss after iteration 164760: 9.920590\n",
            "Loss after iteration 164770: 9.248602\n",
            "Loss after iteration 164780: 9.275800\n",
            "Loss after iteration 164790: 9.402087\n",
            "Loss after iteration 164800: 9.486792\n",
            "Loss after iteration 164810: 9.484075\n",
            "Loss after iteration 164820: 9.605934\n",
            "Loss after iteration 164830: 9.548420\n",
            "Loss after iteration 164840: 9.802398\n",
            "Loss after iteration 164850: 9.265343\n",
            "Loss after iteration 164860: 9.428857\n",
            "Loss after iteration 164870: 9.282063\n",
            "Loss after iteration 164880: 9.217097\n",
            "Loss after iteration 164890: 9.154075\n",
            "Loss after iteration 164900: 9.977148\n",
            "Loss after iteration 164910: 9.593594\n",
            "Loss after iteration 164920: 9.740849\n",
            "Loss after iteration 164930: 9.407834\n",
            "Loss after iteration 164940: 9.462345\n",
            "Loss after iteration 164950: 9.991416\n",
            "Loss after iteration 164960: 9.841730\n",
            "Loss after iteration 164970: 9.875964\n",
            "Loss after iteration 164980: 9.474638\n",
            "Loss after iteration 164990: 9.310104\n",
            "Loss after iteration 165000: 9.632426\n",
            "Loss after iteration 165010: 9.813793\n",
            "Loss after iteration 165020: 10.649390\n",
            "Loss after iteration 165030: 9.364149\n",
            "Loss after iteration 165040: 9.262241\n",
            "Loss after iteration 165050: 9.516550\n",
            "Loss after iteration 165060: 9.206322\n",
            "Loss after iteration 165070: 9.259342\n",
            "Loss after iteration 165080: 9.289743\n",
            "Loss after iteration 165090: 9.275678\n",
            "Loss after iteration 165100: 9.317664\n",
            "Loss after iteration 165110: 9.155561\n",
            "Loss after iteration 165120: 9.800209\n",
            "Loss after iteration 165130: 9.894257\n",
            "Loss after iteration 165140: 10.037095\n",
            "Loss after iteration 165150: 9.127707\n",
            "Loss after iteration 165160: 10.107852\n",
            "Loss after iteration 165170: 9.619668\n",
            "Loss after iteration 165180: 9.596190\n",
            "Loss after iteration 165190: 9.311978\n",
            "Loss after iteration 165200: 9.279667\n",
            "Loss after iteration 165210: 10.026877\n",
            "Loss after iteration 165220: 9.659212\n",
            "Loss after iteration 165230: 9.520349\n",
            "Loss after iteration 165240: 9.862567\n",
            "Loss after iteration 165250: 9.316592\n",
            "Loss after iteration 165260: 9.110737\n",
            "Loss after iteration 165270: 9.261475\n",
            "Loss after iteration 165280: 9.689063\n",
            "Loss after iteration 165290: 8.921773\n",
            "Loss after iteration 165300: 9.414829\n",
            "Loss after iteration 165310: 9.418155\n",
            "Loss after iteration 165320: 9.205233\n",
            "Loss after iteration 165330: 9.820252\n",
            "Loss after iteration 165340: 9.305892\n",
            "Loss after iteration 165350: 9.391863\n",
            "Loss after iteration 165360: 10.063458\n",
            "Loss after iteration 165370: 9.269518\n",
            "Loss after iteration 165380: 9.238185\n",
            "Loss after iteration 165390: 9.415506\n",
            "Loss after iteration 165400: 9.743770\n",
            "Loss after iteration 165410: 9.200707\n",
            "Loss after iteration 165420: 9.421609\n",
            "Loss after iteration 165430: 9.733077\n",
            "Loss after iteration 165440: 9.737534\n",
            "Loss after iteration 165450: 10.021684\n",
            "Loss after iteration 165460: 9.434095\n",
            "Loss after iteration 165470: 9.354712\n",
            "Loss after iteration 165480: 9.653238\n",
            "Loss after iteration 165490: 9.398912\n",
            "Loss after iteration 165500: 9.919404\n",
            "Loss after iteration 165510: 9.303467\n",
            "Loss after iteration 165520: 9.388738\n",
            "Loss after iteration 165530: 9.677760\n",
            "Loss after iteration 165540: 9.330995\n",
            "Loss after iteration 165550: 9.912340\n",
            "Loss after iteration 165560: 9.911276\n",
            "Loss after iteration 165570: 9.223168\n",
            "Loss after iteration 165580: 9.306475\n",
            "Loss after iteration 165590: 9.816384\n",
            "Loss after iteration 165600: 9.207756\n",
            "Loss after iteration 165610: 9.729415\n",
            "Loss after iteration 165620: 9.388896\n",
            "Loss after iteration 165630: 9.270407\n",
            "Loss after iteration 165640: 9.910009\n",
            "Loss after iteration 165650: 9.392921\n",
            "Loss after iteration 165660: 9.226796\n",
            "Loss after iteration 165670: 9.484354\n",
            "Loss after iteration 165680: 9.303487\n",
            "Loss after iteration 165690: 9.469121\n",
            "Loss after iteration 165700: 9.663544\n",
            "Loss after iteration 165710: 9.644785\n",
            "Loss after iteration 165720: 9.771201\n",
            "Loss after iteration 165730: 9.672110\n",
            "Loss after iteration 165740: 9.780517\n",
            "Loss after iteration 165750: 9.719183\n",
            "Loss after iteration 165760: 9.992283\n",
            "Loss after iteration 165770: 9.271051\n",
            "Loss after iteration 165780: 9.159321\n",
            "Loss after iteration 165790: 10.299179\n",
            "Loss after iteration 165800: 10.096714\n",
            "Loss after iteration 165810: 9.256619\n",
            "Loss after iteration 165820: 9.706849\n",
            "Loss after iteration 165830: 10.199506\n",
            "Loss after iteration 165840: 9.918676\n",
            "Loss after iteration 165850: 9.572379\n",
            "Loss after iteration 165860: 9.450535\n",
            "Loss after iteration 165870: 9.669920\n",
            "Loss after iteration 165880: 10.033107\n",
            "Loss after iteration 165890: 10.483349\n",
            "Loss after iteration 165900: 9.506719\n",
            "Loss after iteration 165910: 9.838556\n",
            "Loss after iteration 165920: 9.550927\n",
            "Loss after iteration 165930: 9.639595\n",
            "Loss after iteration 165940: 9.876875\n",
            "Loss after iteration 165950: 9.714539\n",
            "Loss after iteration 165960: 9.823420\n",
            "Loss after iteration 165970: 10.062435\n",
            "Loss after iteration 165980: 9.253692\n",
            "Loss after iteration 165990: 10.322819\n",
            "Loss after iteration 166000: 10.095246\n",
            "Loss after iteration 166010: 10.194853\n",
            "Loss after iteration 166020: 9.277672\n",
            "Loss after iteration 166030: 10.323179\n",
            "Loss after iteration 166040: 9.147500\n",
            "Loss after iteration 166050: 9.351552\n",
            "Loss after iteration 166060: 9.958960\n",
            "Loss after iteration 166070: 9.172635\n",
            "Loss after iteration 166080: 9.256075\n",
            "Loss after iteration 166090: 9.686207\n",
            "Loss after iteration 166100: 9.278621\n",
            "Loss after iteration 166110: 9.809102\n",
            "Loss after iteration 166120: 9.778264\n",
            "Loss after iteration 166130: 9.974194\n",
            "Loss after iteration 166140: 9.913533\n",
            "Loss after iteration 166150: 10.014875\n",
            "Loss after iteration 166160: 9.798593\n",
            "Loss after iteration 166170: 9.699401\n",
            "Loss after iteration 166180: 9.376001\n",
            "Loss after iteration 166190: 9.422066\n",
            "Loss after iteration 166200: 9.773948\n",
            "Loss after iteration 166210: 9.731405\n",
            "Loss after iteration 166220: 9.528662\n",
            "Loss after iteration 166230: 10.075108\n",
            "Loss after iteration 166240: 10.161365\n",
            "Loss after iteration 166250: 9.921809\n",
            "Loss after iteration 166260: 9.840225\n",
            "Loss after iteration 166270: 9.528610\n",
            "Loss after iteration 166280: 9.389152\n",
            "Loss after iteration 166290: 9.158777\n",
            "Loss after iteration 166300: 9.788221\n",
            "Loss after iteration 166310: 9.730425\n",
            "Loss after iteration 166320: 9.373504\n",
            "Loss after iteration 166330: 9.648701\n",
            "Loss after iteration 166340: 9.620689\n",
            "Loss after iteration 166350: 9.695769\n",
            "Loss after iteration 166360: 10.211911\n",
            "Loss after iteration 166370: 9.442901\n",
            "Loss after iteration 166380: 9.231512\n",
            "Loss after iteration 166390: 9.488192\n",
            "Loss after iteration 166400: 11.910604\n",
            "Loss after iteration 166410: 9.425331\n",
            "Loss after iteration 166420: 9.353097\n",
            "Loss after iteration 166430: 9.951174\n",
            "Loss after iteration 166440: 9.328826\n",
            "Loss after iteration 166450: 9.829516\n",
            "Loss after iteration 166460: 9.377016\n",
            "Loss after iteration 166470: 10.020325\n",
            "Loss after iteration 166480: 9.619782\n",
            "Loss after iteration 166490: 9.548509\n",
            "Loss after iteration 166500: 9.589185\n",
            "Loss after iteration 166510: 10.375743\n",
            "Loss after iteration 166520: 9.521407\n",
            "Loss after iteration 166530: 9.290693\n",
            "Loss after iteration 166540: 9.185370\n",
            "Loss after iteration 166550: 9.883177\n",
            "Loss after iteration 166560: 9.255584\n",
            "Loss after iteration 166570: 9.563676\n",
            "Loss after iteration 166580: 9.926925\n",
            "Loss after iteration 166590: 9.504677\n",
            "Loss after iteration 166600: 9.320031\n",
            "Loss after iteration 166610: 9.315500\n",
            "Loss after iteration 166620: 9.712552\n",
            "Loss after iteration 166630: 9.612263\n",
            "Loss after iteration 166640: 9.352883\n",
            "Loss after iteration 166650: 9.392743\n",
            "Loss after iteration 166660: 9.898002\n",
            "Loss after iteration 166670: 9.112455\n",
            "Loss after iteration 166680: 9.178828\n",
            "Loss after iteration 166690: 9.829520\n",
            "Loss after iteration 166700: 9.756338\n",
            "Loss after iteration 166710: 9.313205\n",
            "Loss after iteration 166720: 10.283770\n",
            "Loss after iteration 166730: 9.602206\n",
            "Loss after iteration 166740: 9.249887\n",
            "Loss after iteration 166750: 9.246781\n",
            "Loss after iteration 166760: 9.894539\n",
            "Loss after iteration 166770: 9.986909\n",
            "Loss after iteration 166780: 10.295287\n",
            "Loss after iteration 166790: 9.583248\n",
            "Loss after iteration 166800: 9.364169\n",
            "Loss after iteration 166810: 9.204408\n",
            "Loss after iteration 166820: 9.859584\n",
            "Loss after iteration 166830: 9.800907\n",
            "Loss after iteration 166840: 9.303591\n",
            "Loss after iteration 166850: 9.412845\n",
            "Loss after iteration 166860: 9.335052\n",
            "Loss after iteration 166870: 9.494528\n",
            "Loss after iteration 166880: 9.347440\n",
            "Loss after iteration 166890: 9.458955\n",
            "Loss after iteration 166900: 10.016464\n",
            "Loss after iteration 166910: 9.576204\n",
            "Loss after iteration 166920: 10.018043\n",
            "Loss after iteration 166930: 9.307158\n",
            "Loss after iteration 166940: 9.424770\n",
            "Loss after iteration 166950: 10.102248\n",
            "Loss after iteration 166960: 9.613294\n",
            "Loss after iteration 166970: 9.925030\n",
            "Loss after iteration 166980: 9.450507\n",
            "Loss after iteration 166990: 9.351381\n",
            "Loss after iteration 167000: 9.433029\n",
            "Loss after iteration 167010: 9.583652\n",
            "Loss after iteration 167020: 9.662876\n",
            "Loss after iteration 167030: 10.321665\n",
            "Loss after iteration 167040: 10.275304\n",
            "Loss after iteration 167050: 9.368675\n",
            "Loss after iteration 167060: 9.929216\n",
            "Loss after iteration 167070: 9.193800\n",
            "Loss after iteration 167080: 9.252867\n",
            "Loss after iteration 167090: 9.782000\n",
            "Loss after iteration 167100: 10.011385\n",
            "Loss after iteration 167110: 9.335372\n",
            "Loss after iteration 167120: 9.609277\n",
            "Loss after iteration 167130: 11.017133\n",
            "Loss after iteration 167140: 9.647128\n",
            "Loss after iteration 167150: 9.262257\n",
            "Loss after iteration 167160: 9.486129\n",
            "Loss after iteration 167170: 9.537044\n",
            "Loss after iteration 167180: 9.483316\n",
            "Loss after iteration 167190: 9.564515\n",
            "Loss after iteration 167200: 10.573020\n",
            "Loss after iteration 167210: 9.860759\n",
            "Loss after iteration 167220: 9.463150\n",
            "Loss after iteration 167230: 9.469041\n",
            "Loss after iteration 167240: 9.022916\n",
            "Loss after iteration 167250: 9.488349\n",
            "Loss after iteration 167260: 9.300980\n",
            "Loss after iteration 167270: 9.562009\n",
            "Loss after iteration 167280: 9.956652\n",
            "Loss after iteration 167290: 9.299935\n",
            "Loss after iteration 167300: 9.678435\n",
            "Loss after iteration 167310: 9.865033\n",
            "Loss after iteration 167320: 9.872635\n",
            "Loss after iteration 167330: 9.458412\n",
            "Loss after iteration 167340: 9.942421\n",
            "Loss after iteration 167350: 9.607319\n",
            "Loss after iteration 167360: 10.011531\n",
            "Loss after iteration 167370: 9.964247\n",
            "Loss after iteration 167380: 10.184906\n",
            "Loss after iteration 167390: 9.099715\n",
            "Loss after iteration 167400: 9.434592\n",
            "Loss after iteration 167410: 9.533089\n",
            "Loss after iteration 167420: 9.200411\n",
            "Loss after iteration 167430: 9.321271\n",
            "Loss after iteration 167440: 9.727977\n",
            "Loss after iteration 167450: 9.323602\n",
            "Loss after iteration 167460: 10.182561\n",
            "Loss after iteration 167470: 9.594152\n",
            "Loss after iteration 167480: 9.908385\n",
            "Loss after iteration 167490: 9.819354\n",
            "Loss after iteration 167500: 9.547582\n",
            "Loss after iteration 167510: 10.984968\n",
            "Loss after iteration 167520: 9.605365\n",
            "Loss after iteration 167530: 9.442030\n",
            "Loss after iteration 167540: 9.636883\n",
            "Loss after iteration 167550: 9.823654\n",
            "Loss after iteration 167560: 9.802795\n",
            "Loss after iteration 167570: 11.057025\n",
            "Loss after iteration 167580: 10.418664\n",
            "Loss after iteration 167590: 10.001278\n",
            "Loss after iteration 167600: 9.364107\n",
            "Loss after iteration 167610: 9.285385\n",
            "Loss after iteration 167620: 9.234987\n",
            "Loss after iteration 167630: 9.590778\n",
            "Loss after iteration 167640: 9.857182\n",
            "Loss after iteration 167650: 9.917833\n",
            "Loss after iteration 167660: 9.583898\n",
            "Loss after iteration 167670: 9.660172\n",
            "Loss after iteration 167680: 9.404319\n",
            "Loss after iteration 167690: 9.293424\n",
            "Loss after iteration 167700: 9.482600\n",
            "Loss after iteration 167710: 9.930395\n",
            "Loss after iteration 167720: 9.831160\n",
            "Loss after iteration 167730: 9.643795\n",
            "Loss after iteration 167740: 9.709557\n",
            "Loss after iteration 167750: 10.505304\n",
            "Loss after iteration 167760: 10.146086\n",
            "Loss after iteration 167770: 9.761377\n",
            "Loss after iteration 167780: 10.239236\n",
            "Loss after iteration 167790: 10.685594\n",
            "Loss after iteration 167800: 10.108179\n",
            "Loss after iteration 167810: 9.726247\n",
            "Loss after iteration 167820: 9.717695\n",
            "Loss after iteration 167830: 10.970061\n",
            "Loss after iteration 167840: 9.785809\n",
            "Loss after iteration 167850: 9.617948\n",
            "Loss after iteration 167860: 9.655038\n",
            "Loss after iteration 167870: 9.608880\n",
            "Loss after iteration 167880: 9.355086\n",
            "Loss after iteration 167890: 10.494188\n",
            "Loss after iteration 167900: 10.130845\n",
            "Loss after iteration 167910: 9.868847\n",
            "Loss after iteration 167920: 9.440353\n",
            "Loss after iteration 167930: 9.890310\n",
            "Loss after iteration 167940: 9.413123\n",
            "Loss after iteration 167950: 9.168680\n",
            "Loss after iteration 167960: 9.277050\n",
            "Loss after iteration 167970: 9.789099\n",
            "Loss after iteration 167980: 9.642380\n",
            "Loss after iteration 167990: 9.881466\n",
            "Loss after iteration 168000: 9.665193\n",
            "Loss after iteration 168010: 9.246813\n",
            "Loss after iteration 168020: 9.836297\n",
            "Loss after iteration 168030: 9.410744\n",
            "Loss after iteration 168040: 9.739933\n",
            "Loss after iteration 168050: 9.240312\n",
            "Loss after iteration 168060: 9.190452\n",
            "Loss after iteration 168070: 9.376058\n",
            "Loss after iteration 168080: 9.820399\n",
            "Loss after iteration 168090: 9.489483\n",
            "Loss after iteration 168100: 9.725697\n",
            "Loss after iteration 168110: 9.214788\n",
            "Loss after iteration 168120: 10.113414\n",
            "Loss after iteration 168130: 9.369033\n",
            "Loss after iteration 168140: 9.566317\n",
            "Loss after iteration 168150: 9.768115\n",
            "Loss after iteration 168160: 9.735338\n",
            "Loss after iteration 168170: 9.365840\n",
            "Loss after iteration 168180: 9.728930\n",
            "Loss after iteration 168190: 9.346608\n",
            "Loss after iteration 168200: 9.278074\n",
            "Loss after iteration 168210: 9.140430\n",
            "Loss after iteration 168220: 9.870138\n",
            "Loss after iteration 168230: 10.186988\n",
            "Loss after iteration 168240: 9.898082\n",
            "Loss after iteration 168250: 10.573354\n",
            "Loss after iteration 168260: 10.984535\n",
            "Loss after iteration 168270: 10.211495\n",
            "Loss after iteration 168280: 9.456726\n",
            "Loss after iteration 168290: 9.548991\n",
            "Loss after iteration 168300: 9.934463\n",
            "Loss after iteration 168310: 9.950385\n",
            "Loss after iteration 168320: 9.754814\n",
            "Loss after iteration 168330: 10.157193\n",
            "Loss after iteration 168340: 9.451134\n",
            "Loss after iteration 168350: 9.446395\n",
            "Loss after iteration 168360: 9.911329\n",
            "Loss after iteration 168370: 9.233780\n",
            "Loss after iteration 168380: 9.489102\n",
            "Loss after iteration 168390: 9.743365\n",
            "Loss after iteration 168400: 9.255640\n",
            "Loss after iteration 168410: 8.959304\n",
            "Loss after iteration 168420: 9.133796\n",
            "Loss after iteration 168430: 9.625422\n",
            "Loss after iteration 168440: 9.639825\n",
            "Loss after iteration 168450: 9.430653\n",
            "Loss after iteration 168460: 9.510861\n",
            "Loss after iteration 168470: 10.027381\n",
            "Loss after iteration 168480: 9.527712\n",
            "Loss after iteration 168490: 10.556994\n",
            "Loss after iteration 168500: 9.506949\n",
            "Loss after iteration 168510: 10.447613\n",
            "Loss after iteration 168520: 9.641488\n",
            "Loss after iteration 168530: 9.973180\n",
            "Loss after iteration 168540: 9.549992\n",
            "Loss after iteration 168550: 9.386335\n",
            "Loss after iteration 168560: 9.439565\n",
            "Loss after iteration 168570: 9.521487\n",
            "Loss after iteration 168580: 9.398756\n",
            "Loss after iteration 168590: 9.470614\n",
            "Loss after iteration 168600: 9.389032\n",
            "Loss after iteration 168610: 9.422174\n",
            "Loss after iteration 168620: 9.259549\n",
            "Loss after iteration 168630: 9.455206\n",
            "Loss after iteration 168640: 9.472281\n",
            "Loss after iteration 168650: 10.097987\n",
            "Loss after iteration 168660: 9.582512\n",
            "Loss after iteration 168670: 9.821865\n",
            "Loss after iteration 168680: 10.475951\n",
            "Loss after iteration 168690: 9.933411\n",
            "Loss after iteration 168700: 9.876320\n",
            "Loss after iteration 168710: 10.774399\n",
            "Loss after iteration 168720: 10.873953\n",
            "Loss after iteration 168730: 9.783384\n",
            "Loss after iteration 168740: 9.585478\n",
            "Loss after iteration 168750: 9.244889\n",
            "Loss after iteration 168760: 10.178154\n",
            "Loss after iteration 168770: 10.257771\n",
            "Loss after iteration 168780: 9.607649\n",
            "Loss after iteration 168790: 9.599099\n",
            "Loss after iteration 168800: 9.841585\n",
            "Loss after iteration 168810: 9.986295\n",
            "Loss after iteration 168820: 10.146239\n",
            "Loss after iteration 168830: 9.131846\n",
            "Loss after iteration 168840: 9.246371\n",
            "Loss after iteration 168850: 9.189735\n",
            "Loss after iteration 168860: 9.212835\n",
            "Loss after iteration 168870: 9.228313\n",
            "Loss after iteration 168880: 9.672964\n",
            "Loss after iteration 168890: 9.575777\n",
            "Loss after iteration 168900: 9.341115\n",
            "Loss after iteration 168910: 9.715809\n",
            "Loss after iteration 168920: 9.299408\n",
            "Loss after iteration 168930: 9.570423\n",
            "Loss after iteration 168940: 9.638946\n",
            "Loss after iteration 168950: 9.248698\n",
            "Loss after iteration 168960: 10.058501\n",
            "Loss after iteration 168970: 9.805563\n",
            "Loss after iteration 168980: 10.053255\n",
            "Loss after iteration 168990: 9.623594\n",
            "Loss after iteration 169000: 10.035937\n",
            "Loss after iteration 169010: 9.301250\n",
            "Loss after iteration 169020: 9.294425\n",
            "Loss after iteration 169030: 9.647955\n",
            "Loss after iteration 169040: 9.709920\n",
            "Loss after iteration 169050: 9.658433\n",
            "Loss after iteration 169060: 9.554207\n",
            "Loss after iteration 169070: 9.216533\n",
            "Loss after iteration 169080: 9.427666\n",
            "Loss after iteration 169090: 9.807266\n",
            "Loss after iteration 169100: 9.227047\n",
            "Loss after iteration 169110: 9.602925\n",
            "Loss after iteration 169120: 9.557108\n",
            "Loss after iteration 169130: 9.326947\n",
            "Loss after iteration 169140: 9.698667\n",
            "Loss after iteration 169150: 10.570735\n",
            "Loss after iteration 169160: 10.147461\n",
            "Loss after iteration 169170: 9.578402\n",
            "Loss after iteration 169180: 10.065810\n",
            "Loss after iteration 169190: 9.596087\n",
            "Loss after iteration 169200: 10.200510\n",
            "Loss after iteration 169210: 9.741113\n",
            "Loss after iteration 169220: 9.527472\n",
            "Loss after iteration 169230: 9.935132\n",
            "Loss after iteration 169240: 10.129565\n",
            "Loss after iteration 169250: 10.166872\n",
            "Loss after iteration 169260: 9.737926\n",
            "Loss after iteration 169270: 9.686517\n",
            "Loss after iteration 169280: 9.832029\n",
            "Loss after iteration 169290: 9.396670\n",
            "Loss after iteration 169300: 10.411862\n",
            "Loss after iteration 169310: 9.229788\n",
            "Loss after iteration 169320: 9.905632\n",
            "Loss after iteration 169330: 9.205417\n",
            "Loss after iteration 169340: 9.274348\n",
            "Loss after iteration 169350: 9.651313\n",
            "Loss after iteration 169360: 9.132136\n",
            "Loss after iteration 169370: 9.470343\n",
            "Loss after iteration 169380: 9.562022\n",
            "Loss after iteration 169390: 9.449410\n",
            "Loss after iteration 169400: 9.508170\n",
            "Loss after iteration 169410: 9.488047\n",
            "Loss after iteration 169420: 9.500111\n",
            "Loss after iteration 169430: 9.571337\n",
            "Loss after iteration 169440: 9.675890\n",
            "Loss after iteration 169450: 9.829296\n",
            "Loss after iteration 169460: 9.498279\n",
            "Loss after iteration 169470: 9.714389\n",
            "Loss after iteration 169480: 10.471247\n",
            "Loss after iteration 169490: 9.490894\n",
            "Loss after iteration 169500: 9.281630\n",
            "Loss after iteration 169510: 9.599843\n",
            "Loss after iteration 169520: 9.858640\n",
            "Loss after iteration 169530: 10.006787\n",
            "Loss after iteration 169540: 9.174657\n",
            "Loss after iteration 169550: 10.487971\n",
            "Loss after iteration 169560: 9.714913\n",
            "Loss after iteration 169570: 10.312412\n",
            "Loss after iteration 169580: 9.269606\n",
            "Loss after iteration 169590: 9.567703\n",
            "Loss after iteration 169600: 9.758500\n",
            "Loss after iteration 169610: 9.369904\n",
            "Loss after iteration 169620: 9.790705\n",
            "Loss after iteration 169630: 10.110493\n",
            "Loss after iteration 169640: 10.332966\n",
            "Loss after iteration 169650: 9.791500\n",
            "Loss after iteration 169660: 9.658981\n",
            "Loss after iteration 169670: 9.919911\n",
            "Loss after iteration 169680: 9.806670\n",
            "Loss after iteration 169690: 9.698162\n",
            "Loss after iteration 169700: 9.339597\n",
            "Loss after iteration 169710: 9.723366\n",
            "Loss after iteration 169720: 9.579254\n",
            "Loss after iteration 169730: 9.863408\n",
            "Loss after iteration 169740: 9.413808\n",
            "Loss after iteration 169750: 9.273234\n",
            "Loss after iteration 169760: 10.267464\n",
            "Loss after iteration 169770: 10.397387\n",
            "Loss after iteration 169780: 9.695898\n",
            "Loss after iteration 169790: 9.310575\n",
            "Loss after iteration 169800: 9.576372\n",
            "Loss after iteration 169810: 9.495877\n",
            "Loss after iteration 169820: 9.537624\n",
            "Loss after iteration 169830: 9.618715\n",
            "Loss after iteration 169840: 9.564748\n",
            "Loss after iteration 169850: 9.631852\n",
            "Loss after iteration 169860: 9.425968\n",
            "Loss after iteration 169870: 9.330437\n",
            "Loss after iteration 169880: 9.480290\n",
            "Loss after iteration 169890: 9.962693\n",
            "Loss after iteration 169900: 9.708223\n",
            "Loss after iteration 169910: 9.341030\n",
            "Loss after iteration 169920: 10.239214\n",
            "Loss after iteration 169930: 9.737948\n",
            "Loss after iteration 169940: 10.505515\n",
            "Loss after iteration 169950: 9.564385\n",
            "Loss after iteration 169960: 9.808178\n",
            "Loss after iteration 169970: 9.814039\n",
            "Loss after iteration 169980: 9.960531\n",
            "Loss after iteration 169990: 9.287472\n",
            "Loss after iteration 170000: 9.446419\n",
            "Loss after iteration 170010: 10.436842\n",
            "Loss after iteration 170020: 9.448806\n",
            "Loss after iteration 170030: 9.975653\n",
            "Loss after iteration 170040: 10.029050\n",
            "Loss after iteration 170050: 9.909096\n",
            "Loss after iteration 170060: 10.003186\n",
            "Loss after iteration 170070: 10.057662\n",
            "Loss after iteration 170080: 9.716920\n",
            "Loss after iteration 170090: 9.618008\n",
            "Loss after iteration 170100: 9.704913\n",
            "Loss after iteration 170110: 9.448799\n",
            "Loss after iteration 170120: 9.713561\n",
            "Loss after iteration 170130: 9.890575\n",
            "Loss after iteration 170140: 10.145471\n",
            "Loss after iteration 170150: 9.437083\n",
            "Loss after iteration 170160: 9.771221\n",
            "Loss after iteration 170170: 9.493382\n",
            "Loss after iteration 170180: 9.901019\n",
            "Loss after iteration 170190: 10.090143\n",
            "Loss after iteration 170200: 10.368774\n",
            "Loss after iteration 170210: 9.850163\n",
            "Loss after iteration 170220: 9.739866\n",
            "Loss after iteration 170230: 9.438930\n",
            "Loss after iteration 170240: 9.434491\n",
            "Loss after iteration 170250: 9.317719\n",
            "Loss after iteration 170260: 9.713794\n",
            "Loss after iteration 170270: 9.482558\n",
            "Loss after iteration 170280: 9.376302\n",
            "Loss after iteration 170290: 9.870474\n",
            "Loss after iteration 170300: 9.836780\n",
            "Loss after iteration 170310: 9.068398\n",
            "Loss after iteration 170320: 9.379253\n",
            "Loss after iteration 170330: 9.882204\n",
            "Loss after iteration 170340: 10.422094\n",
            "Loss after iteration 170350: 9.850621\n",
            "Loss after iteration 170360: 10.798156\n",
            "Loss after iteration 170370: 9.392746\n",
            "Loss after iteration 170380: 9.341295\n",
            "Loss after iteration 170390: 9.965750\n",
            "Loss after iteration 170400: 9.106932\n",
            "Loss after iteration 170410: 9.668473\n",
            "Loss after iteration 170420: 9.386115\n",
            "Loss after iteration 170430: 11.012873\n",
            "Loss after iteration 170440: 9.187723\n",
            "Loss after iteration 170450: 9.226305\n",
            "Loss after iteration 170460: 9.208961\n",
            "Loss after iteration 170470: 10.156476\n",
            "Loss after iteration 170480: 9.631537\n",
            "Loss after iteration 170490: 9.968476\n",
            "Loss after iteration 170500: 9.772618\n",
            "Loss after iteration 170510: 9.278931\n",
            "Loss after iteration 170520: 9.725549\n",
            "Loss after iteration 170530: 9.470526\n",
            "Loss after iteration 170540: 9.832169\n",
            "Loss after iteration 170550: 10.219376\n",
            "Loss after iteration 170560: 9.810604\n",
            "Loss after iteration 170570: 9.291173\n",
            "Loss after iteration 170580: 10.241614\n",
            "Loss after iteration 170590: 9.308723\n",
            "Loss after iteration 170600: 9.702199\n",
            "Loss after iteration 170610: 9.362049\n",
            "Loss after iteration 170620: 10.148999\n",
            "Loss after iteration 170630: 11.218270\n",
            "Loss after iteration 170640: 10.709669\n",
            "Loss after iteration 170650: 9.698383\n",
            "Loss after iteration 170660: 9.155005\n",
            "Loss after iteration 170670: 9.258642\n",
            "Loss after iteration 170680: 9.643113\n",
            "Loss after iteration 170690: 10.317946\n",
            "Loss after iteration 170700: 9.895192\n",
            "Loss after iteration 170710: 10.118572\n",
            "Loss after iteration 170720: 9.704454\n",
            "Loss after iteration 170730: 9.970586\n",
            "Loss after iteration 170740: 9.705375\n",
            "Loss after iteration 170750: 9.682165\n",
            "Loss after iteration 170760: 10.590047\n",
            "Loss after iteration 170770: 9.350053\n",
            "Loss after iteration 170780: 11.309452\n",
            "Loss after iteration 170790: 10.098263\n",
            "Loss after iteration 170800: 9.877273\n",
            "Loss after iteration 170810: 9.636501\n",
            "Loss after iteration 170820: 9.339110\n",
            "Loss after iteration 170830: 9.547708\n",
            "Loss after iteration 170840: 10.042415\n",
            "Loss after iteration 170850: 9.373338\n",
            "Loss after iteration 170860: 9.409425\n",
            "Loss after iteration 170870: 9.185425\n",
            "Loss after iteration 170880: 9.500233\n",
            "Loss after iteration 170890: 10.195022\n",
            "Loss after iteration 170900: 9.228195\n",
            "Loss after iteration 170910: 9.788618\n",
            "Loss after iteration 170920: 9.367720\n",
            "Loss after iteration 170930: 9.708462\n",
            "Loss after iteration 170940: 9.287896\n",
            "Loss after iteration 170950: 9.360362\n",
            "Loss after iteration 170960: 10.151324\n",
            "Loss after iteration 170970: 9.851213\n",
            "Loss after iteration 170980: 9.759685\n",
            "Loss after iteration 170990: 10.015799\n",
            "Loss after iteration 171000: 9.558547\n",
            "Loss after iteration 171010: 9.894506\n",
            "Loss after iteration 171020: 9.634116\n",
            "Loss after iteration 171030: 10.347476\n",
            "Loss after iteration 171040: 9.313496\n",
            "Loss after iteration 171050: 9.659461\n",
            "Loss after iteration 171060: 9.845983\n",
            "Loss after iteration 171070: 9.379894\n",
            "Loss after iteration 171080: 9.434953\n",
            "Loss after iteration 171090: 9.651930\n",
            "Loss after iteration 171100: 9.311979\n",
            "Loss after iteration 171110: 10.462024\n",
            "Loss after iteration 171120: 9.729390\n",
            "Loss after iteration 171130: 9.887721\n",
            "Loss after iteration 171140: 9.846776\n",
            "Loss after iteration 171150: 9.616798\n",
            "Loss after iteration 171160: 9.430911\n",
            "Loss after iteration 171170: 9.674908\n",
            "Loss after iteration 171180: 9.444371\n",
            "Loss after iteration 171190: 9.621904\n",
            "Loss after iteration 171200: 9.586966\n",
            "Loss after iteration 171210: 9.234198\n",
            "Loss after iteration 171220: 9.543095\n",
            "Loss after iteration 171230: 9.676763\n",
            "Loss after iteration 171240: 9.555735\n",
            "Loss after iteration 171250: 9.711657\n",
            "Loss after iteration 171260: 9.391549\n",
            "Loss after iteration 171270: 10.061616\n",
            "Loss after iteration 171280: 9.531811\n",
            "Loss after iteration 171290: 10.385923\n",
            "Loss after iteration 171300: 9.862433\n",
            "Loss after iteration 171310: 9.644007\n",
            "Loss after iteration 171320: 9.592640\n",
            "Loss after iteration 171330: 9.479851\n",
            "Loss after iteration 171340: 9.450856\n",
            "Loss after iteration 171350: 9.331961\n",
            "Loss after iteration 171360: 9.669260\n",
            "Loss after iteration 171370: 9.567315\n",
            "Loss after iteration 171380: 9.353511\n",
            "Loss after iteration 171390: 9.915807\n",
            "Loss after iteration 171400: 9.396174\n",
            "Loss after iteration 171410: 9.601240\n",
            "Loss after iteration 171420: 9.516892\n",
            "Loss after iteration 171430: 9.158150\n",
            "Loss after iteration 171440: 9.915074\n",
            "Loss after iteration 171450: 10.644342\n",
            "Loss after iteration 171460: 9.398883\n",
            "Loss after iteration 171470: 11.240624\n",
            "Loss after iteration 171480: 9.527464\n",
            "Loss after iteration 171490: 9.458125\n",
            "Loss after iteration 171500: 9.667909\n",
            "Loss after iteration 171510: 9.455476\n",
            "Loss after iteration 171520: 9.365567\n",
            "Loss after iteration 171530: 9.649634\n",
            "Loss after iteration 171540: 9.691475\n",
            "Loss after iteration 171550: 9.575655\n",
            "Loss after iteration 171560: 9.905342\n",
            "Loss after iteration 171570: 9.470853\n",
            "Loss after iteration 171580: 9.628384\n",
            "Loss after iteration 171590: 9.704277\n",
            "Loss after iteration 171600: 10.293395\n",
            "Loss after iteration 171610: 9.373790\n",
            "Loss after iteration 171620: 9.004906\n",
            "Loss after iteration 171630: 9.391095\n",
            "Loss after iteration 171640: 9.615408\n",
            "Loss after iteration 171650: 9.840560\n",
            "Loss after iteration 171660: 9.680862\n",
            "Loss after iteration 171670: 9.157961\n",
            "Loss after iteration 171680: 9.283899\n",
            "Loss after iteration 171690: 9.366019\n",
            "Loss after iteration 171700: 9.190210\n",
            "Loss after iteration 171710: 9.940783\n",
            "Loss after iteration 171720: 9.604572\n",
            "Loss after iteration 171730: 9.311266\n",
            "Loss after iteration 171740: 9.279019\n",
            "Loss after iteration 171750: 10.022217\n",
            "Loss after iteration 171760: 9.711867\n",
            "Loss after iteration 171770: 9.611728\n",
            "Loss after iteration 171780: 9.245257\n",
            "Loss after iteration 171790: 9.883935\n",
            "Loss after iteration 171800: 9.437399\n",
            "Loss after iteration 171810: 9.856868\n",
            "Loss after iteration 171820: 9.673803\n",
            "Loss after iteration 171830: 9.537130\n",
            "Loss after iteration 171840: 10.442713\n",
            "Loss after iteration 171850: 9.707864\n",
            "Loss after iteration 171860: 10.451014\n",
            "Loss after iteration 171870: 9.198308\n",
            "Loss after iteration 171880: 9.354355\n",
            "Loss after iteration 171890: 9.587167\n",
            "Loss after iteration 171900: 9.885307\n",
            "Loss after iteration 171910: 9.669014\n",
            "Loss after iteration 171920: 9.450638\n",
            "Loss after iteration 171930: 9.822338\n",
            "Loss after iteration 171940: 9.296984\n",
            "Loss after iteration 171950: 10.065518\n",
            "Loss after iteration 171960: 9.531930\n",
            "Loss after iteration 171970: 9.506847\n",
            "Loss after iteration 171980: 9.955210\n",
            "Loss after iteration 171990: 9.333129\n",
            "Loss after iteration 172000: 9.801159\n",
            "Loss after iteration 172010: 9.718724\n",
            "Loss after iteration 172020: 9.761177\n",
            "Loss after iteration 172030: 9.477490\n",
            "Loss after iteration 172040: 9.427711\n",
            "Loss after iteration 172050: 9.652289\n",
            "Loss after iteration 172060: 9.419085\n",
            "Loss after iteration 172070: 9.622424\n",
            "Loss after iteration 172080: 10.372914\n",
            "Loss after iteration 172090: 9.591769\n",
            "Loss after iteration 172100: 10.027822\n",
            "Loss after iteration 172110: 9.786078\n",
            "Loss after iteration 172120: 9.901790\n",
            "Loss after iteration 172130: 9.651130\n",
            "Loss after iteration 172140: 9.687553\n",
            "Loss after iteration 172150: 9.407829\n",
            "Loss after iteration 172160: 10.003674\n",
            "Loss after iteration 172170: 10.068900\n",
            "Loss after iteration 172180: 9.649595\n",
            "Loss after iteration 172190: 9.591715\n",
            "Loss after iteration 172200: 9.667265\n",
            "Loss after iteration 172210: 9.434312\n",
            "Loss after iteration 172220: 9.258095\n",
            "Loss after iteration 172230: 9.571628\n",
            "Loss after iteration 172240: 9.123782\n",
            "Loss after iteration 172250: 9.327165\n",
            "Loss after iteration 172260: 9.659779\n",
            "Loss after iteration 172270: 9.219554\n",
            "Loss after iteration 172280: 9.586182\n",
            "Loss after iteration 172290: 9.494660\n",
            "Loss after iteration 172300: 9.245236\n",
            "Loss after iteration 172310: 9.689480\n",
            "Loss after iteration 172320: 9.987869\n",
            "Loss after iteration 172330: 9.709551\n",
            "Loss after iteration 172340: 10.084864\n",
            "Loss after iteration 172350: 9.422006\n",
            "Loss after iteration 172360: 9.648118\n",
            "Loss after iteration 172370: 9.572259\n",
            "Loss after iteration 172380: 9.560511\n",
            "Loss after iteration 172390: 10.146117\n",
            "Loss after iteration 172400: 9.445911\n",
            "Loss after iteration 172410: 9.496516\n",
            "Loss after iteration 172420: 9.721310\n",
            "Loss after iteration 172430: 9.450792\n",
            "Loss after iteration 172440: 9.620832\n",
            "Loss after iteration 172450: 9.641699\n",
            "Loss after iteration 172460: 9.381048\n",
            "Loss after iteration 172470: 9.037100\n",
            "Loss after iteration 172480: 9.123333\n",
            "Loss after iteration 172490: 10.502059\n",
            "Loss after iteration 172500: 9.583986\n",
            "Loss after iteration 172510: 9.349733\n",
            "Loss after iteration 172520: 9.688170\n",
            "Loss after iteration 172530: 11.129829\n",
            "Loss after iteration 172540: 9.602674\n",
            "Loss after iteration 172550: 9.577517\n",
            "Loss after iteration 172560: 9.873289\n",
            "Loss after iteration 172570: 9.381602\n",
            "Loss after iteration 172580: 10.033638\n",
            "Loss after iteration 172590: 9.647643\n",
            "Loss after iteration 172600: 9.395088\n",
            "Loss after iteration 172610: 9.493748\n",
            "Loss after iteration 172620: 9.586287\n",
            "Loss after iteration 172630: 9.552362\n",
            "Loss after iteration 172640: 9.617596\n",
            "Loss after iteration 172650: 9.406053\n",
            "Loss after iteration 172660: 9.509241\n",
            "Loss after iteration 172670: 10.094350\n",
            "Loss after iteration 172680: 9.568909\n",
            "Loss after iteration 172690: 9.706137\n",
            "Loss after iteration 172700: 9.699970\n",
            "Loss after iteration 172710: 9.837002\n",
            "Loss after iteration 172720: 9.858431\n",
            "Loss after iteration 172730: 9.581146\n",
            "Loss after iteration 172740: 9.751805\n",
            "Loss after iteration 172750: 9.823562\n",
            "Loss after iteration 172760: 9.382440\n",
            "Loss after iteration 172770: 9.376845\n",
            "Loss after iteration 172780: 9.836190\n",
            "Loss after iteration 172790: 10.345865\n",
            "Loss after iteration 172800: 9.690729\n",
            "Loss after iteration 172810: 9.755212\n",
            "Loss after iteration 172820: 9.694246\n",
            "Loss after iteration 172830: 11.500308\n",
            "Loss after iteration 172840: 9.984597\n",
            "Loss after iteration 172850: 10.059296\n",
            "Loss after iteration 172860: 10.787010\n",
            "Loss after iteration 172870: 9.604435\n",
            "Loss after iteration 172880: 9.385318\n",
            "Loss after iteration 172890: 9.478099\n",
            "Loss after iteration 172900: 9.169308\n",
            "Loss after iteration 172910: 9.611174\n",
            "Loss after iteration 172920: 9.618639\n",
            "Loss after iteration 172930: 9.828586\n",
            "Loss after iteration 172940: 9.694841\n",
            "Loss after iteration 172950: 9.890671\n",
            "Loss after iteration 172960: 9.297173\n",
            "Loss after iteration 172970: 9.369362\n",
            "Loss after iteration 172980: 9.434472\n",
            "Loss after iteration 172990: 9.672241\n",
            "Loss after iteration 173000: 9.853405\n",
            "Loss after iteration 173010: 9.687100\n",
            "Loss after iteration 173020: 9.626495\n",
            "Loss after iteration 173030: 10.070376\n",
            "Loss after iteration 173040: 9.501879\n",
            "Loss after iteration 173050: 9.213311\n",
            "Loss after iteration 173060: 9.618917\n",
            "Loss after iteration 173070: 9.536833\n",
            "Loss after iteration 173080: 10.093890\n",
            "Loss after iteration 173090: 9.433593\n",
            "Loss after iteration 173100: 9.598208\n",
            "Loss after iteration 173110: 9.398996\n",
            "Loss after iteration 173120: 9.623485\n",
            "Loss after iteration 173130: 11.000141\n",
            "Loss after iteration 173140: 9.711025\n",
            "Loss after iteration 173150: 9.563652\n",
            "Loss after iteration 173160: 10.957889\n",
            "Loss after iteration 173170: 9.467494\n",
            "Loss after iteration 173180: 9.994403\n",
            "Loss after iteration 173190: 9.333868\n",
            "Loss after iteration 173200: 9.170932\n",
            "Loss after iteration 173210: 9.464272\n",
            "Loss after iteration 173220: 9.340423\n",
            "Loss after iteration 173230: 9.283083\n",
            "Loss after iteration 173240: 9.523639\n",
            "Loss after iteration 173250: 9.400695\n",
            "Loss after iteration 173260: 9.798334\n",
            "Loss after iteration 173270: 9.933552\n",
            "Loss after iteration 173280: 10.205786\n",
            "Loss after iteration 173290: 9.970696\n",
            "Loss after iteration 173300: 9.437029\n",
            "Loss after iteration 173310: 9.408366\n",
            "Loss after iteration 173320: 10.490535\n",
            "Loss after iteration 173330: 10.216528\n",
            "Loss after iteration 173340: 9.483098\n",
            "Loss after iteration 173350: 9.599556\n",
            "Loss after iteration 173360: 9.576634\n",
            "Loss after iteration 173370: 9.352736\n",
            "Loss after iteration 173380: 9.827793\n",
            "Loss after iteration 173390: 9.407985\n",
            "Loss after iteration 173400: 10.175681\n",
            "Loss after iteration 173410: 9.628373\n",
            "Loss after iteration 173420: 9.601357\n",
            "Loss after iteration 173430: 9.459411\n",
            "Loss after iteration 173440: 10.926846\n",
            "Loss after iteration 173450: 10.423540\n",
            "Loss after iteration 173460: 9.819445\n",
            "Loss after iteration 173470: 9.282107\n",
            "Loss after iteration 173480: 10.496756\n",
            "Loss after iteration 173490: 11.394937\n",
            "Loss after iteration 173500: 9.633942\n",
            "Loss after iteration 173510: 9.735823\n",
            "Loss after iteration 173520: 9.614858\n",
            "Loss after iteration 173530: 10.058409\n",
            "Loss after iteration 173540: 9.840011\n",
            "Loss after iteration 173550: 9.456988\n",
            "Loss after iteration 173560: 9.806768\n",
            "Loss after iteration 173570: 9.540460\n",
            "Loss after iteration 173580: 9.965992\n",
            "Loss after iteration 173590: 9.800277\n",
            "Loss after iteration 173600: 9.609172\n",
            "Loss after iteration 173610: 9.728307\n",
            "Loss after iteration 173620: 9.242634\n",
            "Loss after iteration 173630: 10.053568\n",
            "Loss after iteration 173640: 9.514148\n",
            "Loss after iteration 173650: 9.596313\n",
            "Loss after iteration 173660: 10.243729\n",
            "Loss after iteration 173670: 10.093147\n",
            "Loss after iteration 173680: 9.393740\n",
            "Loss after iteration 173690: 9.866098\n",
            "Loss after iteration 173700: 9.655459\n",
            "Loss after iteration 173710: 9.494169\n",
            "Loss after iteration 173720: 9.960228\n",
            "Loss after iteration 173730: 10.195515\n",
            "Loss after iteration 173740: 9.691727\n",
            "Loss after iteration 173750: 9.422101\n",
            "Loss after iteration 173760: 9.886074\n",
            "Loss after iteration 173770: 9.451446\n",
            "Loss after iteration 173780: 9.297367\n",
            "Loss after iteration 173790: 10.641024\n",
            "Loss after iteration 173800: 9.559646\n",
            "Loss after iteration 173810: 10.304361\n",
            "Loss after iteration 173820: 9.520878\n",
            "Loss after iteration 173830: 10.699203\n",
            "Loss after iteration 173840: 9.661427\n",
            "Loss after iteration 173850: 9.544800\n",
            "Loss after iteration 173860: 10.207208\n",
            "Loss after iteration 173870: 9.811980\n",
            "Loss after iteration 173880: 9.782889\n",
            "Loss after iteration 173890: 9.387830\n",
            "Loss after iteration 173900: 9.531005\n",
            "Loss after iteration 173910: 9.543564\n",
            "Loss after iteration 173920: 10.458709\n",
            "Loss after iteration 173930: 9.510765\n",
            "Loss after iteration 173940: 9.695847\n",
            "Loss after iteration 173950: 10.446173\n",
            "Loss after iteration 173960: 10.018776\n",
            "Loss after iteration 173970: 10.109478\n",
            "Loss after iteration 173980: 9.711075\n",
            "Loss after iteration 173990: 9.517297\n",
            "Loss after iteration 174000: 9.855823\n",
            "Loss after iteration 174010: 9.328798\n",
            "Loss after iteration 174020: 9.997895\n",
            "Loss after iteration 174030: 9.685940\n",
            "Loss after iteration 174040: 10.244834\n",
            "Loss after iteration 174050: 9.389470\n",
            "Loss after iteration 174060: 10.033984\n",
            "Loss after iteration 174070: 9.694384\n",
            "Loss after iteration 174080: 9.513784\n",
            "Loss after iteration 174090: 10.315344\n",
            "Loss after iteration 174100: 9.632781\n",
            "Loss after iteration 174110: 9.917914\n",
            "Loss after iteration 174120: 9.647644\n",
            "Loss after iteration 174130: 10.090790\n",
            "Loss after iteration 174140: 9.832244\n",
            "Loss after iteration 174150: 9.760358\n",
            "Loss after iteration 174160: 9.758335\n",
            "Loss after iteration 174170: 9.952848\n",
            "Loss after iteration 174180: 9.311065\n",
            "Loss after iteration 174190: 9.967650\n",
            "Loss after iteration 174200: 10.116411\n",
            "Loss after iteration 174210: 9.496161\n",
            "Loss after iteration 174220: 9.986812\n",
            "Loss after iteration 174230: 10.432457\n",
            "Loss after iteration 174240: 9.545037\n",
            "Loss after iteration 174250: 9.543477\n",
            "Loss after iteration 174260: 9.648009\n",
            "Loss after iteration 174270: 10.183207\n",
            "Loss after iteration 174280: 9.562606\n",
            "Loss after iteration 174290: 9.548078\n",
            "Loss after iteration 174300: 10.704406\n",
            "Loss after iteration 174310: 9.725760\n",
            "Loss after iteration 174320: 9.731276\n",
            "Loss after iteration 174330: 9.914185\n",
            "Loss after iteration 174340: 9.942254\n",
            "Loss after iteration 174350: 9.707517\n",
            "Loss after iteration 174360: 9.506265\n",
            "Loss after iteration 174370: 10.035428\n",
            "Loss after iteration 174380: 9.595651\n",
            "Loss after iteration 174390: 9.520142\n",
            "Loss after iteration 174400: 9.217649\n",
            "Loss after iteration 174410: 9.463645\n",
            "Loss after iteration 174420: 10.238315\n",
            "Loss after iteration 174430: 9.134224\n",
            "Loss after iteration 174440: 9.549473\n",
            "Loss after iteration 174450: 9.233484\n",
            "Loss after iteration 174460: 9.476340\n",
            "Loss after iteration 174470: 9.535395\n",
            "Loss after iteration 174480: 9.755951\n",
            "Loss after iteration 174490: 9.516222\n",
            "Loss after iteration 174500: 9.857483\n",
            "Loss after iteration 174510: 10.044512\n",
            "Loss after iteration 174520: 9.740698\n",
            "Loss after iteration 174530: 9.473313\n",
            "Loss after iteration 174540: 9.158580\n",
            "Loss after iteration 174550: 9.570604\n",
            "Loss after iteration 174560: 9.804913\n",
            "Loss after iteration 174570: 10.075621\n",
            "Loss after iteration 174580: 9.488233\n",
            "Loss after iteration 174590: 9.312094\n",
            "Loss after iteration 174600: 9.549071\n",
            "Loss after iteration 174610: 10.276317\n",
            "Loss after iteration 174620: 9.811313\n",
            "Loss after iteration 174630: 10.635162\n",
            "Loss after iteration 174640: 9.302514\n",
            "Loss after iteration 174650: 9.667018\n",
            "Loss after iteration 174660: 9.463831\n",
            "Loss after iteration 174670: 9.925660\n",
            "Loss after iteration 174680: 9.934010\n",
            "Loss after iteration 174690: 9.099903\n",
            "Loss after iteration 174700: 9.208744\n",
            "Loss after iteration 174710: 9.349545\n",
            "Loss after iteration 174720: 9.221507\n",
            "Loss after iteration 174730: 10.380401\n",
            "Loss after iteration 174740: 9.932838\n",
            "Loss after iteration 174750: 9.600683\n",
            "Loss after iteration 174760: 9.325699\n",
            "Loss after iteration 174770: 9.631887\n",
            "Loss after iteration 174780: 10.402258\n",
            "Loss after iteration 174790: 9.348503\n",
            "Loss after iteration 174800: 9.655072\n",
            "Loss after iteration 174810: 10.019539\n",
            "Loss after iteration 174820: 9.558249\n",
            "Loss after iteration 174830: 9.460733\n",
            "Loss after iteration 174840: 9.755835\n",
            "Loss after iteration 174850: 9.404419\n",
            "Loss after iteration 174860: 10.115685\n",
            "Loss after iteration 174870: 9.673869\n",
            "Loss after iteration 174880: 9.381894\n",
            "Loss after iteration 174890: 10.520756\n",
            "Loss after iteration 174900: 9.288798\n",
            "Loss after iteration 174910: 10.656680\n",
            "Loss after iteration 174920: 9.642777\n",
            "Loss after iteration 174930: 9.109159\n",
            "Loss after iteration 174940: 9.210649\n",
            "Loss after iteration 174950: 9.090108\n",
            "Loss after iteration 174960: 9.869790\n",
            "Loss after iteration 174970: 9.387913\n",
            "Loss after iteration 174980: 9.948110\n",
            "Loss after iteration 174990: 9.629878\n",
            "Loss after iteration 175000: 9.455650\n",
            "Loss after iteration 175010: 9.554534\n",
            "Loss after iteration 175020: 9.454898\n",
            "Loss after iteration 175030: 9.567143\n",
            "Loss after iteration 175040: 9.484877\n",
            "Loss after iteration 175050: 9.543671\n",
            "Loss after iteration 175060: 9.312688\n",
            "Loss after iteration 175070: 9.119865\n",
            "Loss after iteration 175080: 9.185016\n",
            "Loss after iteration 175090: 9.155543\n",
            "Loss after iteration 175100: 9.294828\n",
            "Loss after iteration 175110: 9.957482\n",
            "Loss after iteration 175120: 9.063499\n",
            "Loss after iteration 175130: 9.712474\n",
            "Loss after iteration 175140: 9.570568\n",
            "Loss after iteration 175150: 9.160988\n",
            "Loss after iteration 175160: 9.702316\n",
            "Loss after iteration 175170: 9.221926\n",
            "Loss after iteration 175180: 9.372381\n",
            "Loss after iteration 175190: 9.643728\n",
            "Loss after iteration 175200: 9.250775\n",
            "Loss after iteration 175210: 9.602281\n",
            "Loss after iteration 175220: 9.393547\n",
            "Loss after iteration 175230: 9.734569\n",
            "Loss after iteration 175240: 9.439255\n",
            "Loss after iteration 175250: 10.450307\n",
            "Loss after iteration 175260: 10.406943\n",
            "Loss after iteration 175270: 9.301826\n",
            "Loss after iteration 175280: 9.293040\n",
            "Loss after iteration 175290: 9.729365\n",
            "Loss after iteration 175300: 9.933362\n",
            "Loss after iteration 175310: 9.971131\n",
            "Loss after iteration 175320: 9.166479\n",
            "Loss after iteration 175330: 9.344782\n",
            "Loss after iteration 175340: 9.317205\n",
            "Loss after iteration 175350: 9.417533\n",
            "Loss after iteration 175360: 9.978498\n",
            "Loss after iteration 175370: 9.690721\n",
            "Loss after iteration 175380: 10.036407\n",
            "Loss after iteration 175390: 9.357195\n",
            "Loss after iteration 175400: 9.755655\n",
            "Loss after iteration 175410: 10.531724\n",
            "Loss after iteration 175420: 9.326463\n",
            "Loss after iteration 175430: 9.114254\n",
            "Loss after iteration 175440: 9.583246\n",
            "Loss after iteration 175450: 9.244747\n",
            "Loss after iteration 175460: 9.557064\n",
            "Loss after iteration 175470: 9.551269\n",
            "Loss after iteration 175480: 9.406821\n",
            "Loss after iteration 175490: 9.571239\n",
            "Loss after iteration 175500: 9.892087\n",
            "Loss after iteration 175510: 9.973940\n",
            "Loss after iteration 175520: 9.438579\n",
            "Loss after iteration 175530: 9.273376\n",
            "Loss after iteration 175540: 9.214859\n",
            "Loss after iteration 175550: 9.475891\n",
            "Loss after iteration 175560: 9.536741\n",
            "Loss after iteration 175570: 9.214235\n",
            "Loss after iteration 175580: 9.425733\n",
            "Loss after iteration 175590: 9.689560\n",
            "Loss after iteration 175600: 9.365151\n",
            "Loss after iteration 175610: 9.596698\n",
            "Loss after iteration 175620: 9.595255\n",
            "Loss after iteration 175630: 9.871106\n",
            "Loss after iteration 175640: 10.049447\n",
            "Loss after iteration 175650: 9.510780\n",
            "Loss after iteration 175660: 10.122952\n",
            "Loss after iteration 175670: 9.685099\n",
            "Loss after iteration 175680: 9.721234\n",
            "Loss after iteration 175690: 9.712488\n",
            "Loss after iteration 175700: 9.516748\n",
            "Loss after iteration 175710: 9.720058\n",
            "Loss after iteration 175720: 10.088867\n",
            "Loss after iteration 175730: 9.583964\n",
            "Loss after iteration 175740: 9.556631\n",
            "Loss after iteration 175750: 9.291060\n",
            "Loss after iteration 175760: 10.283486\n",
            "Loss after iteration 175770: 9.510841\n",
            "Loss after iteration 175780: 9.101001\n",
            "Loss after iteration 175790: 9.837956\n",
            "Loss after iteration 175800: 9.633008\n",
            "Loss after iteration 175810: 9.449245\n",
            "Loss after iteration 175820: 9.342342\n",
            "Loss after iteration 175830: 9.425565\n",
            "Loss after iteration 175840: 9.426862\n",
            "Loss after iteration 175850: 9.846286\n",
            "Loss after iteration 175860: 9.938094\n",
            "Loss after iteration 175870: 10.419951\n",
            "Loss after iteration 175880: 9.196348\n",
            "Loss after iteration 175890: 9.366531\n",
            "Loss after iteration 175900: 9.456765\n",
            "Loss after iteration 175910: 9.321671\n",
            "Loss after iteration 175920: 9.470922\n",
            "Loss after iteration 175930: 10.089685\n",
            "Loss after iteration 175940: 9.688410\n",
            "Loss after iteration 175950: 9.442869\n",
            "Loss after iteration 175960: 9.856260\n",
            "Loss after iteration 175970: 9.892984\n",
            "Loss after iteration 175980: 9.622320\n",
            "Loss after iteration 175990: 9.968534\n",
            "Loss after iteration 176000: 10.117679\n",
            "Loss after iteration 176010: 10.320044\n",
            "Loss after iteration 176020: 9.839820\n",
            "Loss after iteration 176030: 9.929774\n",
            "Loss after iteration 176040: 9.092658\n",
            "Loss after iteration 176050: 9.520994\n",
            "Loss after iteration 176060: 9.748572\n",
            "Loss after iteration 176070: 9.328406\n",
            "Loss after iteration 176080: 10.025574\n",
            "Loss after iteration 176090: 9.653381\n",
            "Loss after iteration 176100: 10.158626\n",
            "Loss after iteration 176110: 9.330387\n",
            "Loss after iteration 176120: 9.901771\n",
            "Loss after iteration 176130: 9.196580\n",
            "Loss after iteration 176140: 9.335215\n",
            "Loss after iteration 176150: 9.353923\n",
            "Loss after iteration 176160: 9.640366\n",
            "Loss after iteration 176170: 10.231710\n",
            "Loss after iteration 176180: 10.452997\n",
            "Loss after iteration 176190: 9.452683\n",
            "Loss after iteration 176200: 10.696031\n",
            "Loss after iteration 176210: 9.307207\n",
            "Loss after iteration 176220: 9.204470\n",
            "Loss after iteration 176230: 9.583962\n",
            "Loss after iteration 176240: 9.370176\n",
            "Loss after iteration 176250: 9.942975\n",
            "Loss after iteration 176260: 9.485773\n",
            "Loss after iteration 176270: 9.283240\n",
            "Loss after iteration 176280: 9.712808\n",
            "Loss after iteration 176290: 9.397184\n",
            "Loss after iteration 176300: 9.813146\n",
            "Loss after iteration 176310: 9.723440\n",
            "Loss after iteration 176320: 9.526324\n",
            "Loss after iteration 176330: 9.297531\n",
            "Loss after iteration 176340: 10.207003\n",
            "Loss after iteration 176350: 9.673970\n",
            "Loss after iteration 176360: 9.023354\n",
            "Loss after iteration 176370: 9.363613\n",
            "Loss after iteration 176380: 9.787638\n",
            "Loss after iteration 176390: 9.570357\n",
            "Loss after iteration 176400: 9.551264\n",
            "Loss after iteration 176410: 10.167161\n",
            "Loss after iteration 176420: 9.891242\n",
            "Loss after iteration 176430: 10.005713\n",
            "Loss after iteration 176440: 9.407468\n",
            "Loss after iteration 176450: 9.513697\n",
            "Loss after iteration 176460: 9.451468\n",
            "Loss after iteration 176470: 9.782099\n",
            "Loss after iteration 176480: 9.804200\n",
            "Loss after iteration 176490: 9.496004\n",
            "Loss after iteration 176500: 10.297494\n",
            "Loss after iteration 176510: 9.498965\n",
            "Loss after iteration 176520: 9.550434\n",
            "Loss after iteration 176530: 10.163568\n",
            "Loss after iteration 176540: 9.681251\n",
            "Loss after iteration 176550: 9.221706\n",
            "Loss after iteration 176560: 9.431722\n",
            "Loss after iteration 176570: 9.156232\n",
            "Loss after iteration 176580: 9.369447\n",
            "Loss after iteration 176590: 9.692635\n",
            "Loss after iteration 176600: 9.438011\n",
            "Loss after iteration 176610: 9.447712\n",
            "Loss after iteration 176620: 9.605919\n",
            "Loss after iteration 176630: 9.190022\n",
            "Loss after iteration 176640: 10.229424\n",
            "Loss after iteration 176650: 9.487854\n",
            "Loss after iteration 176660: 9.458513\n",
            "Loss after iteration 176670: 10.202712\n",
            "Loss after iteration 176680: 10.540746\n",
            "Loss after iteration 176690: 10.301103\n",
            "Loss after iteration 176700: 9.605811\n",
            "Loss after iteration 176710: 9.734952\n",
            "Loss after iteration 176720: 9.188100\n",
            "Loss after iteration 176730: 10.122211\n",
            "Loss after iteration 176740: 9.232654\n",
            "Loss after iteration 176750: 9.339367\n",
            "Loss after iteration 176760: 9.588698\n",
            "Loss after iteration 176770: 9.370571\n",
            "Loss after iteration 176780: 9.076417\n",
            "Loss after iteration 176790: 9.391161\n",
            "Loss after iteration 176800: 9.366563\n",
            "Loss after iteration 176810: 9.284643\n",
            "Loss after iteration 176820: 9.378401\n",
            "Loss after iteration 176830: 9.952771\n",
            "Loss after iteration 176840: 9.411312\n",
            "Loss after iteration 176850: 9.519999\n",
            "Loss after iteration 176860: 9.915529\n",
            "Loss after iteration 176870: 9.415099\n",
            "Loss after iteration 176880: 9.519152\n",
            "Loss after iteration 176890: 10.000515\n",
            "Loss after iteration 176900: 9.640847\n",
            "Loss after iteration 176910: 9.301234\n",
            "Loss after iteration 176920: 9.500065\n",
            "Loss after iteration 176930: 9.870054\n",
            "Loss after iteration 176940: 10.074827\n",
            "Loss after iteration 176950: 10.350320\n",
            "Loss after iteration 176960: 9.989030\n",
            "Loss after iteration 176970: 9.319673\n",
            "Loss after iteration 176980: 9.205496\n",
            "Loss after iteration 176990: 9.152423\n",
            "Loss after iteration 177000: 9.067699\n",
            "Loss after iteration 177010: 9.213505\n",
            "Loss after iteration 177020: 9.162673\n",
            "Loss after iteration 177030: 9.986882\n",
            "Loss after iteration 177040: 9.225574\n",
            "Loss after iteration 177050: 10.013505\n",
            "Loss after iteration 177060: 9.652462\n",
            "Loss after iteration 177070: 10.014149\n",
            "Loss after iteration 177080: 9.435168\n",
            "Loss after iteration 177090: 9.604529\n",
            "Loss after iteration 177100: 9.539164\n",
            "Loss after iteration 177110: 9.351444\n",
            "Loss after iteration 177120: 9.474987\n",
            "Loss after iteration 177130: 9.588760\n",
            "Loss after iteration 177140: 9.476270\n",
            "Loss after iteration 177150: 9.357097\n",
            "Loss after iteration 177160: 9.435916\n",
            "Loss after iteration 177170: 10.017668\n",
            "Loss after iteration 177180: 9.618691\n",
            "Loss after iteration 177190: 9.418601\n",
            "Loss after iteration 177200: 9.781329\n",
            "Loss after iteration 177210: 9.810020\n",
            "Loss after iteration 177220: 9.814564\n",
            "Loss after iteration 177230: 9.662701\n",
            "Loss after iteration 177240: 9.315702\n",
            "Loss after iteration 177250: 9.582007\n",
            "Loss after iteration 177260: 9.646745\n",
            "Loss after iteration 177270: 9.609777\n",
            "Loss after iteration 177280: 9.327799\n",
            "Loss after iteration 177290: 9.877020\n",
            "Loss after iteration 177300: 10.280732\n",
            "Loss after iteration 177310: 9.221520\n",
            "Loss after iteration 177320: 10.873217\n",
            "Loss after iteration 177330: 9.518806\n",
            "Loss after iteration 177340: 9.164566\n",
            "Loss after iteration 177350: 9.138033\n",
            "Loss after iteration 177360: 8.982424\n",
            "Loss after iteration 177370: 9.703339\n",
            "Loss after iteration 177380: 10.222671\n",
            "Loss after iteration 177390: 9.526699\n",
            "Loss after iteration 177400: 9.708694\n",
            "Loss after iteration 177410: 9.669820\n",
            "Loss after iteration 177420: 9.678254\n",
            "Loss after iteration 177430: 9.959318\n",
            "Loss after iteration 177440: 9.449773\n",
            "Loss after iteration 177450: 9.884240\n",
            "Loss after iteration 177460: 10.043473\n",
            "Loss after iteration 177470: 9.267086\n",
            "Loss after iteration 177480: 9.467915\n",
            "Loss after iteration 177490: 9.468879\n",
            "Loss after iteration 177500: 9.139285\n",
            "Loss after iteration 177510: 9.163681\n",
            "Loss after iteration 177520: 9.283258\n",
            "Loss after iteration 177530: 9.968967\n",
            "Loss after iteration 177540: 9.083831\n",
            "Loss after iteration 177550: 9.550457\n",
            "Loss after iteration 177560: 9.301729\n",
            "Loss after iteration 177570: 9.317605\n",
            "Loss after iteration 177580: 10.446498\n",
            "Loss after iteration 177590: 9.896278\n",
            "Loss after iteration 177600: 9.407305\n",
            "Loss after iteration 177610: 9.692974\n",
            "Loss after iteration 177620: 9.465387\n",
            "Loss after iteration 177630: 9.539595\n",
            "Loss after iteration 177640: 9.593049\n",
            "Loss after iteration 177650: 9.685974\n",
            "Loss after iteration 177660: 10.014790\n",
            "Loss after iteration 177670: 9.345361\n",
            "Loss after iteration 177680: 10.189446\n",
            "Loss after iteration 177690: 9.864513\n",
            "Loss after iteration 177700: 10.031517\n",
            "Loss after iteration 177710: 9.648517\n",
            "Loss after iteration 177720: 9.441294\n",
            "Loss after iteration 177730: 9.801548\n",
            "Loss after iteration 177740: 9.827407\n",
            "Loss after iteration 177750: 10.636777\n",
            "Loss after iteration 177760: 9.665323\n",
            "Loss after iteration 177770: 10.220139\n",
            "Loss after iteration 177780: 9.565032\n",
            "Loss after iteration 177790: 10.106796\n",
            "Loss after iteration 177800: 10.156341\n",
            "Loss after iteration 177810: 9.756492\n",
            "Loss after iteration 177820: 9.484032\n",
            "Loss after iteration 177830: 10.039205\n",
            "Loss after iteration 177840: 9.248375\n",
            "Loss after iteration 177850: 9.316777\n",
            "Loss after iteration 177860: 9.296398\n",
            "Loss after iteration 177870: 9.429345\n",
            "Loss after iteration 177880: 9.891919\n",
            "Loss after iteration 177890: 9.205626\n",
            "Loss after iteration 177900: 9.604303\n",
            "Loss after iteration 177910: 9.847619\n",
            "Loss after iteration 177920: 8.815821\n",
            "Loss after iteration 177930: 9.618685\n",
            "Loss after iteration 177940: 9.188645\n",
            "Loss after iteration 177950: 9.987459\n",
            "Loss after iteration 177960: 9.866007\n",
            "Loss after iteration 177970: 10.047304\n",
            "Loss after iteration 177980: 9.669663\n",
            "Loss after iteration 177990: 9.166292\n",
            "Loss after iteration 178000: 10.289203\n",
            "Loss after iteration 178010: 9.101565\n",
            "Loss after iteration 178020: 10.359069\n",
            "Loss after iteration 178030: 9.246921\n",
            "Loss after iteration 178040: 9.489538\n",
            "Loss after iteration 178050: 9.591190\n",
            "Loss after iteration 178060: 9.516222\n",
            "Loss after iteration 178070: 10.106559\n",
            "Loss after iteration 178080: 9.863120\n",
            "Loss after iteration 178090: 9.335397\n",
            "Loss after iteration 178100: 9.793390\n",
            "Loss after iteration 178110: 9.174346\n",
            "Loss after iteration 178120: 9.586626\n",
            "Loss after iteration 178130: 9.876027\n",
            "Loss after iteration 178140: 9.978190\n",
            "Loss after iteration 178150: 9.649525\n",
            "Loss after iteration 178160: 9.418946\n",
            "Loss after iteration 178170: 9.935966\n",
            "Loss after iteration 178180: 10.529548\n",
            "Loss after iteration 178190: 9.877483\n",
            "Loss after iteration 178200: 9.734498\n",
            "Loss after iteration 178210: 9.499246\n",
            "Loss after iteration 178220: 9.582570\n",
            "Loss after iteration 178230: 9.797924\n",
            "Loss after iteration 178240: 10.403665\n",
            "Loss after iteration 178250: 9.263758\n",
            "Loss after iteration 178260: 9.428432\n",
            "Loss after iteration 178270: 9.246300\n",
            "Loss after iteration 178280: 9.141327\n",
            "Loss after iteration 178290: 9.243257\n",
            "Loss after iteration 178300: 9.891222\n",
            "Loss after iteration 178310: 10.247947\n",
            "Loss after iteration 178320: 10.672010\n",
            "Loss after iteration 178330: 9.766493\n",
            "Loss after iteration 178340: 10.278332\n",
            "Loss after iteration 178350: 9.349687\n",
            "Loss after iteration 178360: 9.541575\n",
            "Loss after iteration 178370: 10.087735\n",
            "Loss after iteration 178380: 9.022720\n",
            "Loss after iteration 178390: 9.292051\n",
            "Loss after iteration 178400: 9.351564\n",
            "Loss after iteration 178410: 9.692731\n",
            "Loss after iteration 178420: 9.718701\n",
            "Loss after iteration 178430: 9.261314\n",
            "Loss after iteration 178440: 9.713004\n",
            "Loss after iteration 178450: 10.038034\n",
            "Loss after iteration 178460: 9.699155\n",
            "Loss after iteration 178470: 9.359864\n",
            "Loss after iteration 178480: 9.709985\n",
            "Loss after iteration 178490: 9.363160\n",
            "Loss after iteration 178500: 9.144746\n",
            "Loss after iteration 178510: 9.374902\n",
            "Loss after iteration 178520: 9.471821\n",
            "Loss after iteration 178530: 9.211963\n",
            "Loss after iteration 178540: 9.326539\n",
            "Loss after iteration 178550: 9.561134\n",
            "Loss after iteration 178560: 10.199192\n",
            "Loss after iteration 178570: 9.813459\n",
            "Loss after iteration 178580: 9.824249\n",
            "Loss after iteration 178590: 9.390589\n",
            "Loss after iteration 178600: 9.854707\n",
            "Loss after iteration 178610: 9.611403\n",
            "Loss after iteration 178620: 9.691609\n",
            "Loss after iteration 178630: 9.683122\n",
            "Loss after iteration 178640: 9.656023\n",
            "Loss after iteration 178650: 9.877915\n",
            "Loss after iteration 178660: 9.875026\n",
            "Loss after iteration 178670: 9.561993\n",
            "Loss after iteration 178680: 9.888136\n",
            "Loss after iteration 178690: 9.196370\n",
            "Loss after iteration 178700: 9.231526\n",
            "Loss after iteration 178710: 9.431152\n",
            "Loss after iteration 178720: 9.484273\n",
            "Loss after iteration 178730: 9.687489\n",
            "Loss after iteration 178740: 10.139637\n",
            "Loss after iteration 178750: 9.204561\n",
            "Loss after iteration 178760: 9.811049\n",
            "Loss after iteration 178770: 9.911449\n",
            "Loss after iteration 178780: 10.079895\n",
            "Loss after iteration 178790: 9.514540\n",
            "Loss after iteration 178800: 9.622160\n",
            "Loss after iteration 178810: 9.743085\n",
            "Loss after iteration 178820: 10.018127\n",
            "Loss after iteration 178830: 9.648105\n",
            "Loss after iteration 178840: 9.415408\n",
            "Loss after iteration 178850: 9.787014\n",
            "Loss after iteration 178860: 9.308746\n",
            "Loss after iteration 178870: 9.868471\n",
            "Loss after iteration 178880: 9.450085\n",
            "Loss after iteration 178890: 10.451712\n",
            "Loss after iteration 178900: 9.365901\n",
            "Loss after iteration 178910: 9.625730\n",
            "Loss after iteration 178920: 9.460585\n",
            "Loss after iteration 178930: 9.563084\n",
            "Loss after iteration 178940: 10.086870\n",
            "Loss after iteration 178950: 9.173337\n",
            "Loss after iteration 178960: 9.573685\n",
            "Loss after iteration 178970: 9.425672\n",
            "Loss after iteration 178980: 10.130588\n",
            "Loss after iteration 178990: 9.197247\n",
            "Loss after iteration 179000: 9.176130\n",
            "Loss after iteration 179010: 9.738802\n",
            "Loss after iteration 179020: 9.673442\n",
            "Loss after iteration 179030: 9.198451\n",
            "Loss after iteration 179040: 9.493267\n",
            "Loss after iteration 179050: 9.291577\n",
            "Loss after iteration 179060: 9.522424\n",
            "Loss after iteration 179070: 9.807970\n",
            "Loss after iteration 179080: 10.267821\n",
            "Loss after iteration 179090: 9.582283\n",
            "Loss after iteration 179100: 9.266738\n",
            "Loss after iteration 179110: 9.504338\n",
            "Loss after iteration 179120: 9.609725\n",
            "Loss after iteration 179130: 9.757715\n",
            "Loss after iteration 179140: 10.107359\n",
            "Loss after iteration 179150: 9.591638\n",
            "Loss after iteration 179160: 9.557487\n",
            "Loss after iteration 179170: 9.532565\n",
            "Loss after iteration 179180: 9.411602\n",
            "Loss after iteration 179190: 9.375620\n",
            "Loss after iteration 179200: 9.355209\n",
            "Loss after iteration 179210: 10.282701\n",
            "Loss after iteration 179220: 10.001732\n",
            "Loss after iteration 179230: 9.338842\n",
            "Loss after iteration 179240: 9.647593\n",
            "Loss after iteration 179250: 9.677753\n",
            "Loss after iteration 179260: 10.739046\n",
            "Loss after iteration 179270: 9.476061\n",
            "Loss after iteration 179280: 9.498211\n",
            "Loss after iteration 179290: 10.127510\n",
            "Loss after iteration 179300: 9.335366\n",
            "Loss after iteration 179310: 9.304392\n",
            "Loss after iteration 179320: 9.634492\n",
            "Loss after iteration 179330: 10.084330\n",
            "Loss after iteration 179340: 9.583354\n",
            "Loss after iteration 179350: 9.217106\n",
            "Loss after iteration 179360: 9.699423\n",
            "Loss after iteration 179370: 9.640376\n",
            "Loss after iteration 179380: 9.478208\n",
            "Loss after iteration 179390: 9.763396\n",
            "Loss after iteration 179400: 9.996978\n",
            "Loss after iteration 179410: 9.249227\n",
            "Loss after iteration 179420: 9.283274\n",
            "Loss after iteration 179430: 9.603760\n",
            "Loss after iteration 179440: 9.107506\n",
            "Loss after iteration 179450: 9.954731\n",
            "Loss after iteration 179460: 9.487074\n",
            "Loss after iteration 179470: 10.247403\n",
            "Loss after iteration 179480: 9.275731\n",
            "Loss after iteration 179490: 9.821669\n",
            "Loss after iteration 179500: 9.292012\n",
            "Loss after iteration 179510: 9.920161\n",
            "Loss after iteration 179520: 9.401892\n",
            "Loss after iteration 179530: 9.302964\n",
            "Loss after iteration 179540: 9.575540\n",
            "Loss after iteration 179550: 9.087369\n",
            "Loss after iteration 179560: 9.352661\n",
            "Loss after iteration 179570: 9.349928\n",
            "Loss after iteration 179580: 8.880933\n",
            "Loss after iteration 179590: 9.037738\n",
            "Loss after iteration 179600: 9.417464\n",
            "Loss after iteration 179610: 9.349195\n",
            "Loss after iteration 179620: 9.711183\n",
            "Loss after iteration 179630: 9.229822\n",
            "Loss after iteration 179640: 9.404415\n",
            "Loss after iteration 179650: 9.725726\n",
            "Loss after iteration 179660: 9.574713\n",
            "Loss after iteration 179670: 9.900571\n",
            "Loss after iteration 179680: 11.292916\n",
            "Loss after iteration 179690: 9.479930\n",
            "Loss after iteration 179700: 9.759428\n",
            "Loss after iteration 179710: 9.862105\n",
            "Loss after iteration 179720: 9.358649\n",
            "Loss after iteration 179730: 9.769194\n",
            "Loss after iteration 179740: 9.888730\n",
            "Loss after iteration 179750: 9.934894\n",
            "Loss after iteration 179760: 9.422141\n",
            "Loss after iteration 179770: 9.616929\n",
            "Loss after iteration 179780: 10.334379\n",
            "Loss after iteration 179790: 10.255511\n",
            "Loss after iteration 179800: 9.488347\n",
            "Loss after iteration 179810: 9.621195\n",
            "Loss after iteration 179820: 9.442057\n",
            "Loss after iteration 179830: 9.751564\n",
            "Loss after iteration 179840: 9.519679\n",
            "Loss after iteration 179850: 9.678658\n",
            "Loss after iteration 179860: 9.703042\n",
            "Loss after iteration 179870: 9.836855\n",
            "Loss after iteration 179880: 9.877328\n",
            "Loss after iteration 179890: 9.286955\n",
            "Loss after iteration 179900: 9.327600\n",
            "Loss after iteration 179910: 9.960855\n",
            "Loss after iteration 179920: 9.373813\n",
            "Loss after iteration 179930: 9.619793\n",
            "Loss after iteration 179940: 10.850678\n",
            "Loss after iteration 179950: 10.304677\n",
            "Loss after iteration 179960: 9.657588\n",
            "Loss after iteration 179970: 10.146243\n",
            "Loss after iteration 179980: 9.943938\n",
            "Loss after iteration 179990: 9.631518\n",
            "Loss after iteration 180000: 10.050767\n",
            "Loss after iteration 180010: 9.911132\n",
            "Loss after iteration 180020: 9.551969\n",
            "Loss after iteration 180030: 9.747073\n",
            "Loss after iteration 180040: 10.103532\n",
            "Loss after iteration 180050: 9.966289\n",
            "Loss after iteration 180060: 9.689302\n",
            "Loss after iteration 180070: 9.329833\n",
            "Loss after iteration 180080: 9.572397\n",
            "Loss after iteration 180090: 9.466906\n",
            "Loss after iteration 180100: 9.992663\n",
            "Loss after iteration 180110: 9.620300\n",
            "Loss after iteration 180120: 9.882588\n",
            "Loss after iteration 180130: 9.584361\n",
            "Loss after iteration 180140: 9.476709\n",
            "Loss after iteration 180150: 10.350258\n",
            "Loss after iteration 180160: 9.535810\n",
            "Loss after iteration 180170: 9.509092\n",
            "Loss after iteration 180180: 9.347690\n",
            "Loss after iteration 180190: 9.431749\n",
            "Loss after iteration 180200: 9.485811\n",
            "Loss after iteration 180210: 10.441063\n",
            "Loss after iteration 180220: 10.084527\n",
            "Loss after iteration 180230: 9.978667\n",
            "Loss after iteration 180240: 10.129574\n",
            "Loss after iteration 180250: 9.301593\n",
            "Loss after iteration 180260: 9.503875\n",
            "Loss after iteration 180270: 9.374104\n",
            "Loss after iteration 180280: 10.339066\n",
            "Loss after iteration 180290: 9.357881\n",
            "Loss after iteration 180300: 9.542161\n",
            "Loss after iteration 180310: 9.421351\n",
            "Loss after iteration 180320: 9.466467\n",
            "Loss after iteration 180330: 9.525234\n",
            "Loss after iteration 180340: 10.279108\n",
            "Loss after iteration 180350: 9.328670\n",
            "Loss after iteration 180360: 9.904718\n",
            "Loss after iteration 180370: 9.652082\n",
            "Loss after iteration 180380: 9.852025\n",
            "Loss after iteration 180390: 9.516428\n",
            "Loss after iteration 180400: 9.722320\n",
            "Loss after iteration 180410: 9.307498\n",
            "Loss after iteration 180420: 9.240183\n",
            "Loss after iteration 180430: 9.508022\n",
            "Loss after iteration 180440: 9.524871\n",
            "Loss after iteration 180450: 9.565438\n",
            "Loss after iteration 180460: 9.607026\n",
            "Loss after iteration 180470: 9.623055\n",
            "Loss after iteration 180480: 9.860167\n",
            "Loss after iteration 180490: 9.439309\n",
            "Loss after iteration 180500: 9.767102\n",
            "Loss after iteration 180510: 9.486728\n",
            "Loss after iteration 180520: 9.625523\n",
            "Loss after iteration 180530: 9.664687\n",
            "Loss after iteration 180540: 10.090518\n",
            "Loss after iteration 180550: 9.753868\n",
            "Loss after iteration 180560: 9.573612\n",
            "Loss after iteration 180570: 9.601958\n",
            "Loss after iteration 180580: 10.171946\n",
            "Loss after iteration 180590: 9.243252\n",
            "Loss after iteration 180600: 9.584999\n",
            "Loss after iteration 180610: 9.500815\n",
            "Loss after iteration 180620: 9.508846\n",
            "Loss after iteration 180630: 9.941388\n",
            "Loss after iteration 180640: 9.756465\n",
            "Loss after iteration 180650: 9.612229\n",
            "Loss after iteration 180660: 9.287858\n",
            "Loss after iteration 180670: 9.306857\n",
            "Loss after iteration 180680: 10.190008\n",
            "Loss after iteration 180690: 9.926207\n",
            "Loss after iteration 180700: 9.628905\n",
            "Loss after iteration 180710: 9.174801\n",
            "Loss after iteration 180720: 9.252711\n",
            "Loss after iteration 180730: 9.730955\n",
            "Loss after iteration 180740: 9.938111\n",
            "Loss after iteration 180750: 10.234815\n",
            "Loss after iteration 180760: 9.401549\n",
            "Loss after iteration 180770: 9.983451\n",
            "Loss after iteration 180780: 10.449177\n",
            "Loss after iteration 180790: 9.916181\n",
            "Loss after iteration 180800: 10.157077\n",
            "Loss after iteration 180810: 9.666032\n",
            "Loss after iteration 180820: 10.076481\n",
            "Loss after iteration 180830: 9.492145\n",
            "Loss after iteration 180840: 9.806281\n",
            "Loss after iteration 180850: 9.694980\n",
            "Loss after iteration 180860: 9.615400\n",
            "Loss after iteration 180870: 9.977488\n",
            "Loss after iteration 180880: 9.711803\n",
            "Loss after iteration 180890: 9.956706\n",
            "Loss after iteration 180900: 9.533383\n",
            "Loss after iteration 180910: 9.435187\n",
            "Loss after iteration 180920: 9.561349\n",
            "Loss after iteration 180930: 9.213450\n",
            "Loss after iteration 180940: 9.553327\n",
            "Loss after iteration 180950: 9.440813\n",
            "Loss after iteration 180960: 9.287060\n",
            "Loss after iteration 180970: 9.821568\n",
            "Loss after iteration 180980: 9.738223\n",
            "Loss after iteration 180990: 9.513535\n",
            "Loss after iteration 181000: 9.915655\n",
            "Loss after iteration 181010: 9.862617\n",
            "Loss after iteration 181020: 9.315719\n",
            "Loss after iteration 181030: 9.651631\n",
            "Loss after iteration 181040: 9.465780\n",
            "Loss after iteration 181050: 9.702733\n",
            "Loss after iteration 181060: 9.498381\n",
            "Loss after iteration 181070: 9.236557\n",
            "Loss after iteration 181080: 9.405691\n",
            "Loss after iteration 181090: 9.470839\n",
            "Loss after iteration 181100: 10.131076\n",
            "Loss after iteration 181110: 9.707526\n",
            "Loss after iteration 181120: 9.448025\n",
            "Loss after iteration 181130: 9.584823\n",
            "Loss after iteration 181140: 9.341221\n",
            "Loss after iteration 181150: 9.227081\n",
            "Loss after iteration 181160: 9.819275\n",
            "Loss after iteration 181170: 9.490964\n",
            "Loss after iteration 181180: 9.236718\n",
            "Loss after iteration 181190: 9.399749\n",
            "Loss after iteration 181200: 9.380462\n",
            "Loss after iteration 181210: 10.252376\n",
            "Loss after iteration 181220: 9.311020\n",
            "Loss after iteration 181230: 9.519701\n",
            "Loss after iteration 181240: 9.656377\n",
            "Loss after iteration 181250: 9.114376\n",
            "Loss after iteration 181260: 9.135708\n",
            "Loss after iteration 181270: 9.344975\n",
            "Loss after iteration 181280: 9.925748\n",
            "Loss after iteration 181290: 9.439310\n",
            "Loss after iteration 181300: 9.171357\n",
            "Loss after iteration 181310: 9.385557\n",
            "Loss after iteration 181320: 9.652583\n",
            "Loss after iteration 181330: 9.665989\n",
            "Loss after iteration 181340: 9.571974\n",
            "Loss after iteration 181350: 9.272887\n",
            "Loss after iteration 181360: 9.664672\n",
            "Loss after iteration 181370: 9.768660\n",
            "Loss after iteration 181380: 9.697280\n",
            "Loss after iteration 181390: 10.540427\n",
            "Loss after iteration 181400: 9.424361\n",
            "Loss after iteration 181410: 9.708476\n",
            "Loss after iteration 181420: 9.464182\n",
            "Loss after iteration 181430: 9.414763\n",
            "Loss after iteration 181440: 9.821658\n",
            "Loss after iteration 181450: 9.623493\n",
            "Loss after iteration 181460: 9.535236\n",
            "Loss after iteration 181470: 9.550114\n",
            "Loss after iteration 181480: 10.117150\n",
            "Loss after iteration 181490: 9.541698\n",
            "Loss after iteration 181500: 9.638731\n",
            "Loss after iteration 181510: 9.601379\n",
            "Loss after iteration 181520: 9.382981\n",
            "Loss after iteration 181530: 9.584142\n",
            "Loss after iteration 181540: 10.031047\n",
            "Loss after iteration 181550: 9.138012\n",
            "Loss after iteration 181560: 9.329796\n",
            "Loss after iteration 181570: 9.223019\n",
            "Loss after iteration 181580: 9.356789\n",
            "Loss after iteration 181590: 9.499130\n",
            "Loss after iteration 181600: 9.722985\n",
            "Loss after iteration 181610: 9.983570\n",
            "Loss after iteration 181620: 9.316112\n",
            "Loss after iteration 181630: 9.147242\n",
            "Loss after iteration 181640: 9.463221\n",
            "Loss after iteration 181650: 10.140056\n",
            "Loss after iteration 181660: 9.985687\n",
            "Loss after iteration 181670: 9.555011\n",
            "Loss after iteration 181680: 9.804203\n",
            "Loss after iteration 181690: 9.581088\n",
            "Loss after iteration 181700: 9.405073\n",
            "Loss after iteration 181710: 9.331648\n",
            "Loss after iteration 181720: 9.342929\n",
            "Loss after iteration 181730: 9.116790\n",
            "Loss after iteration 181740: 9.934698\n",
            "Loss after iteration 181750: 9.238730\n",
            "Loss after iteration 181760: 9.752904\n",
            "Loss after iteration 181770: 9.914239\n",
            "Loss after iteration 181780: 9.405671\n",
            "Loss after iteration 181790: 9.692298\n",
            "Loss after iteration 181800: 9.600717\n",
            "Loss after iteration 181810: 9.690551\n",
            "Loss after iteration 181820: 9.172106\n",
            "Loss after iteration 181830: 9.239712\n",
            "Loss after iteration 181840: 10.236437\n",
            "Loss after iteration 181850: 9.295981\n",
            "Loss after iteration 181860: 9.337674\n",
            "Loss after iteration 181870: 9.719239\n",
            "Loss after iteration 181880: 10.073245\n",
            "Loss after iteration 181890: 9.259654\n",
            "Loss after iteration 181900: 10.800448\n",
            "Loss after iteration 181910: 9.838333\n",
            "Loss after iteration 181920: 10.113461\n",
            "Loss after iteration 181930: 10.266350\n",
            "Loss after iteration 181940: 9.928045\n",
            "Loss after iteration 181950: 10.235133\n",
            "Loss after iteration 181960: 10.018911\n",
            "Loss after iteration 181970: 9.677646\n",
            "Loss after iteration 181980: 10.081314\n",
            "Loss after iteration 181990: 9.397718\n",
            "Loss after iteration 182000: 9.718895\n",
            "Loss after iteration 182010: 9.506804\n",
            "Loss after iteration 182020: 9.812796\n",
            "Loss after iteration 182030: 10.153974\n",
            "Loss after iteration 182040: 10.135179\n",
            "Loss after iteration 182050: 9.418457\n",
            "Loss after iteration 182060: 10.197426\n",
            "Loss after iteration 182070: 9.234862\n",
            "Loss after iteration 182080: 9.489210\n",
            "Loss after iteration 182090: 9.295095\n",
            "Loss after iteration 182100: 9.501314\n",
            "Loss after iteration 182110: 9.646347\n",
            "Loss after iteration 182120: 9.440104\n",
            "Loss after iteration 182130: 9.852930\n",
            "Loss after iteration 182140: 9.452846\n",
            "Loss after iteration 182150: 9.658995\n",
            "Loss after iteration 182160: 9.757454\n",
            "Loss after iteration 182170: 9.493181\n",
            "Loss after iteration 182180: 9.476775\n",
            "Loss after iteration 182190: 10.141413\n",
            "Loss after iteration 182200: 9.327529\n",
            "Loss after iteration 182210: 9.622915\n",
            "Loss after iteration 182220: 9.699712\n",
            "Loss after iteration 182230: 10.096236\n",
            "Loss after iteration 182240: 9.919137\n",
            "Loss after iteration 182250: 9.657382\n",
            "Loss after iteration 182260: 9.712291\n",
            "Loss after iteration 182270: 9.444073\n",
            "Loss after iteration 182280: 9.349323\n",
            "Loss after iteration 182290: 10.256365\n",
            "Loss after iteration 182300: 9.857495\n",
            "Loss after iteration 182310: 9.605552\n",
            "Loss after iteration 182320: 9.642172\n",
            "Loss after iteration 182330: 9.397362\n",
            "Loss after iteration 182340: 9.651672\n",
            "Loss after iteration 182350: 10.051768\n",
            "Loss after iteration 182360: 10.001287\n",
            "Loss after iteration 182370: 9.267336\n",
            "Loss after iteration 182380: 9.779467\n",
            "Loss after iteration 182390: 9.192803\n",
            "Loss after iteration 182400: 9.449084\n",
            "Loss after iteration 182410: 9.952542\n",
            "Loss after iteration 182420: 9.447140\n",
            "Loss after iteration 182430: 9.634651\n",
            "Loss after iteration 182440: 9.485212\n",
            "Loss after iteration 182450: 9.267957\n",
            "Loss after iteration 182460: 9.811353\n",
            "Loss after iteration 182470: 9.824628\n",
            "Loss after iteration 182480: 10.034996\n",
            "Loss after iteration 182490: 9.907102\n",
            "Loss after iteration 182500: 9.357318\n",
            "Loss after iteration 182510: 9.771796\n",
            "Loss after iteration 182520: 9.754784\n",
            "Loss after iteration 182530: 9.362758\n",
            "Loss after iteration 182540: 10.329991\n",
            "Loss after iteration 182550: 9.900804\n",
            "Loss after iteration 182560: 9.357161\n",
            "Loss after iteration 182570: 9.743415\n",
            "Loss after iteration 182580: 9.685615\n",
            "Loss after iteration 182590: 9.587799\n",
            "Loss after iteration 182600: 10.103133\n",
            "Loss after iteration 182610: 10.405882\n",
            "Loss after iteration 182620: 10.345047\n",
            "Loss after iteration 182630: 9.352826\n",
            "Loss after iteration 182640: 9.444918\n",
            "Loss after iteration 182650: 9.542396\n",
            "Loss after iteration 182660: 9.498606\n",
            "Loss after iteration 182670: 9.134748\n",
            "Loss after iteration 182680: 9.996262\n",
            "Loss after iteration 182690: 9.460479\n",
            "Loss after iteration 182700: 9.634602\n",
            "Loss after iteration 182710: 9.165169\n",
            "Loss after iteration 182720: 9.577996\n",
            "Loss after iteration 182730: 9.214727\n",
            "Loss after iteration 182740: 9.465607\n",
            "Loss after iteration 182750: 9.391243\n",
            "Loss after iteration 182760: 9.536452\n",
            "Loss after iteration 182770: 9.817757\n",
            "Loss after iteration 182780: 9.544082\n",
            "Loss after iteration 182790: 9.704441\n",
            "Loss after iteration 182800: 9.440890\n",
            "Loss after iteration 182810: 10.386814\n",
            "Loss after iteration 182820: 9.936404\n",
            "Loss after iteration 182830: 9.445138\n",
            "Loss after iteration 182840: 9.200818\n",
            "Loss after iteration 182850: 9.729516\n",
            "Loss after iteration 182860: 9.491484\n",
            "Loss after iteration 182870: 8.838829\n",
            "Loss after iteration 182880: 8.844384\n",
            "Loss after iteration 182890: 9.045889\n",
            "Loss after iteration 182900: 9.171001\n",
            "Loss after iteration 182910: 9.112046\n",
            "Loss after iteration 182920: 10.107570\n",
            "Loss after iteration 182930: 9.064287\n",
            "Loss after iteration 182940: 9.605735\n",
            "Loss after iteration 182950: 9.492746\n",
            "Loss after iteration 182960: 9.487319\n",
            "Loss after iteration 182970: 9.347921\n",
            "Loss after iteration 182980: 9.804013\n",
            "Loss after iteration 182990: 9.393766\n",
            "Loss after iteration 183000: 9.920056\n",
            "Loss after iteration 183010: 9.582441\n",
            "Loss after iteration 183020: 9.646129\n",
            "Loss after iteration 183030: 10.183984\n",
            "Loss after iteration 183040: 10.097692\n",
            "Loss after iteration 183050: 9.704698\n",
            "Loss after iteration 183060: 9.874964\n",
            "Loss after iteration 183070: 9.278679\n",
            "Loss after iteration 183080: 9.624263\n",
            "Loss after iteration 183090: 10.185648\n",
            "Loss after iteration 183100: 10.371282\n",
            "Loss after iteration 183110: 9.788417\n",
            "Loss after iteration 183120: 9.308145\n",
            "Loss after iteration 183130: 9.475945\n",
            "Loss after iteration 183140: 9.542010\n",
            "Loss after iteration 183150: 9.703720\n",
            "Loss after iteration 183160: 10.045730\n",
            "Loss after iteration 183170: 10.039383\n",
            "Loss after iteration 183180: 9.622891\n",
            "Loss after iteration 183190: 10.571466\n",
            "Loss after iteration 183200: 9.605837\n",
            "Loss after iteration 183210: 9.213192\n",
            "Loss after iteration 183220: 9.735841\n",
            "Loss after iteration 183230: 10.174660\n",
            "Loss after iteration 183240: 9.135034\n",
            "Loss after iteration 183250: 9.493106\n",
            "Loss after iteration 183260: 9.997638\n",
            "Loss after iteration 183270: 9.715510\n",
            "Loss after iteration 183280: 9.447701\n",
            "Loss after iteration 183290: 9.585361\n",
            "Loss after iteration 183300: 10.560404\n",
            "Loss after iteration 183310: 10.024555\n",
            "Loss after iteration 183320: 10.066416\n",
            "Loss after iteration 183330: 10.504774\n",
            "Loss after iteration 183340: 9.876951\n",
            "Loss after iteration 183350: 9.521915\n",
            "Loss after iteration 183360: 9.861589\n",
            "Loss after iteration 183370: 10.093057\n",
            "Loss after iteration 183380: 9.652192\n",
            "Loss after iteration 183390: 9.858829\n",
            "Loss after iteration 183400: 9.318501\n",
            "Loss after iteration 183410: 9.624807\n",
            "Loss after iteration 183420: 9.820286\n",
            "Loss after iteration 183430: 9.190545\n",
            "Loss after iteration 183440: 9.089825\n",
            "Loss after iteration 183450: 9.542476\n",
            "Loss after iteration 183460: 9.241782\n",
            "Loss after iteration 183470: 9.277308\n",
            "Loss after iteration 183480: 9.540708\n",
            "Loss after iteration 183490: 9.490807\n",
            "Loss after iteration 183500: 9.398638\n",
            "Loss after iteration 183510: 9.200930\n",
            "Loss after iteration 183520: 9.073896\n",
            "Loss after iteration 183530: 9.618949\n",
            "Loss after iteration 183540: 9.944220\n",
            "Loss after iteration 183550: 9.869226\n",
            "Loss after iteration 183560: 9.329531\n",
            "Loss after iteration 183570: 9.342901\n",
            "Loss after iteration 183580: 9.419395\n",
            "Loss after iteration 183590: 9.491520\n",
            "Loss after iteration 183600: 9.293647\n",
            "Loss after iteration 183610: 9.531723\n",
            "Loss after iteration 183620: 9.807139\n",
            "Loss after iteration 183630: 9.506133\n",
            "Loss after iteration 183640: 9.575581\n",
            "Loss after iteration 183650: 9.147545\n",
            "Loss after iteration 183660: 9.450169\n",
            "Loss after iteration 183670: 10.073792\n",
            "Loss after iteration 183680: 9.547375\n",
            "Loss after iteration 183690: 9.254803\n",
            "Loss after iteration 183700: 9.658326\n",
            "Loss after iteration 183710: 9.913870\n",
            "Loss after iteration 183720: 9.512994\n",
            "Loss after iteration 183730: 9.562093\n",
            "Loss after iteration 183740: 10.063576\n",
            "Loss after iteration 183750: 9.658986\n",
            "Loss after iteration 183760: 9.687012\n",
            "Loss after iteration 183770: 9.446861\n",
            "Loss after iteration 183780: 9.290103\n",
            "Loss after iteration 183790: 10.535416\n",
            "Loss after iteration 183800: 9.476373\n",
            "Loss after iteration 183810: 10.268241\n",
            "Loss after iteration 183820: 9.476463\n",
            "Loss after iteration 183830: 9.605522\n",
            "Loss after iteration 183840: 9.310980\n",
            "Loss after iteration 183850: 9.404713\n",
            "Loss after iteration 183860: 9.258197\n",
            "Loss after iteration 183870: 9.142201\n",
            "Loss after iteration 183880: 9.322804\n",
            "Loss after iteration 183890: 9.743545\n",
            "Loss after iteration 183900: 9.196299\n",
            "Loss after iteration 183910: 9.390222\n",
            "Loss after iteration 183920: 10.439145\n",
            "Loss after iteration 183930: 9.339450\n",
            "Loss after iteration 183940: 9.855406\n",
            "Loss after iteration 183950: 9.399133\n",
            "Loss after iteration 183960: 9.429906\n",
            "Loss after iteration 183970: 9.748550\n",
            "Loss after iteration 183980: 9.805937\n",
            "Loss after iteration 183990: 9.799245\n",
            "Loss after iteration 184000: 10.151150\n",
            "Loss after iteration 184010: 9.603185\n",
            "Loss after iteration 184020: 9.320427\n",
            "Loss after iteration 184030: 9.610254\n",
            "Loss after iteration 184040: 9.481840\n",
            "Loss after iteration 184050: 9.635403\n",
            "Loss after iteration 184060: 10.297635\n",
            "Loss after iteration 184070: 9.911088\n",
            "Loss after iteration 184080: 9.331407\n",
            "Loss after iteration 184090: 10.251798\n",
            "Loss after iteration 184100: 9.309847\n",
            "Loss after iteration 184110: 9.874073\n",
            "Loss after iteration 184120: 9.500410\n",
            "Loss after iteration 184130: 9.613482\n",
            "Loss after iteration 184140: 9.127850\n",
            "Loss after iteration 184150: 9.913678\n",
            "Loss after iteration 184160: 9.564809\n",
            "Loss after iteration 184170: 9.642398\n",
            "Loss after iteration 184180: 9.435611\n",
            "Loss after iteration 184190: 9.883898\n",
            "Loss after iteration 184200: 9.737187\n",
            "Loss after iteration 184210: 9.900744\n",
            "Loss after iteration 184220: 10.040658\n",
            "Loss after iteration 184230: 10.376451\n",
            "Loss after iteration 184240: 9.451931\n",
            "Loss after iteration 184250: 10.200219\n",
            "Loss after iteration 184260: 9.799485\n",
            "Loss after iteration 184270: 9.638886\n",
            "Loss after iteration 184280: 9.142711\n",
            "Loss after iteration 184290: 10.437141\n",
            "Loss after iteration 184300: 9.751208\n",
            "Loss after iteration 184310: 9.878959\n",
            "Loss after iteration 184320: 10.088222\n",
            "Loss after iteration 184330: 9.514248\n",
            "Loss after iteration 184340: 9.299416\n",
            "Loss after iteration 184350: 10.051403\n",
            "Loss after iteration 184360: 9.549463\n",
            "Loss after iteration 184370: 9.330000\n",
            "Loss after iteration 184380: 9.415922\n",
            "Loss after iteration 184390: 9.854706\n",
            "Loss after iteration 184400: 9.346233\n",
            "Loss after iteration 184410: 9.327015\n",
            "Loss after iteration 184420: 10.395935\n",
            "Loss after iteration 184430: 9.207100\n",
            "Loss after iteration 184440: 9.493100\n",
            "Loss after iteration 184450: 9.388655\n",
            "Loss after iteration 184460: 9.125944\n",
            "Loss after iteration 184470: 9.433580\n",
            "Loss after iteration 184480: 10.829025\n",
            "Loss after iteration 184490: 9.706397\n",
            "Loss after iteration 184500: 9.700132\n",
            "Loss after iteration 184510: 9.326842\n",
            "Loss after iteration 184520: 9.344451\n",
            "Loss after iteration 184530: 9.553139\n",
            "Loss after iteration 184540: 9.794975\n",
            "Loss after iteration 184550: 9.253616\n",
            "Loss after iteration 184560: 10.113705\n",
            "Loss after iteration 184570: 9.612711\n",
            "Loss after iteration 184580: 9.657760\n",
            "Loss after iteration 184590: 10.014626\n",
            "Loss after iteration 184600: 9.401314\n",
            "Loss after iteration 184610: 9.425433\n",
            "Loss after iteration 184620: 9.800441\n",
            "Loss after iteration 184630: 9.097778\n",
            "Loss after iteration 184640: 9.996825\n",
            "Loss after iteration 184650: 9.401833\n",
            "Loss after iteration 184660: 9.927261\n",
            "Loss after iteration 184670: 9.065614\n",
            "Loss after iteration 184680: 9.691904\n",
            "Loss after iteration 184690: 9.241653\n",
            "Loss after iteration 184700: 9.736134\n",
            "Loss after iteration 184710: 9.398577\n",
            "Loss after iteration 184720: 9.722288\n",
            "Loss after iteration 184730: 9.935323\n",
            "Loss after iteration 184740: 9.579096\n",
            "Loss after iteration 184750: 10.426292\n",
            "Loss after iteration 184760: 9.292046\n",
            "Loss after iteration 184770: 9.689716\n",
            "Loss after iteration 184780: 10.842372\n",
            "Loss after iteration 184790: 9.432006\n",
            "Loss after iteration 184800: 9.479778\n",
            "Loss after iteration 184810: 9.970144\n",
            "Loss after iteration 184820: 9.332496\n",
            "Loss after iteration 184830: 10.014066\n",
            "Loss after iteration 184840: 9.491159\n",
            "Loss after iteration 184850: 10.086839\n",
            "Loss after iteration 184860: 9.520671\n",
            "Loss after iteration 184870: 9.338540\n",
            "Loss after iteration 184880: 9.229758\n",
            "Loss after iteration 184890: 9.233665\n",
            "Loss after iteration 184900: 9.253353\n",
            "Loss after iteration 184910: 9.259281\n",
            "Loss after iteration 184920: 9.332984\n",
            "Loss after iteration 184930: 9.540375\n",
            "Loss after iteration 184940: 10.389347\n",
            "Loss after iteration 184950: 9.260676\n",
            "Loss after iteration 184960: 10.188842\n",
            "Loss after iteration 184970: 10.185567\n",
            "Loss after iteration 184980: 9.520597\n",
            "Loss after iteration 184990: 9.056563\n",
            "Loss after iteration 185000: 9.878015\n",
            "Loss after iteration 185010: 10.175042\n",
            "Loss after iteration 185020: 9.733437\n",
            "Loss after iteration 185030: 9.694382\n",
            "Loss after iteration 185040: 10.336357\n",
            "Loss after iteration 185050: 9.763732\n",
            "Loss after iteration 185060: 9.593948\n",
            "Loss after iteration 185070: 9.525154\n",
            "Loss after iteration 185080: 9.319031\n",
            "Loss after iteration 185090: 9.646707\n",
            "Loss after iteration 185100: 9.856916\n",
            "Loss after iteration 185110: 9.726808\n",
            "Loss after iteration 185120: 9.679164\n",
            "Loss after iteration 185130: 9.848145\n",
            "Loss after iteration 185140: 10.211239\n",
            "Loss after iteration 185150: 10.196041\n",
            "Loss after iteration 185160: 9.468830\n",
            "Loss after iteration 185170: 9.951427\n",
            "Loss after iteration 185180: 9.294939\n",
            "Loss after iteration 185190: 9.492071\n",
            "Loss after iteration 185200: 9.564171\n",
            "Loss after iteration 185210: 9.682953\n",
            "Loss after iteration 185220: 10.002415\n",
            "Loss after iteration 185230: 9.653948\n",
            "Loss after iteration 185240: 9.439009\n",
            "Loss after iteration 185250: 9.790015\n",
            "Loss after iteration 185260: 9.762286\n",
            "Loss after iteration 185270: 9.440942\n",
            "Loss after iteration 185280: 9.580760\n",
            "Loss after iteration 185290: 9.794594\n",
            "Loss after iteration 185300: 9.894945\n",
            "Loss after iteration 185310: 9.737872\n",
            "Loss after iteration 185320: 9.117480\n",
            "Loss after iteration 185330: 9.236490\n",
            "Loss after iteration 185340: 9.288555\n",
            "Loss after iteration 185350: 9.188054\n",
            "Loss after iteration 185360: 9.486268\n",
            "Loss after iteration 185370: 10.335703\n",
            "Loss after iteration 185380: 9.476181\n",
            "Loss after iteration 185390: 10.065338\n",
            "Loss after iteration 185400: 9.444291\n",
            "Loss after iteration 185410: 10.407433\n",
            "Loss after iteration 185420: 9.930193\n",
            "Loss after iteration 185430: 9.973837\n",
            "Loss after iteration 185440: 9.326165\n",
            "Loss after iteration 185450: 10.292835\n",
            "Loss after iteration 185460: 9.883969\n",
            "Loss after iteration 185470: 9.331765\n",
            "Loss after iteration 185480: 9.221522\n",
            "Loss after iteration 185490: 9.456863\n",
            "Loss after iteration 185500: 9.344343\n",
            "Loss after iteration 185510: 9.332166\n",
            "Loss after iteration 185520: 9.302436\n",
            "Loss after iteration 185530: 10.207916\n",
            "Loss after iteration 185540: 9.272079\n",
            "Loss after iteration 185550: 9.365413\n",
            "Loss after iteration 185560: 9.667597\n",
            "Loss after iteration 185570: 9.645414\n",
            "Loss after iteration 185580: 9.573239\n",
            "Loss after iteration 185590: 10.384380\n",
            "Loss after iteration 185600: 10.306002\n",
            "Loss after iteration 185610: 9.924550\n",
            "Loss after iteration 185620: 9.253467\n",
            "Loss after iteration 185630: 9.975774\n",
            "Loss after iteration 185640: 9.241213\n",
            "Loss after iteration 185650: 9.538871\n",
            "Loss after iteration 185660: 9.462099\n",
            "Loss after iteration 185670: 9.812995\n",
            "Loss after iteration 185680: 9.598080\n",
            "Loss after iteration 185690: 9.403277\n",
            "Loss after iteration 185700: 10.336482\n",
            "Loss after iteration 185710: 9.361646\n",
            "Loss after iteration 185720: 10.386322\n",
            "Loss after iteration 185730: 9.894325\n",
            "Loss after iteration 185740: 9.841001\n",
            "Loss after iteration 185750: 10.919592\n",
            "Loss after iteration 185760: 9.816200\n",
            "Loss after iteration 185770: 9.768166\n",
            "Loss after iteration 185780: 9.547456\n",
            "Loss after iteration 185790: 9.621937\n",
            "Loss after iteration 185800: 9.758052\n",
            "Loss after iteration 185810: 10.672890\n",
            "Loss after iteration 185820: 9.509548\n",
            "Loss after iteration 185830: 9.411864\n",
            "Loss after iteration 185840: 9.474556\n",
            "Loss after iteration 185850: 9.893859\n",
            "Loss after iteration 185860: 9.910328\n",
            "Loss after iteration 185870: 9.633740\n",
            "Loss after iteration 185880: 9.933815\n",
            "Loss after iteration 185890: 9.359287\n",
            "Loss after iteration 185900: 9.599687\n",
            "Loss after iteration 185910: 9.566896\n",
            "Loss after iteration 185920: 8.994498\n",
            "Loss after iteration 185930: 9.468463\n",
            "Loss after iteration 185940: 9.388230\n",
            "Loss after iteration 185950: 9.291689\n",
            "Loss after iteration 185960: 10.182387\n",
            "Loss after iteration 185970: 9.302877\n",
            "Loss after iteration 185980: 9.744496\n",
            "Loss after iteration 185990: 9.241380\n",
            "Loss after iteration 186000: 9.423416\n",
            "Loss after iteration 186010: 9.338392\n",
            "Loss after iteration 186020: 9.926823\n",
            "Loss after iteration 186030: 9.232065\n",
            "Loss after iteration 186040: 9.403184\n",
            "Loss after iteration 186050: 9.597386\n",
            "Loss after iteration 186060: 9.384290\n",
            "Loss after iteration 186070: 9.516628\n",
            "Loss after iteration 186080: 9.420531\n",
            "Loss after iteration 186090: 9.772770\n",
            "Loss after iteration 186100: 9.048264\n",
            "Loss after iteration 186110: 9.892206\n",
            "Loss after iteration 186120: 9.688116\n",
            "Loss after iteration 186130: 9.503212\n",
            "Loss after iteration 186140: 9.083037\n",
            "Loss after iteration 186150: 9.225319\n",
            "Loss after iteration 186160: 9.622188\n",
            "Loss after iteration 186170: 9.475799\n",
            "Loss after iteration 186180: 9.592469\n",
            "Loss after iteration 186190: 9.167928\n",
            "Loss after iteration 186200: 9.133735\n",
            "Loss after iteration 186210: 9.363840\n",
            "Loss after iteration 186220: 10.147540\n",
            "Loss after iteration 186230: 9.521045\n",
            "Loss after iteration 186240: 10.219744\n",
            "Loss after iteration 186250: 9.707290\n",
            "Loss after iteration 186260: 9.149084\n",
            "Loss after iteration 186270: 10.069100\n",
            "Loss after iteration 186280: 9.223827\n",
            "Loss after iteration 186290: 9.594015\n",
            "Loss after iteration 186300: 10.115651\n",
            "Loss after iteration 186310: 9.636912\n",
            "Loss after iteration 186320: 10.102619\n",
            "Loss after iteration 186330: 9.361927\n",
            "Loss after iteration 186340: 9.576646\n",
            "Loss after iteration 186350: 9.320881\n",
            "Loss after iteration 186360: 9.958016\n",
            "Loss after iteration 186370: 9.517630\n",
            "Loss after iteration 186380: 10.023436\n",
            "Loss after iteration 186390: 9.535827\n",
            "Loss after iteration 186400: 9.361475\n",
            "Loss after iteration 186410: 9.533076\n",
            "Loss after iteration 186420: 10.011756\n",
            "Loss after iteration 186430: 9.327695\n",
            "Loss after iteration 186440: 9.371983\n",
            "Loss after iteration 186450: 9.441663\n",
            "Loss after iteration 186460: 10.022028\n",
            "Loss after iteration 186470: 9.334293\n",
            "Loss after iteration 186480: 9.261934\n",
            "Loss after iteration 186490: 9.781576\n",
            "Loss after iteration 186500: 9.846353\n",
            "Loss after iteration 186510: 9.477267\n",
            "Loss after iteration 186520: 9.363852\n",
            "Loss after iteration 186530: 10.062537\n",
            "Loss after iteration 186540: 9.839145\n",
            "Loss after iteration 186550: 9.717304\n",
            "Loss after iteration 186560: 9.910718\n",
            "Loss after iteration 186570: 9.720906\n",
            "Loss after iteration 186580: 9.396188\n",
            "Loss after iteration 186590: 9.663421\n",
            "Loss after iteration 186600: 9.111616\n",
            "Loss after iteration 186610: 9.132500\n",
            "Loss after iteration 186620: 9.372355\n",
            "Loss after iteration 186630: 9.932148\n",
            "Loss after iteration 186640: 9.853738\n",
            "Loss after iteration 186650: 9.439472\n",
            "Loss after iteration 186660: 9.536613\n",
            "Loss after iteration 186670: 9.638830\n",
            "Loss after iteration 186680: 9.824148\n",
            "Loss after iteration 186690: 9.015085\n",
            "Loss after iteration 186700: 9.085707\n",
            "Loss after iteration 186710: 9.773485\n",
            "Loss after iteration 186720: 9.420474\n",
            "Loss after iteration 186730: 9.227311\n",
            "Loss after iteration 186740: 9.458928\n",
            "Loss after iteration 186750: 9.607349\n",
            "Loss after iteration 186760: 9.226851\n",
            "Loss after iteration 186770: 9.483061\n",
            "Loss after iteration 186780: 9.625014\n",
            "Loss after iteration 186790: 9.774489\n",
            "Loss after iteration 186800: 9.711722\n",
            "Loss after iteration 186810: 9.392720\n",
            "Loss after iteration 186820: 9.513641\n",
            "Loss after iteration 186830: 9.515015\n",
            "Loss after iteration 186840: 9.334008\n",
            "Loss after iteration 186850: 10.418505\n",
            "Loss after iteration 186860: 9.565589\n",
            "Loss after iteration 186870: 9.575417\n",
            "Loss after iteration 186880: 9.519031\n",
            "Loss after iteration 186890: 9.352106\n",
            "Loss after iteration 186900: 9.606120\n",
            "Loss after iteration 186910: 9.473176\n",
            "Loss after iteration 186920: 10.157687\n",
            "Loss after iteration 186930: 9.768460\n",
            "Loss after iteration 186940: 9.769008\n",
            "Loss after iteration 186950: 9.656499\n",
            "Loss after iteration 186960: 9.663088\n",
            "Loss after iteration 186970: 9.765959\n",
            "Loss after iteration 186980: 9.529117\n",
            "Loss after iteration 186990: 10.055902\n",
            "Loss after iteration 187000: 9.784785\n",
            "Loss after iteration 187010: 9.513101\n",
            "Loss after iteration 187020: 9.798514\n",
            "Loss after iteration 187030: 9.468148\n",
            "Loss after iteration 187040: 9.767537\n",
            "Loss after iteration 187050: 9.098689\n",
            "Loss after iteration 187060: 9.397099\n",
            "Loss after iteration 187070: 9.554361\n",
            "Loss after iteration 187080: 9.315442\n",
            "Loss after iteration 187090: 10.340551\n",
            "Loss after iteration 187100: 9.905523\n",
            "Loss after iteration 187110: 9.399485\n",
            "Loss after iteration 187120: 9.633619\n",
            "Loss after iteration 187130: 9.936226\n",
            "Loss after iteration 187140: 9.541704\n",
            "Loss after iteration 187150: 9.495429\n",
            "Loss after iteration 187160: 9.992169\n",
            "Loss after iteration 187170: 10.415142\n",
            "Loss after iteration 187180: 10.320581\n",
            "Loss after iteration 187190: 9.453848\n",
            "Loss after iteration 187200: 9.662991\n",
            "Loss after iteration 187210: 9.696294\n",
            "Loss after iteration 187220: 9.950655\n",
            "Loss after iteration 187230: 9.805054\n",
            "Loss after iteration 187240: 9.631395\n",
            "Loss after iteration 187250: 10.137678\n",
            "Loss after iteration 187260: 10.722340\n",
            "Loss after iteration 187270: 9.701826\n",
            "Loss after iteration 187280: 9.428057\n",
            "Loss after iteration 187290: 9.696654\n",
            "Loss after iteration 187300: 9.818865\n",
            "Loss after iteration 187310: 9.989525\n",
            "Loss after iteration 187320: 9.562050\n",
            "Loss after iteration 187330: 9.739915\n",
            "Loss after iteration 187340: 10.054089\n",
            "Loss after iteration 187350: 9.427270\n",
            "Loss after iteration 187360: 9.518508\n",
            "Loss after iteration 187370: 9.727682\n",
            "Loss after iteration 187380: 9.891586\n",
            "Loss after iteration 187390: 9.950322\n",
            "Loss after iteration 187400: 10.139217\n",
            "Loss after iteration 187410: 9.419051\n",
            "Loss after iteration 187420: 9.399937\n",
            "Loss after iteration 187430: 9.441797\n",
            "Loss after iteration 187440: 9.338696\n",
            "Loss after iteration 187450: 9.795584\n",
            "Loss after iteration 187460: 9.614038\n",
            "Loss after iteration 187470: 9.569722\n",
            "Loss after iteration 187480: 9.117715\n",
            "Loss after iteration 187490: 9.260934\n",
            "Loss after iteration 187500: 9.253176\n",
            "Loss after iteration 187510: 9.543154\n",
            "Loss after iteration 187520: 9.080440\n",
            "Loss after iteration 187530: 9.092482\n",
            "Loss after iteration 187540: 9.442883\n",
            "Loss after iteration 187550: 9.436711\n",
            "Loss after iteration 187560: 9.333489\n",
            "Loss after iteration 187570: 9.284727\n",
            "Loss after iteration 187580: 10.211894\n",
            "Loss after iteration 187590: 10.141900\n",
            "Loss after iteration 187600: 9.203458\n",
            "Loss after iteration 187610: 9.635062\n",
            "Loss after iteration 187620: 10.334645\n",
            "Loss after iteration 187630: 9.895341\n",
            "Loss after iteration 187640: 9.228183\n",
            "Loss after iteration 187650: 9.138977\n",
            "Loss after iteration 187660: 9.319367\n",
            "Loss after iteration 187670: 9.366141\n",
            "Loss after iteration 187680: 9.540711\n",
            "Loss after iteration 187690: 9.848517\n",
            "Loss after iteration 187700: 9.933063\n",
            "Loss after iteration 187710: 9.730315\n",
            "Loss after iteration 187720: 9.511368\n",
            "Loss after iteration 187730: 9.559617\n",
            "Loss after iteration 187740: 9.445320\n",
            "Loss after iteration 187750: 9.809728\n",
            "Loss after iteration 187760: 9.371509\n",
            "Loss after iteration 187770: 9.581804\n",
            "Loss after iteration 187780: 9.194638\n",
            "Loss after iteration 187790: 9.555917\n",
            "Loss after iteration 187800: 9.690095\n",
            "Loss after iteration 187810: 10.183722\n",
            "Loss after iteration 187820: 9.691221\n",
            "Loss after iteration 187830: 9.870980\n",
            "Loss after iteration 187840: 9.224899\n",
            "Loss after iteration 187850: 9.181672\n",
            "Loss after iteration 187860: 10.406574\n",
            "Loss after iteration 187870: 10.081780\n",
            "Loss after iteration 187880: 9.765830\n",
            "Loss after iteration 187890: 9.577075\n",
            "Loss after iteration 187900: 9.675606\n",
            "Loss after iteration 187910: 9.614778\n",
            "Loss after iteration 187920: 9.656153\n",
            "Loss after iteration 187930: 9.795644\n",
            "Loss after iteration 187940: 9.886127\n",
            "Loss after iteration 187950: 9.446960\n",
            "Loss after iteration 187960: 9.750874\n",
            "Loss after iteration 187970: 10.273314\n",
            "Loss after iteration 187980: 10.426672\n",
            "Loss after iteration 187990: 10.572371\n",
            "Loss after iteration 188000: 10.587105\n",
            "Loss after iteration 188010: 10.487489\n",
            "Loss after iteration 188020: 9.562024\n",
            "Loss after iteration 188030: 9.815933\n",
            "Loss after iteration 188040: 10.263652\n",
            "Loss after iteration 188050: 9.949294\n",
            "Loss after iteration 188060: 9.329032\n",
            "Loss after iteration 188070: 9.387905\n",
            "Loss after iteration 188080: 9.533386\n",
            "Loss after iteration 188090: 9.754307\n",
            "Loss after iteration 188100: 9.299920\n",
            "Loss after iteration 188110: 9.801946\n",
            "Loss after iteration 188120: 9.328363\n",
            "Loss after iteration 188130: 9.824382\n",
            "Loss after iteration 188140: 9.491373\n",
            "Loss after iteration 188150: 9.318951\n",
            "Loss after iteration 188160: 9.709545\n",
            "Loss after iteration 188170: 9.462941\n",
            "Loss after iteration 188180: 9.635374\n",
            "Loss after iteration 188190: 10.000913\n",
            "Loss after iteration 188200: 9.939033\n",
            "Loss after iteration 188210: 9.843518\n",
            "Loss after iteration 188220: 11.274652\n",
            "Loss after iteration 188230: 9.214543\n",
            "Loss after iteration 188240: 9.537646\n",
            "Loss after iteration 188250: 9.887330\n",
            "Loss after iteration 188260: 9.430000\n",
            "Loss after iteration 188270: 9.286162\n",
            "Loss after iteration 188280: 9.363068\n",
            "Loss after iteration 188290: 9.434353\n",
            "Loss after iteration 188300: 10.098095\n",
            "Loss after iteration 188310: 9.249368\n",
            "Loss after iteration 188320: 9.230877\n",
            "Loss after iteration 188330: 9.481246\n",
            "Loss after iteration 188340: 9.163211\n",
            "Loss after iteration 188350: 9.477254\n",
            "Loss after iteration 188360: 9.156822\n",
            "Loss after iteration 188370: 9.839777\n",
            "Loss after iteration 188380: 9.646358\n",
            "Loss after iteration 188390: 9.860261\n",
            "Loss after iteration 188400: 9.510519\n",
            "Loss after iteration 188410: 10.102164\n",
            "Loss after iteration 188420: 9.311861\n",
            "Loss after iteration 188430: 9.323948\n",
            "Loss after iteration 188440: 10.653898\n",
            "Loss after iteration 188450: 9.684229\n",
            "Loss after iteration 188460: 9.191359\n",
            "Loss after iteration 188470: 9.279542\n",
            "Loss after iteration 188480: 10.041461\n",
            "Loss after iteration 188490: 9.405504\n",
            "Loss after iteration 188500: 9.756624\n",
            "Loss after iteration 188510: 9.791653\n",
            "Loss after iteration 188520: 9.869573\n",
            "Loss after iteration 188530: 9.702462\n",
            "Loss after iteration 188540: 10.686680\n",
            "Loss after iteration 188550: 9.671229\n",
            "Loss after iteration 188560: 9.909415\n",
            "Loss after iteration 188570: 9.061782\n",
            "Loss after iteration 188580: 9.324687\n",
            "Loss after iteration 188590: 9.302748\n",
            "Loss after iteration 188600: 10.026957\n",
            "Loss after iteration 188610: 9.326917\n",
            "Loss after iteration 188620: 9.541042\n",
            "Loss after iteration 188630: 9.689829\n",
            "Loss after iteration 188640: 10.640953\n",
            "Loss after iteration 188650: 9.804343\n",
            "Loss after iteration 188660: 9.503675\n",
            "Loss after iteration 188670: 10.008270\n",
            "Loss after iteration 188680: 9.548433\n",
            "Loss after iteration 188690: 10.034433\n",
            "Loss after iteration 188700: 9.719604\n",
            "Loss after iteration 188710: 9.535673\n",
            "Loss after iteration 188720: 10.145992\n",
            "Loss after iteration 188730: 9.856083\n",
            "Loss after iteration 188740: 9.646257\n",
            "Loss after iteration 188750: 9.819862\n",
            "Loss after iteration 188760: 10.083005\n",
            "Loss after iteration 188770: 9.350245\n",
            "Loss after iteration 188780: 9.723542\n",
            "Loss after iteration 188790: 9.713823\n",
            "Loss after iteration 188800: 9.248502\n",
            "Loss after iteration 188810: 9.901618\n",
            "Loss after iteration 188820: 9.225036\n",
            "Loss after iteration 188830: 9.556959\n",
            "Loss after iteration 188840: 10.222199\n",
            "Loss after iteration 188850: 10.508086\n",
            "Loss after iteration 188860: 11.039056\n",
            "Loss after iteration 188870: 9.243017\n",
            "Loss after iteration 188880: 9.921731\n",
            "Loss after iteration 188890: 9.175596\n",
            "Loss after iteration 188900: 9.402486\n",
            "Loss after iteration 188910: 9.676342\n",
            "Loss after iteration 188920: 9.366395\n",
            "Loss after iteration 188930: 10.604630\n",
            "Loss after iteration 188940: 9.277119\n",
            "Loss after iteration 188950: 9.627773\n",
            "Loss after iteration 188960: 10.560550\n",
            "Loss after iteration 188970: 9.493926\n",
            "Loss after iteration 188980: 9.519453\n",
            "Loss after iteration 188990: 9.323747\n",
            "Loss after iteration 189000: 9.627762\n",
            "Loss after iteration 189010: 9.114802\n",
            "Loss after iteration 189020: 9.068485\n",
            "Loss after iteration 189030: 9.579797\n",
            "Loss after iteration 189040: 8.964074\n",
            "Loss after iteration 189050: 9.850598\n",
            "Loss after iteration 189060: 8.979299\n",
            "Loss after iteration 189070: 9.231384\n",
            "Loss after iteration 189080: 9.772653\n",
            "Loss after iteration 189090: 9.531046\n",
            "Loss after iteration 189100: 9.662941\n",
            "Loss after iteration 189110: 10.081620\n",
            "Loss after iteration 189120: 9.809179\n",
            "Loss after iteration 189130: 9.461002\n",
            "Loss after iteration 189140: 9.183096\n",
            "Loss after iteration 189150: 9.286081\n",
            "Loss after iteration 189160: 10.068814\n",
            "Loss after iteration 189170: 9.600552\n",
            "Loss after iteration 189180: 9.159940\n",
            "Loss after iteration 189190: 9.702919\n",
            "Loss after iteration 189200: 9.859645\n",
            "Loss after iteration 189210: 9.535819\n",
            "Loss after iteration 189220: 9.448714\n",
            "Loss after iteration 189230: 9.495996\n",
            "Loss after iteration 189240: 9.671971\n",
            "Loss after iteration 189250: 9.864818\n",
            "Loss after iteration 189260: 9.423395\n",
            "Loss after iteration 189270: 9.538169\n",
            "Loss after iteration 189280: 9.422709\n",
            "Loss after iteration 189290: 10.075805\n",
            "Loss after iteration 189300: 9.865766\n",
            "Loss after iteration 189310: 10.417587\n",
            "Loss after iteration 189320: 9.390238\n",
            "Loss after iteration 189330: 9.414577\n",
            "Loss after iteration 189340: 9.362734\n",
            "Loss after iteration 189350: 9.863316\n",
            "Loss after iteration 189360: 9.753189\n",
            "Loss after iteration 189370: 9.404807\n",
            "Loss after iteration 189380: 9.442911\n",
            "Loss after iteration 189390: 9.968164\n",
            "Loss after iteration 189400: 9.803122\n",
            "Loss after iteration 189410: 9.663282\n",
            "Loss after iteration 189420: 10.535898\n",
            "Loss after iteration 189430: 9.342726\n",
            "Loss after iteration 189440: 9.368386\n",
            "Loss after iteration 189450: 10.652370\n",
            "Loss after iteration 189460: 9.641652\n",
            "Loss after iteration 189470: 10.010974\n",
            "Loss after iteration 189480: 9.600483\n",
            "Loss after iteration 189490: 9.838959\n",
            "Loss after iteration 189500: 9.429787\n",
            "Loss after iteration 189510: 10.070292\n",
            "Loss after iteration 189520: 10.252410\n",
            "Loss after iteration 189530: 9.381203\n",
            "Loss after iteration 189540: 9.679253\n",
            "Loss after iteration 189550: 9.775306\n",
            "Loss after iteration 189560: 10.160470\n",
            "Loss after iteration 189570: 9.836212\n",
            "Loss after iteration 189580: 10.627991\n",
            "Loss after iteration 189590: 9.733679\n",
            "Loss after iteration 189600: 9.525392\n",
            "Loss after iteration 189610: 9.721889\n",
            "Loss after iteration 189620: 9.519297\n",
            "Loss after iteration 189630: 9.275780\n",
            "Loss after iteration 189640: 10.003561\n",
            "Loss after iteration 189650: 9.281556\n",
            "Loss after iteration 189660: 9.877462\n",
            "Loss after iteration 189670: 9.717904\n",
            "Loss after iteration 189680: 9.360315\n",
            "Loss after iteration 189690: 9.589049\n",
            "Loss after iteration 189700: 9.476193\n",
            "Loss after iteration 189710: 9.896186\n",
            "Loss after iteration 189720: 9.558284\n",
            "Loss after iteration 189730: 9.110486\n",
            "Loss after iteration 189740: 9.397461\n",
            "Loss after iteration 189750: 9.322333\n",
            "Loss after iteration 189760: 9.687819\n",
            "Loss after iteration 189770: 9.281076\n",
            "Loss after iteration 189780: 9.456926\n",
            "Loss after iteration 189790: 9.456886\n",
            "Loss after iteration 189800: 9.038722\n",
            "Loss after iteration 189810: 9.718770\n",
            "Loss after iteration 189820: 9.366689\n",
            "Loss after iteration 189830: 9.398758\n",
            "Loss after iteration 189840: 9.184389\n",
            "Loss after iteration 189850: 9.511937\n",
            "Loss after iteration 189860: 9.351276\n",
            "Loss after iteration 189870: 9.593563\n",
            "Loss after iteration 189880: 9.828063\n",
            "Loss after iteration 189890: 10.314973\n",
            "Loss after iteration 189900: 9.896604\n",
            "Loss after iteration 189910: 9.657613\n",
            "Loss after iteration 189920: 9.606150\n",
            "Loss after iteration 189930: 9.681128\n",
            "Loss after iteration 189940: 10.167236\n",
            "Loss after iteration 189950: 9.810208\n",
            "Loss after iteration 189960: 9.538902\n",
            "Loss after iteration 189970: 9.630835\n",
            "Loss after iteration 189980: 9.305793\n",
            "Loss after iteration 189990: 9.836104\n",
            "Loss after iteration 190000: 9.660824\n",
            "Loss after iteration 190010: 9.524307\n",
            "Loss after iteration 190020: 9.684065\n",
            "Loss after iteration 190030: 10.003570\n",
            "Loss after iteration 190040: 9.859271\n",
            "Loss after iteration 190050: 9.679299\n",
            "Loss after iteration 190060: 9.919919\n",
            "Loss after iteration 190070: 9.701947\n",
            "Loss after iteration 190080: 9.499960\n",
            "Loss after iteration 190090: 9.245238\n",
            "Loss after iteration 190100: 9.589544\n",
            "Loss after iteration 190110: 9.320463\n",
            "Loss after iteration 190120: 9.743692\n",
            "Loss after iteration 190130: 10.120836\n",
            "Loss after iteration 190140: 9.303446\n",
            "Loss after iteration 190150: 9.410621\n",
            "Loss after iteration 190160: 9.716418\n",
            "Loss after iteration 190170: 9.197735\n",
            "Loss after iteration 190180: 9.292304\n",
            "Loss after iteration 190190: 9.379212\n",
            "Loss after iteration 190200: 9.315458\n",
            "Loss after iteration 190210: 9.892017\n",
            "Loss after iteration 190220: 9.511120\n",
            "Loss after iteration 190230: 8.975777\n",
            "Loss after iteration 190240: 9.692089\n",
            "Loss after iteration 190250: 10.050855\n",
            "Loss after iteration 190260: 9.419762\n",
            "Loss after iteration 190270: 9.593428\n",
            "Loss after iteration 190280: 9.691680\n",
            "Loss after iteration 190290: 9.736946\n",
            "Loss after iteration 190300: 9.525595\n",
            "Loss after iteration 190310: 9.924570\n",
            "Loss after iteration 190320: 10.026666\n",
            "Loss after iteration 190330: 9.976875\n",
            "Loss after iteration 190340: 9.554729\n",
            "Loss after iteration 190350: 9.433100\n",
            "Loss after iteration 190360: 9.210634\n",
            "Loss after iteration 190370: 9.579828\n",
            "Loss after iteration 190380: 9.244409\n",
            "Loss after iteration 190390: 9.415624\n",
            "Loss after iteration 190400: 9.606529\n",
            "Loss after iteration 190410: 9.666724\n",
            "Loss after iteration 190420: 9.171058\n",
            "Loss after iteration 190430: 9.556196\n",
            "Loss after iteration 190440: 9.532728\n",
            "Loss after iteration 190450: 9.174379\n",
            "Loss after iteration 190460: 9.154102\n",
            "Loss after iteration 190470: 9.791974\n",
            "Loss after iteration 190480: 9.266897\n",
            "Loss after iteration 190490: 9.592820\n",
            "Loss after iteration 190500: 9.872413\n",
            "Loss after iteration 190510: 10.369507\n",
            "Loss after iteration 190520: 9.428643\n",
            "Loss after iteration 190530: 9.721228\n",
            "Loss after iteration 190540: 9.743077\n",
            "Loss after iteration 190550: 9.678541\n",
            "Loss after iteration 190560: 9.553191\n",
            "Loss after iteration 190570: 9.588049\n",
            "Loss after iteration 190580: 9.454118\n",
            "Loss after iteration 190590: 10.129218\n",
            "Loss after iteration 190600: 9.664160\n",
            "Loss after iteration 190610: 9.465904\n",
            "Loss after iteration 190620: 9.663889\n",
            "Loss after iteration 190630: 10.261885\n",
            "Loss after iteration 190640: 9.510117\n",
            "Loss after iteration 190650: 9.645301\n",
            "Loss after iteration 190660: 9.562573\n",
            "Loss after iteration 190670: 9.990268\n",
            "Loss after iteration 190680: 9.565631\n",
            "Loss after iteration 190690: 9.494187\n",
            "Loss after iteration 190700: 9.622105\n",
            "Loss after iteration 190710: 10.666864\n",
            "Loss after iteration 190720: 9.666246\n",
            "Loss after iteration 190730: 9.187834\n",
            "Loss after iteration 190740: 9.595670\n",
            "Loss after iteration 190750: 9.862666\n",
            "Loss after iteration 190760: 9.392078\n",
            "Loss after iteration 190770: 9.689252\n",
            "Loss after iteration 190780: 9.489003\n",
            "Loss after iteration 190790: 9.626870\n",
            "Loss after iteration 190800: 9.388253\n",
            "Loss after iteration 190810: 10.119325\n",
            "Loss after iteration 190820: 9.593180\n",
            "Loss after iteration 190830: 9.361337\n",
            "Loss after iteration 190840: 9.889223\n",
            "Loss after iteration 190850: 9.634028\n",
            "Loss after iteration 190860: 9.335166\n",
            "Loss after iteration 190870: 9.276369\n",
            "Loss after iteration 190880: 9.301631\n",
            "Loss after iteration 190890: 9.191658\n",
            "Loss after iteration 190900: 9.274639\n",
            "Loss after iteration 190910: 10.708910\n",
            "Loss after iteration 190920: 9.228470\n",
            "Loss after iteration 190930: 10.114077\n",
            "Loss after iteration 190940: 9.170031\n",
            "Loss after iteration 190950: 9.273372\n",
            "Loss after iteration 190960: 9.679317\n",
            "Loss after iteration 190970: 9.367402\n",
            "Loss after iteration 190980: 9.487186\n",
            "Loss after iteration 190990: 9.839095\n",
            "Loss after iteration 191000: 9.425258\n",
            "Loss after iteration 191010: 10.347888\n",
            "Loss after iteration 191020: 9.278299\n",
            "Loss after iteration 191030: 9.235357\n",
            "Loss after iteration 191040: 10.774745\n",
            "Loss after iteration 191050: 10.084951\n",
            "Loss after iteration 191060: 10.115580\n",
            "Loss after iteration 191070: 9.368971\n",
            "Loss after iteration 191080: 9.444461\n",
            "Loss after iteration 191090: 9.807237\n",
            "Loss after iteration 191100: 9.468373\n",
            "Loss after iteration 191110: 9.290214\n",
            "Loss after iteration 191120: 9.524045\n",
            "Loss after iteration 191130: 9.453674\n",
            "Loss after iteration 191140: 9.619019\n",
            "Loss after iteration 191150: 9.627822\n",
            "Loss after iteration 191160: 9.533692\n",
            "Loss after iteration 191170: 9.192628\n",
            "Loss after iteration 191180: 10.148376\n",
            "Loss after iteration 191190: 9.250700\n",
            "Loss after iteration 191200: 9.273546\n",
            "Loss after iteration 191210: 9.332372\n",
            "Loss after iteration 191220: 10.005938\n",
            "Loss after iteration 191230: 9.390919\n",
            "Loss after iteration 191240: 9.358663\n",
            "Loss after iteration 191250: 9.524823\n",
            "Loss after iteration 191260: 9.879630\n",
            "Loss after iteration 191270: 9.137206\n",
            "Loss after iteration 191280: 9.722475\n",
            "Loss after iteration 191290: 9.831846\n",
            "Loss after iteration 191300: 9.242017\n",
            "Loss after iteration 191310: 9.714134\n",
            "Loss after iteration 191320: 9.656975\n",
            "Loss after iteration 191330: 9.581531\n",
            "Loss after iteration 191340: 9.815219\n",
            "Loss after iteration 191350: 10.132743\n",
            "Loss after iteration 191360: 9.912766\n",
            "Loss after iteration 191370: 9.755462\n",
            "Loss after iteration 191380: 9.489355\n",
            "Loss after iteration 191390: 9.570186\n",
            "Loss after iteration 191400: 9.411926\n",
            "Loss after iteration 191410: 9.191443\n",
            "Loss after iteration 191420: 9.818794\n",
            "Loss after iteration 191430: 9.564840\n",
            "Loss after iteration 191440: 9.979110\n",
            "Loss after iteration 191450: 9.855871\n",
            "Loss after iteration 191460: 10.151533\n",
            "Loss after iteration 191470: 10.005666\n",
            "Loss after iteration 191480: 9.408160\n",
            "Loss after iteration 191490: 9.599129\n",
            "Loss after iteration 191500: 9.638487\n",
            "Loss after iteration 191510: 9.521980\n",
            "Loss after iteration 191520: 9.951770\n",
            "Loss after iteration 191530: 9.855224\n",
            "Loss after iteration 191540: 9.631131\n",
            "Loss after iteration 191550: 9.586198\n",
            "Loss after iteration 191560: 9.419681\n",
            "Loss after iteration 191570: 9.724783\n",
            "Loss after iteration 191580: 9.631090\n",
            "Loss after iteration 191590: 9.608629\n",
            "Loss after iteration 191600: 10.242891\n",
            "Loss after iteration 191610: 10.596843\n",
            "Loss after iteration 191620: 10.103472\n",
            "Loss after iteration 191630: 9.625120\n",
            "Loss after iteration 191640: 9.733381\n",
            "Loss after iteration 191650: 9.477296\n",
            "Loss after iteration 191660: 10.013393\n",
            "Loss after iteration 191670: 9.767429\n",
            "Loss after iteration 191680: 9.890883\n",
            "Loss after iteration 191690: 10.034976\n",
            "Loss after iteration 191700: 10.132672\n",
            "Loss after iteration 191710: 9.855476\n",
            "Loss after iteration 191720: 9.970942\n",
            "Loss after iteration 191730: 9.422399\n",
            "Loss after iteration 191740: 9.532407\n",
            "Loss after iteration 191750: 9.991442\n",
            "Loss after iteration 191760: 9.812195\n",
            "Loss after iteration 191770: 10.033228\n",
            "Loss after iteration 191780: 9.430065\n",
            "Loss after iteration 191790: 9.457720\n",
            "Loss after iteration 191800: 9.641516\n",
            "Loss after iteration 191810: 9.357670\n",
            "Loss after iteration 191820: 9.315413\n",
            "Loss after iteration 191830: 9.724125\n",
            "Loss after iteration 191840: 10.153062\n",
            "Loss after iteration 191850: 9.889377\n",
            "Loss after iteration 191860: 9.435719\n",
            "Loss after iteration 191870: 10.486494\n",
            "Loss after iteration 191880: 9.535358\n",
            "Loss after iteration 191890: 9.472186\n",
            "Loss after iteration 191900: 9.356681\n",
            "Loss after iteration 191910: 10.153220\n",
            "Loss after iteration 191920: 10.009299\n",
            "Loss after iteration 191930: 9.642845\n",
            "Loss after iteration 191940: 10.134665\n",
            "Loss after iteration 191950: 9.910803\n",
            "Loss after iteration 191960: 9.943488\n",
            "Loss after iteration 191970: 9.731021\n",
            "Loss after iteration 191980: 9.425420\n",
            "Loss after iteration 191990: 9.386311\n",
            "Loss after iteration 192000: 9.295635\n",
            "Loss after iteration 192010: 9.534542\n",
            "Loss after iteration 192020: 9.974583\n",
            "Loss after iteration 192030: 9.895622\n",
            "Loss after iteration 192040: 9.297208\n",
            "Loss after iteration 192050: 9.780298\n",
            "Loss after iteration 192060: 9.333299\n",
            "Loss after iteration 192070: 9.586883\n",
            "Loss after iteration 192080: 9.404402\n",
            "Loss after iteration 192090: 9.473313\n",
            "Loss after iteration 192100: 9.418225\n",
            "Loss after iteration 192110: 10.725651\n",
            "Loss after iteration 192120: 10.455740\n",
            "Loss after iteration 192130: 9.496617\n",
            "Loss after iteration 192140: 9.324506\n",
            "Loss after iteration 192150: 9.878503\n",
            "Loss after iteration 192160: 9.384072\n",
            "Loss after iteration 192170: 10.002574\n",
            "Loss after iteration 192180: 9.971357\n",
            "Loss after iteration 192190: 9.416198\n",
            "Loss after iteration 192200: 9.483725\n",
            "Loss after iteration 192210: 9.574225\n",
            "Loss after iteration 192220: 9.126179\n",
            "Loss after iteration 192230: 9.409368\n",
            "Loss after iteration 192240: 9.132430\n",
            "Loss after iteration 192250: 9.677975\n",
            "Loss after iteration 192260: 9.376061\n",
            "Loss after iteration 192270: 9.399508\n",
            "Loss after iteration 192280: 9.805509\n",
            "Loss after iteration 192290: 9.176405\n",
            "Loss after iteration 192300: 9.593328\n",
            "Loss after iteration 192310: 10.383738\n",
            "Loss after iteration 192320: 9.824384\n",
            "Loss after iteration 192330: 10.053505\n",
            "Loss after iteration 192340: 9.320696\n",
            "Loss after iteration 192350: 9.006503\n",
            "Loss after iteration 192360: 10.162068\n",
            "Loss after iteration 192370: 9.789736\n",
            "Loss after iteration 192380: 9.649207\n",
            "Loss after iteration 192390: 9.316892\n",
            "Loss after iteration 192400: 9.908717\n",
            "Loss after iteration 192410: 9.776788\n",
            "Loss after iteration 192420: 9.818765\n",
            "Loss after iteration 192430: 9.514828\n",
            "Loss after iteration 192440: 9.497294\n",
            "Loss after iteration 192450: 9.469958\n",
            "Loss after iteration 192460: 10.069981\n",
            "Loss after iteration 192470: 9.968391\n",
            "Loss after iteration 192480: 10.448494\n",
            "Loss after iteration 192490: 9.317787\n",
            "Loss after iteration 192500: 9.894220\n",
            "Loss after iteration 192510: 9.166523\n",
            "Loss after iteration 192520: 9.155597\n",
            "Loss after iteration 192530: 9.937329\n",
            "Loss after iteration 192540: 9.831364\n",
            "Loss after iteration 192550: 10.062294\n",
            "Loss after iteration 192560: 9.199215\n",
            "Loss after iteration 192570: 9.340945\n",
            "Loss after iteration 192580: 9.223461\n",
            "Loss after iteration 192590: 9.640251\n",
            "Loss after iteration 192600: 9.584407\n",
            "Loss after iteration 192610: 9.292337\n",
            "Loss after iteration 192620: 10.170676\n",
            "Loss after iteration 192630: 9.622287\n",
            "Loss after iteration 192640: 9.625209\n",
            "Loss after iteration 192650: 9.181561\n",
            "Loss after iteration 192660: 9.665946\n",
            "Loss after iteration 192670: 9.713034\n",
            "Loss after iteration 192680: 9.074576\n",
            "Loss after iteration 192690: 9.884982\n",
            "Loss after iteration 192700: 10.606159\n",
            "Loss after iteration 192710: 10.219165\n",
            "Loss after iteration 192720: 9.728128\n",
            "Loss after iteration 192730: 9.714086\n",
            "Loss after iteration 192740: 9.408573\n",
            "Loss after iteration 192750: 9.646710\n",
            "Loss after iteration 192760: 9.943808\n",
            "Loss after iteration 192770: 9.986529\n",
            "Loss after iteration 192780: 9.218485\n",
            "Loss after iteration 192790: 9.731692\n",
            "Loss after iteration 192800: 9.552017\n",
            "Loss after iteration 192810: 9.647174\n",
            "Loss after iteration 192820: 10.158195\n",
            "Loss after iteration 192830: 9.483194\n",
            "Loss after iteration 192840: 9.391293\n",
            "Loss after iteration 192850: 9.636030\n",
            "Loss after iteration 192860: 10.213719\n",
            "Loss after iteration 192870: 9.494103\n",
            "Loss after iteration 192880: 9.860903\n",
            "Loss after iteration 192890: 10.019198\n",
            "Loss after iteration 192900: 9.242389\n",
            "Loss after iteration 192910: 9.554831\n",
            "Loss after iteration 192920: 9.702492\n",
            "Loss after iteration 192930: 9.375871\n",
            "Loss after iteration 192940: 10.088531\n",
            "Loss after iteration 192950: 9.766497\n",
            "Loss after iteration 192960: 10.979536\n",
            "Loss after iteration 192970: 9.684597\n",
            "Loss after iteration 192980: 9.624633\n",
            "Loss after iteration 192990: 9.273063\n",
            "Loss after iteration 193000: 9.246209\n",
            "Loss after iteration 193010: 9.114233\n",
            "Loss after iteration 193020: 9.046972\n",
            "Loss after iteration 193030: 9.369089\n",
            "Loss after iteration 193040: 9.221472\n",
            "Loss after iteration 193050: 9.930460\n",
            "Loss after iteration 193060: 9.711443\n",
            "Loss after iteration 193070: 9.951488\n",
            "Loss after iteration 193080: 10.449325\n",
            "Loss after iteration 193090: 9.507806\n",
            "Loss after iteration 193100: 10.632880\n",
            "Loss after iteration 193110: 9.523438\n",
            "Loss after iteration 193120: 9.409696\n",
            "Loss after iteration 193130: 10.020702\n",
            "Loss after iteration 193140: 9.763529\n",
            "Loss after iteration 193150: 9.747763\n",
            "Loss after iteration 193160: 9.185628\n",
            "Loss after iteration 193170: 9.454727\n",
            "Loss after iteration 193180: 9.878986\n",
            "Loss after iteration 193190: 9.299277\n",
            "Loss after iteration 193200: 9.562620\n",
            "Loss after iteration 193210: 9.748946\n",
            "Loss after iteration 193220: 9.715936\n",
            "Loss after iteration 193230: 9.318657\n",
            "Loss after iteration 193240: 9.622360\n",
            "Loss after iteration 193250: 9.486139\n",
            "Loss after iteration 193260: 10.364250\n",
            "Loss after iteration 193270: 10.067205\n",
            "Loss after iteration 193280: 9.923434\n",
            "Loss after iteration 193290: 10.092310\n",
            "Loss after iteration 193300: 9.180784\n",
            "Loss after iteration 193310: 9.542739\n",
            "Loss after iteration 193320: 10.778359\n",
            "Loss after iteration 193330: 9.582067\n",
            "Loss after iteration 193340: 10.128332\n",
            "Loss after iteration 193350: 9.957024\n",
            "Loss after iteration 193360: 9.795581\n",
            "Loss after iteration 193370: 9.614725\n",
            "Loss after iteration 193380: 9.438365\n",
            "Loss after iteration 193390: 9.790294\n",
            "Loss after iteration 193400: 9.315252\n",
            "Loss after iteration 193410: 10.256650\n",
            "Loss after iteration 193420: 9.476769\n",
            "Loss after iteration 193430: 9.285280\n",
            "Loss after iteration 193440: 10.088011\n",
            "Loss after iteration 193450: 9.319424\n",
            "Loss after iteration 193460: 9.760180\n",
            "Loss after iteration 193470: 9.648414\n",
            "Loss after iteration 193480: 9.545364\n",
            "Loss after iteration 193490: 9.092728\n",
            "Loss after iteration 193500: 9.117128\n",
            "Loss after iteration 193510: 9.131915\n",
            "Loss after iteration 193520: 9.273237\n",
            "Loss after iteration 193530: 9.450009\n",
            "Loss after iteration 193540: 9.294962\n",
            "Loss after iteration 193550: 9.396029\n",
            "Loss after iteration 193560: 9.876087\n",
            "Loss after iteration 193570: 9.169473\n",
            "Loss after iteration 193580: 9.700132\n",
            "Loss after iteration 193590: 9.120151\n",
            "Loss after iteration 193600: 9.783442\n",
            "Loss after iteration 193610: 9.114647\n",
            "Loss after iteration 193620: 9.326403\n",
            "Loss after iteration 193630: 9.114678\n",
            "Loss after iteration 193640: 9.177674\n",
            "Loss after iteration 193650: 11.029160\n",
            "Loss after iteration 193660: 9.489465\n",
            "Loss after iteration 193670: 9.798097\n",
            "Loss after iteration 193680: 9.405476\n",
            "Loss after iteration 193690: 10.784720\n",
            "Loss after iteration 193700: 9.493318\n",
            "Loss after iteration 193710: 9.688242\n",
            "Loss after iteration 193720: 9.168077\n",
            "Loss after iteration 193730: 9.209811\n",
            "Loss after iteration 193740: 9.672918\n",
            "Loss after iteration 193750: 9.639109\n",
            "Loss after iteration 193760: 9.521531\n",
            "Loss after iteration 193770: 10.101704\n",
            "Loss after iteration 193780: 9.628489\n",
            "Loss after iteration 193790: 9.585131\n",
            "Loss after iteration 193800: 9.417618\n",
            "Loss after iteration 193810: 9.601625\n",
            "Loss after iteration 193820: 9.848951\n",
            "Loss after iteration 193830: 9.890846\n",
            "Loss after iteration 193840: 9.853404\n",
            "Loss after iteration 193850: 9.550120\n",
            "Loss after iteration 193860: 9.836654\n",
            "Loss after iteration 193870: 10.119897\n",
            "Loss after iteration 193880: 9.170934\n",
            "Loss after iteration 193890: 8.906382\n",
            "Loss after iteration 193900: 9.588641\n",
            "Loss after iteration 193910: 9.075241\n",
            "Loss after iteration 193920: 9.397130\n",
            "Loss after iteration 193930: 9.469194\n",
            "Loss after iteration 193940: 8.965640\n",
            "Loss after iteration 193950: 9.370212\n",
            "Loss after iteration 193960: 9.417838\n",
            "Loss after iteration 193970: 9.142001\n",
            "Loss after iteration 193980: 9.459377\n",
            "Loss after iteration 193990: 9.321177\n",
            "Loss after iteration 194000: 10.439336\n",
            "Loss after iteration 194010: 9.625507\n",
            "Loss after iteration 194020: 9.535731\n",
            "Loss after iteration 194030: 9.559233\n",
            "Loss after iteration 194040: 9.929547\n",
            "Loss after iteration 194050: 9.505878\n",
            "Loss after iteration 194060: 9.321763\n",
            "Loss after iteration 194070: 9.577833\n",
            "Loss after iteration 194080: 10.213449\n",
            "Loss after iteration 194090: 9.796554\n",
            "Loss after iteration 194100: 9.620709\n",
            "Loss after iteration 194110: 9.718442\n",
            "Loss after iteration 194120: 9.597104\n",
            "Loss after iteration 194130: 9.723931\n",
            "Loss after iteration 194140: 11.348237\n",
            "Loss after iteration 194150: 9.811472\n",
            "Loss after iteration 194160: 9.635331\n",
            "Loss after iteration 194170: 9.543062\n",
            "Loss after iteration 194180: 9.532918\n",
            "Loss after iteration 194190: 9.459892\n",
            "Loss after iteration 194200: 9.339390\n",
            "Loss after iteration 194210: 9.654898\n",
            "Loss after iteration 194220: 9.710136\n",
            "Loss after iteration 194230: 9.491001\n",
            "Loss after iteration 194240: 9.130759\n",
            "Loss after iteration 194250: 9.141460\n",
            "Loss after iteration 194260: 9.855839\n",
            "Loss after iteration 194270: 9.219213\n",
            "Loss after iteration 194280: 9.323354\n",
            "Loss after iteration 194290: 9.957901\n",
            "Loss after iteration 194300: 10.024727\n",
            "Loss after iteration 194310: 9.494120\n",
            "Loss after iteration 194320: 10.915542\n",
            "Loss after iteration 194330: 9.671871\n",
            "Loss after iteration 194340: 10.543207\n",
            "Loss after iteration 194350: 9.988988\n",
            "Loss after iteration 194360: 9.448278\n",
            "Loss after iteration 194370: 9.163386\n",
            "Loss after iteration 194380: 9.829395\n",
            "Loss after iteration 194390: 10.726657\n",
            "Loss after iteration 194400: 9.833292\n",
            "Loss after iteration 194410: 9.753799\n",
            "Loss after iteration 194420: 9.452499\n",
            "Loss after iteration 194430: 9.166185\n",
            "Loss after iteration 194440: 9.434548\n",
            "Loss after iteration 194450: 9.385729\n",
            "Loss after iteration 194460: 9.322785\n",
            "Loss after iteration 194470: 9.319866\n",
            "Loss after iteration 194480: 9.354111\n",
            "Loss after iteration 194490: 9.587705\n",
            "Loss after iteration 194500: 10.074649\n",
            "Loss after iteration 194510: 9.702067\n",
            "Loss after iteration 194520: 9.973566\n",
            "Loss after iteration 194530: 9.518980\n",
            "Loss after iteration 194540: 9.628068\n",
            "Loss after iteration 194550: 9.473498\n",
            "Loss after iteration 194560: 9.809913\n",
            "Loss after iteration 194570: 9.550755\n",
            "Loss after iteration 194580: 10.299283\n",
            "Loss after iteration 194590: 10.882667\n",
            "Loss after iteration 194600: 9.777672\n",
            "Loss after iteration 194610: 10.068231\n",
            "Loss after iteration 194620: 9.412430\n",
            "Loss after iteration 194630: 10.427361\n",
            "Loss after iteration 194640: 10.297418\n",
            "Loss after iteration 194650: 9.593373\n",
            "Loss after iteration 194660: 9.941441\n",
            "Loss after iteration 194670: 10.019983\n",
            "Loss after iteration 194680: 10.137140\n",
            "Loss after iteration 194690: 9.673508\n",
            "Loss after iteration 194700: 9.363553\n",
            "Loss after iteration 194710: 10.833839\n",
            "Loss after iteration 194720: 9.729987\n",
            "Loss after iteration 194730: 9.525089\n",
            "Loss after iteration 194740: 10.539149\n",
            "Loss after iteration 194750: 9.216072\n",
            "Loss after iteration 194760: 9.742498\n",
            "Loss after iteration 194770: 9.354862\n",
            "Loss after iteration 194780: 10.630339\n",
            "Loss after iteration 194790: 9.846174\n",
            "Loss after iteration 194800: 9.451391\n",
            "Loss after iteration 194810: 9.632136\n",
            "Loss after iteration 194820: 9.477285\n",
            "Loss after iteration 194830: 9.676306\n",
            "Loss after iteration 194840: 9.262596\n",
            "Loss after iteration 194850: 9.951643\n",
            "Loss after iteration 194860: 9.720048\n",
            "Loss after iteration 194870: 10.074242\n",
            "Loss after iteration 194880: 9.790236\n",
            "Loss after iteration 194890: 9.274770\n",
            "Loss after iteration 194900: 9.679507\n",
            "Loss after iteration 194910: 10.074964\n",
            "Loss after iteration 194920: 9.388692\n",
            "Loss after iteration 194930: 9.642114\n",
            "Loss after iteration 194940: 9.678959\n",
            "Loss after iteration 194950: 10.157839\n",
            "Loss after iteration 194960: 10.037974\n",
            "Loss after iteration 194970: 9.603624\n",
            "Loss after iteration 194980: 9.489310\n",
            "Loss after iteration 194990: 9.542777\n",
            "Loss after iteration 195000: 10.015166\n",
            "Loss after iteration 195010: 9.598510\n",
            "Loss after iteration 195020: 10.734581\n",
            "Loss after iteration 195030: 9.523007\n",
            "Loss after iteration 195040: 9.521983\n",
            "Loss after iteration 195050: 9.408697\n",
            "Loss after iteration 195060: 9.585201\n",
            "Loss after iteration 195070: 9.217116\n",
            "Loss after iteration 195080: 9.423063\n",
            "Loss after iteration 195090: 9.618915\n",
            "Loss after iteration 195100: 9.654580\n",
            "Loss after iteration 195110: 9.449926\n",
            "Loss after iteration 195120: 9.152654\n",
            "Loss after iteration 195130: 10.385893\n",
            "Loss after iteration 195140: 9.942672\n",
            "Loss after iteration 195150: 10.604861\n",
            "Loss after iteration 195160: 9.684514\n",
            "Loss after iteration 195170: 9.290022\n",
            "Loss after iteration 195180: 10.088928\n",
            "Loss after iteration 195190: 9.401007\n",
            "Loss after iteration 195200: 9.407997\n",
            "Loss after iteration 195210: 9.480675\n",
            "Loss after iteration 195220: 9.319601\n",
            "Loss after iteration 195230: 9.339684\n",
            "Loss after iteration 195240: 9.498910\n",
            "Loss after iteration 195250: 9.580585\n",
            "Loss after iteration 195260: 10.155745\n",
            "Loss after iteration 195270: 9.854271\n",
            "Loss after iteration 195280: 9.290356\n",
            "Loss after iteration 195290: 9.593961\n",
            "Loss after iteration 195300: 9.320701\n",
            "Loss after iteration 195310: 9.678912\n",
            "Loss after iteration 195320: 10.469723\n",
            "Loss after iteration 195330: 9.413217\n",
            "Loss after iteration 195340: 9.238850\n",
            "Loss after iteration 195350: 10.116943\n",
            "Loss after iteration 195360: 9.699482\n",
            "Loss after iteration 195370: 9.445283\n",
            "Loss after iteration 195380: 9.778896\n",
            "Loss after iteration 195390: 9.695812\n",
            "Loss after iteration 195400: 9.805985\n",
            "Loss after iteration 195410: 9.608814\n",
            "Loss after iteration 195420: 9.936610\n",
            "Loss after iteration 195430: 9.374954\n",
            "Loss after iteration 195440: 9.817979\n",
            "Loss after iteration 195450: 9.510155\n",
            "Loss after iteration 195460: 10.068685\n",
            "Loss after iteration 195470: 9.851277\n",
            "Loss after iteration 195480: 9.434803\n",
            "Loss after iteration 195490: 9.323915\n",
            "Loss after iteration 195500: 9.962447\n",
            "Loss after iteration 195510: 9.749721\n",
            "Loss after iteration 195520: 10.766952\n",
            "Loss after iteration 195530: 9.525456\n",
            "Loss after iteration 195540: 9.830894\n",
            "Loss after iteration 195550: 10.283235\n",
            "Loss after iteration 195560: 9.535200\n",
            "Loss after iteration 195570: 9.593422\n",
            "Loss after iteration 195580: 9.525142\n",
            "Loss after iteration 195590: 9.348035\n",
            "Loss after iteration 195600: 9.534166\n",
            "Loss after iteration 195610: 9.614682\n",
            "Loss after iteration 195620: 9.263718\n",
            "Loss after iteration 195630: 9.576568\n",
            "Loss after iteration 195640: 9.026830\n",
            "Loss after iteration 195650: 9.739875\n",
            "Loss after iteration 195660: 9.424603\n",
            "Loss after iteration 195670: 9.209712\n",
            "Loss after iteration 195680: 9.244550\n",
            "Loss after iteration 195690: 9.354142\n",
            "Loss after iteration 195700: 9.732583\n",
            "Loss after iteration 195710: 9.589190\n",
            "Loss after iteration 195720: 10.315652\n",
            "Loss after iteration 195730: 9.592504\n",
            "Loss after iteration 195740: 9.782502\n",
            "Loss after iteration 195750: 10.123449\n",
            "Loss after iteration 195760: 9.320683\n",
            "Loss after iteration 195770: 9.117387\n",
            "Loss after iteration 195780: 9.367174\n",
            "Loss after iteration 195790: 9.618673\n",
            "Loss after iteration 195800: 9.171011\n",
            "Loss after iteration 195810: 9.399246\n",
            "Loss after iteration 195820: 9.927296\n",
            "Loss after iteration 195830: 9.864628\n",
            "Loss after iteration 195840: 9.505401\n",
            "Loss after iteration 195850: 9.618254\n",
            "Loss after iteration 195860: 9.558926\n",
            "Loss after iteration 195870: 9.614582\n",
            "Loss after iteration 195880: 9.558551\n",
            "Loss after iteration 195890: 9.482309\n",
            "Loss after iteration 195900: 9.506954\n",
            "Loss after iteration 195910: 9.951059\n",
            "Loss after iteration 195920: 9.632445\n",
            "Loss after iteration 195930: 10.307868\n",
            "Loss after iteration 195940: 10.004490\n",
            "Loss after iteration 195950: 10.154015\n",
            "Loss after iteration 195960: 9.669440\n",
            "Loss after iteration 195970: 9.588533\n",
            "Loss after iteration 195980: 9.915658\n",
            "Loss after iteration 195990: 9.304193\n",
            "Loss after iteration 196000: 9.930584\n",
            "Loss after iteration 196010: 9.238334\n",
            "Loss after iteration 196020: 9.206509\n",
            "Loss after iteration 196030: 9.387901\n",
            "Loss after iteration 196040: 9.498036\n",
            "Loss after iteration 196050: 9.229671\n",
            "Loss after iteration 196060: 9.420917\n",
            "Loss after iteration 196070: 9.476762\n",
            "Loss after iteration 196080: 9.666647\n",
            "Loss after iteration 196090: 9.230361\n",
            "Loss after iteration 196100: 9.223012\n",
            "Loss after iteration 196110: 9.564013\n",
            "Loss after iteration 196120: 9.778436\n",
            "Loss after iteration 196130: 9.718098\n",
            "Loss after iteration 196140: 9.653021\n",
            "Loss after iteration 196150: 10.099671\n",
            "Loss after iteration 196160: 9.434040\n",
            "Loss after iteration 196170: 9.421415\n",
            "Loss after iteration 196180: 9.947028\n",
            "Loss after iteration 196190: 10.405586\n",
            "Loss after iteration 196200: 9.809512\n",
            "Loss after iteration 196210: 10.640112\n",
            "Loss after iteration 196220: 9.383861\n",
            "Loss after iteration 196230: 9.802557\n",
            "Loss after iteration 196240: 9.910875\n",
            "Loss after iteration 196250: 9.759042\n",
            "Loss after iteration 196260: 9.545042\n",
            "Loss after iteration 196270: 9.453784\n",
            "Loss after iteration 196280: 9.345119\n",
            "Loss after iteration 196290: 9.898954\n",
            "Loss after iteration 196300: 9.743205\n",
            "Loss after iteration 196310: 9.693467\n",
            "Loss after iteration 196320: 9.794030\n",
            "Loss after iteration 196330: 9.572072\n",
            "Loss after iteration 196340: 9.322745\n",
            "Loss after iteration 196350: 9.518312\n",
            "Loss after iteration 196360: 9.808936\n",
            "Loss after iteration 196370: 9.204668\n",
            "Loss after iteration 196380: 9.221816\n",
            "Loss after iteration 196390: 9.509025\n",
            "Loss after iteration 196400: 9.302186\n",
            "Loss after iteration 196410: 9.656213\n",
            "Loss after iteration 196420: 9.176864\n",
            "Loss after iteration 196430: 9.173608\n",
            "Loss after iteration 196440: 9.860733\n",
            "Loss after iteration 196450: 9.151903\n",
            "Loss after iteration 196460: 9.443153\n",
            "Loss after iteration 196470: 9.242952\n",
            "Loss after iteration 196480: 9.419357\n",
            "Loss after iteration 196490: 9.497065\n",
            "Loss after iteration 196500: 10.039686\n",
            "Loss after iteration 196510: 9.214809\n",
            "Loss after iteration 196520: 9.703116\n",
            "Loss after iteration 196530: 9.443960\n",
            "Loss after iteration 196540: 9.931902\n",
            "Loss after iteration 196550: 9.527965\n",
            "Loss after iteration 196560: 10.136080\n",
            "Loss after iteration 196570: 9.221705\n",
            "Loss after iteration 196580: 9.228783\n",
            "Loss after iteration 196590: 9.606506\n",
            "Loss after iteration 196600: 10.177033\n",
            "Loss after iteration 196610: 9.434640\n",
            "Loss after iteration 196620: 10.060401\n",
            "Loss after iteration 196630: 9.980626\n",
            "Loss after iteration 196640: 9.806895\n",
            "Loss after iteration 196650: 9.812689\n",
            "Loss after iteration 196660: 9.647428\n",
            "Loss after iteration 196670: 9.712347\n",
            "Loss after iteration 196680: 9.061420\n",
            "Loss after iteration 196690: 9.042620\n",
            "Loss after iteration 196700: 9.015850\n",
            "Loss after iteration 196710: 10.161027\n",
            "Loss after iteration 196720: 9.581031\n",
            "Loss after iteration 196730: 9.567093\n",
            "Loss after iteration 196740: 9.929175\n",
            "Loss after iteration 196750: 9.252336\n",
            "Loss after iteration 196760: 9.449878\n",
            "Loss after iteration 196770: 9.312471\n",
            "Loss after iteration 196780: 9.629114\n",
            "Loss after iteration 196790: 9.405529\n",
            "Loss after iteration 196800: 9.758375\n",
            "Loss after iteration 196810: 9.994764\n",
            "Loss after iteration 196820: 9.560254\n",
            "Loss after iteration 196830: 9.883223\n",
            "Loss after iteration 196840: 9.357521\n",
            "Loss after iteration 196850: 9.626514\n",
            "Loss after iteration 196860: 9.654736\n",
            "Loss after iteration 196870: 9.309029\n",
            "Loss after iteration 196880: 10.130188\n",
            "Loss after iteration 196890: 9.498011\n",
            "Loss after iteration 196900: 9.892318\n",
            "Loss after iteration 196910: 10.015427\n",
            "Loss after iteration 196920: 9.213689\n",
            "Loss after iteration 196930: 9.835694\n",
            "Loss after iteration 196940: 9.713356\n",
            "Loss after iteration 196950: 9.418690\n",
            "Loss after iteration 196960: 9.254738\n",
            "Loss after iteration 196970: 9.301705\n",
            "Loss after iteration 196980: 9.521895\n",
            "Loss after iteration 196990: 9.861858\n",
            "Loss after iteration 197000: 9.186632\n",
            "Loss after iteration 197010: 10.012828\n",
            "Loss after iteration 197020: 9.621626\n",
            "Loss after iteration 197030: 9.618835\n",
            "Loss after iteration 197040: 9.035672\n",
            "Loss after iteration 197050: 9.397944\n",
            "Loss after iteration 197060: 9.199526\n",
            "Loss after iteration 197070: 9.394717\n",
            "Loss after iteration 197080: 9.533656\n",
            "Loss after iteration 197090: 9.056055\n",
            "Loss after iteration 197100: 10.112292\n",
            "Loss after iteration 197110: 9.710570\n",
            "Loss after iteration 197120: 9.379145\n",
            "Loss after iteration 197130: 9.927887\n",
            "Loss after iteration 197140: 9.095981\n",
            "Loss after iteration 197150: 9.123014\n",
            "Loss after iteration 197160: 9.253000\n",
            "Loss after iteration 197170: 9.386559\n",
            "Loss after iteration 197180: 9.624967\n",
            "Loss after iteration 197190: 10.148414\n",
            "Loss after iteration 197200: 10.451900\n",
            "Loss after iteration 197210: 9.718312\n",
            "Loss after iteration 197220: 9.442499\n",
            "Loss after iteration 197230: 9.945617\n",
            "Loss after iteration 197240: 9.593426\n",
            "Loss after iteration 197250: 9.627747\n",
            "Loss after iteration 197260: 9.477999\n",
            "Loss after iteration 197270: 9.127425\n",
            "Loss after iteration 197280: 9.450705\n",
            "Loss after iteration 197290: 9.752123\n",
            "Loss after iteration 197300: 9.686286\n",
            "Loss after iteration 197310: 9.531529\n",
            "Loss after iteration 197320: 9.568437\n",
            "Loss after iteration 197330: 9.372085\n",
            "Loss after iteration 197340: 10.674157\n",
            "Loss after iteration 197350: 9.725464\n",
            "Loss after iteration 197360: 9.552688\n",
            "Loss after iteration 197370: 9.757549\n",
            "Loss after iteration 197380: 10.299437\n",
            "Loss after iteration 197390: 9.261856\n",
            "Loss after iteration 197400: 9.312706\n",
            "Loss after iteration 197410: 9.843688\n",
            "Loss after iteration 197420: 9.489587\n",
            "Loss after iteration 197430: 9.680738\n",
            "Loss after iteration 197440: 9.545023\n",
            "Loss after iteration 197450: 10.238935\n",
            "Loss after iteration 197460: 9.593067\n",
            "Loss after iteration 197470: 9.621406\n",
            "Loss after iteration 197480: 9.842056\n",
            "Loss after iteration 197490: 9.410813\n",
            "Loss after iteration 197500: 9.492259\n",
            "Loss after iteration 197510: 9.659992\n",
            "Loss after iteration 197520: 10.045500\n",
            "Loss after iteration 197530: 10.107597\n",
            "Loss after iteration 197540: 9.461116\n",
            "Loss after iteration 197550: 10.029331\n",
            "Loss after iteration 197560: 9.347406\n",
            "Loss after iteration 197570: 9.333722\n",
            "Loss after iteration 197580: 10.012112\n",
            "Loss after iteration 197590: 9.725754\n",
            "Loss after iteration 197600: 9.914671\n",
            "Loss after iteration 197610: 9.633596\n",
            "Loss after iteration 197620: 9.499728\n",
            "Loss after iteration 197630: 9.552644\n",
            "Loss after iteration 197640: 9.277190\n",
            "Loss after iteration 197650: 10.192782\n",
            "Loss after iteration 197660: 9.933496\n",
            "Loss after iteration 197670: 9.610688\n",
            "Loss after iteration 197680: 10.108313\n",
            "Loss after iteration 197690: 9.772659\n",
            "Loss after iteration 197700: 9.999609\n",
            "Loss after iteration 197710: 9.683680\n",
            "Loss after iteration 197720: 9.626760\n",
            "Loss after iteration 197730: 9.843652\n",
            "Loss after iteration 197740: 9.939293\n",
            "Loss after iteration 197750: 9.915577\n",
            "Loss after iteration 197760: 9.447210\n",
            "Loss after iteration 197770: 9.405818\n",
            "Loss after iteration 197780: 9.295334\n",
            "Loss after iteration 197790: 9.099942\n",
            "Loss after iteration 197800: 9.039726\n",
            "Loss after iteration 197810: 9.186696\n",
            "Loss after iteration 197820: 9.164087\n",
            "Loss after iteration 197830: 9.681587\n",
            "Loss after iteration 197840: 9.304053\n",
            "Loss after iteration 197850: 9.746427\n",
            "Loss after iteration 197860: 9.537124\n",
            "Loss after iteration 197870: 10.023619\n",
            "Loss after iteration 197880: 9.281008\n",
            "Loss after iteration 197890: 9.344549\n",
            "Loss after iteration 197900: 10.560333\n",
            "Loss after iteration 197910: 10.258782\n",
            "Loss after iteration 197920: 10.022380\n",
            "Loss after iteration 197930: 9.723393\n",
            "Loss after iteration 197940: 9.198571\n",
            "Loss after iteration 197950: 9.140188\n",
            "Loss after iteration 197960: 9.790940\n",
            "Loss after iteration 197970: 9.343408\n",
            "Loss after iteration 197980: 9.765854\n",
            "Loss after iteration 197990: 10.628245\n",
            "Loss after iteration 198000: 9.980874\n",
            "Loss after iteration 198010: 9.597361\n",
            "Loss after iteration 198020: 10.357811\n",
            "Loss after iteration 198030: 9.355357\n",
            "Loss after iteration 198040: 9.422947\n",
            "Loss after iteration 198050: 10.483876\n",
            "Loss after iteration 198060: 9.263288\n",
            "Loss after iteration 198070: 9.176688\n",
            "Loss after iteration 198080: 10.012046\n",
            "Loss after iteration 198090: 9.623895\n",
            "Loss after iteration 198100: 9.288681\n",
            "Loss after iteration 198110: 10.452536\n",
            "Loss after iteration 198120: 9.723913\n",
            "Loss after iteration 198130: 9.262920\n",
            "Loss after iteration 198140: 9.232964\n",
            "Loss after iteration 198150: 9.344712\n",
            "Loss after iteration 198160: 9.197802\n",
            "Loss after iteration 198170: 9.195998\n",
            "Loss after iteration 198180: 9.200854\n",
            "Loss after iteration 198190: 9.322803\n",
            "Loss after iteration 198200: 10.052433\n",
            "Loss after iteration 198210: 9.497204\n",
            "Loss after iteration 198220: 9.324537\n",
            "Loss after iteration 198230: 10.397639\n",
            "Loss after iteration 198240: 9.990015\n",
            "Loss after iteration 198250: 9.825550\n",
            "Loss after iteration 198260: 9.416161\n",
            "Loss after iteration 198270: 9.850950\n",
            "Loss after iteration 198280: 9.562399\n",
            "Loss after iteration 198290: 9.584496\n",
            "Loss after iteration 198300: 10.285618\n",
            "Loss after iteration 198310: 9.704049\n",
            "Loss after iteration 198320: 9.643044\n",
            "Loss after iteration 198330: 9.776176\n",
            "Loss after iteration 198340: 9.589089\n",
            "Loss after iteration 198350: 9.270803\n",
            "Loss after iteration 198360: 9.866315\n",
            "Loss after iteration 198370: 9.918530\n",
            "Loss after iteration 198380: 9.485660\n",
            "Loss after iteration 198390: 9.591809\n",
            "Loss after iteration 198400: 9.537932\n",
            "Loss after iteration 198410: 9.609655\n",
            "Loss after iteration 198420: 9.552761\n",
            "Loss after iteration 198430: 9.704079\n",
            "Loss after iteration 198440: 9.297668\n",
            "Loss after iteration 198450: 9.517385\n",
            "Loss after iteration 198460: 9.541400\n",
            "Loss after iteration 198470: 9.804507\n",
            "Loss after iteration 198480: 9.063547\n",
            "Loss after iteration 198490: 11.256211\n",
            "Loss after iteration 198500: 9.750620\n",
            "Loss after iteration 198510: 9.378191\n",
            "Loss after iteration 198520: 9.758755\n",
            "Loss after iteration 198530: 9.950014\n",
            "Loss after iteration 198540: 9.073818\n",
            "Loss after iteration 198550: 9.194233\n",
            "Loss after iteration 198560: 9.299213\n",
            "Loss after iteration 198570: 9.373148\n",
            "Loss after iteration 198580: 9.277116\n",
            "Loss after iteration 198590: 9.816961\n",
            "Loss after iteration 198600: 9.952121\n",
            "Loss after iteration 198610: 9.447902\n",
            "Loss after iteration 198620: 9.437397\n",
            "Loss after iteration 198630: 9.447443\n",
            "Loss after iteration 198640: 9.877676\n",
            "Loss after iteration 198650: 9.538362\n",
            "Loss after iteration 198660: 9.477156\n",
            "Loss after iteration 198670: 9.716414\n",
            "Loss after iteration 198680: 9.600622\n",
            "Loss after iteration 198690: 9.786046\n",
            "Loss after iteration 198700: 9.751348\n",
            "Loss after iteration 198710: 9.588943\n",
            "Loss after iteration 198720: 10.088195\n",
            "Loss after iteration 198730: 10.057308\n",
            "Loss after iteration 198740: 9.532265\n",
            "Loss after iteration 198750: 9.384756\n",
            "Loss after iteration 198760: 9.398120\n",
            "Loss after iteration 198770: 9.563719\n",
            "Loss after iteration 198780: 10.641192\n",
            "Loss after iteration 198790: 9.543004\n",
            "Loss after iteration 198800: 9.570181\n",
            "Loss after iteration 198810: 9.619175\n",
            "Loss after iteration 198820: 9.580316\n",
            "Loss after iteration 198830: 9.784443\n",
            "Loss after iteration 198840: 9.510448\n",
            "Loss after iteration 198850: 10.525646\n",
            "Loss after iteration 198860: 10.046564\n",
            "Loss after iteration 198870: 10.025962\n",
            "Loss after iteration 198880: 9.369535\n",
            "Loss after iteration 198890: 9.651237\n",
            "Loss after iteration 198900: 9.773699\n",
            "Loss after iteration 198910: 9.515036\n",
            "Loss after iteration 198920: 9.547652\n",
            "Loss after iteration 198930: 9.948534\n",
            "Loss after iteration 198940: 9.536009\n",
            "Loss after iteration 198950: 9.656812\n",
            "Loss after iteration 198960: 10.322644\n",
            "Loss after iteration 198970: 9.392170\n",
            "Loss after iteration 198980: 9.665025\n",
            "Loss after iteration 198990: 10.537276\n",
            "Loss after iteration 199000: 9.444333\n",
            "Loss after iteration 199010: 9.307016\n",
            "Loss after iteration 199020: 9.365482\n",
            "Loss after iteration 199030: 9.261246\n",
            "Loss after iteration 199040: 9.529557\n",
            "Loss after iteration 199050: 9.836629\n",
            "Loss after iteration 199060: 9.536959\n",
            "Loss after iteration 199070: 9.547438\n",
            "Loss after iteration 199080: 9.445198\n",
            "Loss after iteration 199090: 9.456544\n",
            "Loss after iteration 199100: 9.952911\n",
            "Loss after iteration 199110: 9.880498\n",
            "Loss after iteration 199120: 9.973653\n",
            "Loss after iteration 199130: 9.467731\n",
            "Loss after iteration 199140: 9.883424\n",
            "Loss after iteration 199150: 10.502701\n",
            "Loss after iteration 199160: 10.034449\n",
            "Loss after iteration 199170: 9.923807\n",
            "Loss after iteration 199180: 9.652203\n",
            "Loss after iteration 199190: 9.810939\n",
            "Loss after iteration 199200: 9.459057\n",
            "Loss after iteration 199210: 9.364088\n",
            "Loss after iteration 199220: 9.985088\n",
            "Loss after iteration 199230: 9.328461\n",
            "Loss after iteration 199240: 9.900276\n",
            "Loss after iteration 199250: 9.513305\n",
            "Loss after iteration 199260: 9.392399\n",
            "Loss after iteration 199270: 9.903615\n",
            "Loss after iteration 199280: 9.359568\n",
            "Loss after iteration 199290: 9.867211\n",
            "Loss after iteration 199300: 9.383589\n",
            "Loss after iteration 199310: 9.461397\n",
            "Loss after iteration 199320: 9.555191\n",
            "Loss after iteration 199330: 10.029393\n",
            "Loss after iteration 199340: 9.661829\n",
            "Loss after iteration 199350: 9.182083\n",
            "Loss after iteration 199360: 9.226065\n",
            "Loss after iteration 199370: 9.777312\n",
            "Loss after iteration 199380: 10.180735\n",
            "Loss after iteration 199390: 9.685468\n",
            "Loss after iteration 199400: 9.709450\n",
            "Loss after iteration 199410: 9.649643\n",
            "Loss after iteration 199420: 10.159774\n",
            "Loss after iteration 199430: 9.977341\n",
            "Loss after iteration 199440: 10.021264\n",
            "Loss after iteration 199450: 9.939504\n",
            "Loss after iteration 199460: 9.515252\n",
            "Loss after iteration 199470: 9.997245\n",
            "Loss after iteration 199480: 9.950586\n",
            "Loss after iteration 199490: 9.752246\n",
            "Loss after iteration 199500: 9.742531\n",
            "Loss after iteration 199510: 9.418281\n",
            "Loss after iteration 199520: 9.633504\n",
            "Loss after iteration 199530: 9.914354\n",
            "Loss after iteration 199540: 10.091458\n",
            "Loss after iteration 199550: 10.187460\n",
            "Loss after iteration 199560: 9.400109\n",
            "Loss after iteration 199570: 10.150789\n",
            "Loss after iteration 199580: 9.762877\n",
            "Loss after iteration 199590: 9.298693\n",
            "Loss after iteration 199600: 9.974345\n",
            "Loss after iteration 199610: 9.210370\n",
            "Loss after iteration 199620: 10.037073\n",
            "Loss after iteration 199630: 9.448380\n",
            "Loss after iteration 199640: 9.608145\n",
            "Loss after iteration 199650: 9.486372\n",
            "Loss after iteration 199660: 9.819289\n",
            "Loss after iteration 199670: 9.425945\n",
            "Loss after iteration 199680: 9.857045\n",
            "Loss after iteration 199690: 9.481057\n",
            "Loss after iteration 199700: 9.967182\n",
            "Loss after iteration 199710: 9.324264\n",
            "Loss after iteration 199720: 9.319500\n",
            "Loss after iteration 199730: 9.399753\n",
            "Loss after iteration 199740: 9.408219\n",
            "Loss after iteration 199750: 9.911988\n",
            "Loss after iteration 199760: 9.843707\n",
            "Loss after iteration 199770: 9.321952\n",
            "Loss after iteration 199780: 9.203435\n",
            "Loss after iteration 199790: 9.015439\n",
            "Loss after iteration 199800: 9.551183\n",
            "Loss after iteration 199810: 9.704511\n",
            "Loss after iteration 199820: 9.501349\n",
            "Loss after iteration 199830: 9.725505\n",
            "Loss after iteration 199840: 10.068298\n",
            "Loss after iteration 199850: 10.712527\n",
            "Loss after iteration 199860: 9.965009\n",
            "Loss after iteration 199870: 9.390932\n",
            "Loss after iteration 199880: 9.899877\n",
            "Loss after iteration 199890: 10.117699\n",
            "Loss after iteration 199900: 10.311710\n",
            "Loss after iteration 199910: 9.553080\n",
            "Loss after iteration 199920: 9.162378\n",
            "Loss after iteration 199930: 10.666202\n",
            "Loss after iteration 199940: 9.715346\n",
            "Loss after iteration 199950: 9.579871\n",
            "Loss after iteration 199960: 10.002164\n",
            "Loss after iteration 199970: 9.318822\n",
            "Loss after iteration 199980: 9.490012\n",
            "Loss after iteration 199990: 9.482680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1wHs01O__LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dee67b8a-4a07-4f4d-8c9c-6e558bbf455e"
      },
      "source": [
        "visualize(X, y, model)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exp_scores predict  [[-0.16691571]\n",
            " [-0.15745649]\n",
            " [-0.14867885]\n",
            " [-0.14025302]\n",
            " [-0.13178592]\n",
            " [-0.12282744]\n",
            " [-0.11288434]\n",
            " [-0.10144362]\n",
            " [-0.08800705]\n",
            " [-0.07213743]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAH4CAYAAACWvlHqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3wUxfsH8M8kAUINJfSqgoCAhCIKiqjYUOyCoj8FRcFesLcvgkgRQRBE6SAo3ULvvbck9F5CIoFASCM9md8fx1z27nav5fYuwOf9evEit7e7N0kue8/OPPOMkFKCiIiIiIjMExToBhARERERXesYdBMRERERmYxBNxERERGRyRh0ExERERGZjEE3EREREZHJGHQTEREREZmMQTcR0TVKCNFDCCGFEPUD3RYiousdg24iIiIiIpMx6CYiIiIiMhmDbiKi65QQopgQYoAQ4pQQIvvK/wOEEMU0+4QIIb4TQhwXQmQKIS4IITYKIe7S7POCECJSCJEmhEgRQuwVQvQOzHdFRFQ0hQS6AUREFDBTAXQFMBDARgDtAHwF4EYAL1zZ5zMAH17ZHgWgHIDWACoCwJXgezqAnwF8AktnTiMA5f31TRARXQ0YdBMRXYeEEE0BdAPQT0r57ZXNy4UQuQC+E0IMllLuAdAWwHIp5UjN4Qs0X98BIElK+YFm23ITm05EdFViegkR0fXp7iv/T7fbrh53uPL/DgCPCCG+F0LcJYQobrf/DgAVhBDThRCdhRDs4SYi0sGgm4jo+lTxyv9n7bbH2z0/EEBfAI8D2ADgohBishAiHACklOsAdAFQG8DfABKEECuFELea2XgioqsNg24ioutT4pX/q9ltr6Z9XkqZI6UcIqVsBqA6LPndzwD4RR0gpZwrpewAoAKAp67st1QIwc8YIqIreEEkIro+rb/y//N221+88v9a+wOklPFSygkAVgJoqvN8mpRyIYCxsATelXzWWiKiqxwnUhIRXfseFkLE221LBjADwLdCiBAAm2GZNPkNgBlSyr0AIIT4F0A0gN0ALgFoAeBhWAJrCCH6A6gKYA2A/wDUAvAegCgpZYLJ3xcR0VWDQTcR0bVvlM62/QBaAjgB4FUAX8MSNA8B0E+z33pYcrbfBlAKQAyAHwB8f+X5bbAE2T/Bkgd+HpbqJd/4+psgIrqaCSlloNtARERERHRNY043EREREZHJGHQTEREREZmMQTcRERERkckYdBMRERERmYxBNxERERGRya6LkoHh4eGyXr16fn3NyLORyJf5aFG9BYK4KBsRERHRNW/Xrl0XpJSV9Z67LoLuevXqYefOnX59zdIDSyM9Jx0bvtiA0sVL+/W1iYiIiMj/hBCnjZ67LoLuQHgl4hVk52UjJIg/YiIiIqLrHSNCk4x+ZHSgm0BERERERQSTjYmIiIiITMaebpOoiZQR1SIQHBQc6OYQERERUQAx6DbJXZPvQnpOOtK+SONESiIiIqLrHNNLiIiIiIhMxqCbiIiIiMhkDLqJiIiIiEzGoJuIiIiIyGQMuomIiIiITMagm4iIiIjIZCwZaJKNr2xEvsxHaEhooJtCRERERAHGoNskLaq3CHQTiIiIiKiIYHoJEREREZHJGHSb5N3F76LXgl7IzM0MdFOIiIiIKMAYdJtkctRkjN89Hrn5uYFuChEREREFGINuIiIiIiKTMegmIiIiIjIZg24iIiIiIpMx6CYiIiIiMhmDbiIiIiIik3FxHJNEVItARm4GggTva4iIiIiudwy6TbLx1Y2BbgIRERERFRHshiUiIiIiMhmDbiIiIiIikzHoNkmZgWUg+gmkZacFuilEREREFGAMuomIiIiITMagm4iIiIjIZAy6iYiIiIhMxqCbiIiIiMhkfq/TLYSYBKAzgPNSyqZXts0C0PDKLuUBJEkpI3SOPQUgFUAegFwpZWu/NJqIiIiIqBACsTjOFACjAfyuNkgpn1NfCyGGAUh2cvy9UsoLprWOiIiIiMjH/B50SynXCyHq6T0nhBAAugK4z59tMsPPnX5Gbn4uSgSXCHRTiIiIiCjAitoy8O0BnJNSHjV4XgJYLoSQAMZKKcf5r2meebXFq4FuAhEREREVEUUt6O4GYIaT5++SUsYJIaoAWCGEOCSlXK+3oxCiF4BeAFCnTh3ft5SIiIiIyE1FpnqJECIEwNMAZhntI6WMu/L/eQB/A2jjZN9xUsrWUsrWlStX9nVzXZocORnjdo1Ddl6231+biIiIiIqWIhN0A7gfwCEpZazek0KI0kKIsuprAA8C2OfH9nnkvaXvoffC3sjKzQp0U4iIiIgowPwedAshZgDYAqChECJWCNHzylPPwy61RAhRQwix+MrDqgA2CiGiAWwHsEhKudRf7SYiIiIi8lYgqpd0M9jeQ2fbfwAeufL1CQDNTW0cEREREZEJilJ6CRERERHRNYlBNxERERGRyRh0ExERERGZjEE3EREREZHJitriONeM1C9SA90EIiIiIioi2NNNRERERGQyBt1ERERERCZj0G2SuyffjVbjWiEtOy3QTSEiIiKiAGNOt0mi4qOQmp2KfJkf6KYQERERUYCxp5uIiIiIyGQMuomIiIiITMagm4iIiIjIZAy6iYiIiIhMxqCbiIiIiMhkrF5ikh4RPZCZm4liQcUC3RQiIiIiCjAG3Sb5udPPgW4CERERERURTC8hIiIiIjIZe7pNEnk2EvkyHxHVIhAcFBzo5hARERFRADHoNkmHKR2Qmp2K5M+TUa5EuUA3h4iIiIgCiOklREREREQmY9BNRERERGQyBt1ERERERCZj0E1EREREZDIG3UREREREJmPQTURERERkMpYMNMm6HuuQL/NRuljpQDeFiIiIiAKMQbdJWlRvEegmEBEREVERwfQSIiIiIiKTMeg2yftL3kevBb2QnpMe6KYQERERUYAx6DbJlOgpGL97PHLycgLdFCIiIiIKMAbdREREREQmY9BNRERERGQyBt1ERERERCZj0E1EREREZDIG3UREREREJuPiOCaJqBaBtOw0BAne1xARERFd7xh0m2Rdj3WBbgIRERERFRHshiUiIiIiMhmDbiIiIiIikzHoNknY4DCIfgLJmcmBbkqRkZGTgbz8vEA3g4iIiMjvGHSTX6Rlp6HUwFJo/lvzQDeFiIiIyO8YdJNf7Du/DwCwP2F/gFtCRERE5H8MuomIiIiITMagm/wirERYoJtAREREFDAMuskvypYoCwCoWbZmgFtCRERE5H9cHIf8omRISTzV6ClULFkx0E0hIiIi8jsG3SYZ+fBIZOdlIzQkNNBNKRJKFiuJrk26omRIyUA3hYiIiMjvGHSbpEdEj0A3oUhJzEhEt3ndULNsTTzR6IlAN4eIiIjIr/ye0y2EmCSEOC+E2KfZ9q0QIk4IEXXl3yMGxz4shDgshDgmhPjcf62mwsrNzwUAxKXGBbglRERERP4XiImUUwA8rLP9JyllxJV/i+2fFEIEA/gFQCcAtwDoJoS4xdSWFsKUqCkYt2scsnKzAt2UIuFc2rlAN4GIiIgoYPwedEsp1wNI9OLQNgCOSSlPSCmzAcwEUGTzFD5Y+gF6L+yNjNyMQDeFiIiIiAKsKJUMfEcIsedK+kkFnedrAjijeRx7ZRsRERERUZFWVILuXwHcBCACwFkAwwp7QiFELyHETiHEzoSEhMKejoiIiIjIa0Ui6JZSnpNS5kkp8wGMhyWVxF4cgNqax7WubDM65zgpZWspZevKlSv7tsFERERERB4oEkG3EKK65uFTAPbp7LYDQAMhxA1CiOIAngcw3x/to8KrUbYGAKBM8TIBbgkRERGR//m9TrcQYgaAewCECyFiAfQFcI8QIgKABHAKQO8r+9YAMEFK+YiUMlcI8Q6AZQCCAUySUu73d/vJO0HCcn9XrkS5ALeEiIiIyP/8HnRLKbvpbJ5osO9/AB7RPF4MwKGcIBV9lUpVwpIXl6BEcIlAN4WIiIjI77gipUmSPk8KdBOKlJSsFPyw6QdULl0Z995wb6CbQ0RERORXDLrJL7Jys7Dm1BrUKlcr0E0hIiIi8rsiMZGSrn3JWckAgNiU2AC3hIiIiMj/GHSbpMOUDmg1rhVSs1ID3ZQiIS07LdBNICIiIgoYppeYJDo+GslZyciTeYFuChEREREFGHu6iYiIiIhMxqCbiIiIiMhkDLrJL0qGlAx0E4iIiIgChkE3+UV4qXAABcvBExEREV1POJGS/CI4KBh1wuqgaumqgW4KERERkd8x6DZJ9+bdkZGbgeLBxQPdlCKhUslKWPnSSoQE8S1HRERE1x9GQCYZ2WlkoJtQpJxNO4ubR9+M2uVqI+bDmEA3h4iIiMivmNNNRERERGQy9nSbJCo+Cnn5eWherTlTKgDEp8UDAM6knAlwS4iIiIj8j9GgSe6dei+SMpOQ+GkiKpSsEOjmBFy+zA90E4iIiIgChuklREREREQmY9BNRERERGQyBt1ERERERCZj0E1+UaV0lUA3gYiIiChgGHSTX4SGhAIAqpepHuCWEBEREfkfq5eQX5QtXhYD7h2AMsXLBLopRERERH7HoNska7qvQV5+HsqWKBvophQJufm5SMpMCnQziIiIiAKCQbdJIqpFBLoJRUpqdip+3PIjaperja/u/irQzSEiIiLyK+Z0k19k5GQA4IqUREREdH1i0G2SD5Z+gF4LeuFy9uVAN6VIYGoJERERXc8YdJtkavRUjN89Htl52YFuChEREREFGINuIiIiIiKTMegmIiIiIjIZg27yi5AgFsohIiKi6xeDbvKLGmVrAACqlakW4JYQERER+R+DbiIiIiIik3HM3yQR1SKQkpWCIMH7GgCoWqYqEj5JgIAIdFOIiIiI/I5Bt0nWdF8T6CYUKbEpsWj2azPULlcb+97aF+jmEBEREfkVu2HJL6SUSMlKQWp2aqCbQkREROR3DLrJLxIzEgEAMckxAW4JERERkf8x6DZJxSEVIfoJa7B5vcvKywp0E4iIiIgChkE3EREREZHJGHQTEREREZmMQTcRERERkckYdJNflA8tH+gmEBEREQUMg27yi7ASYQC4DDwRERFdn7g4DvlFaEgonmr0FHu8iYiI6LrEoNskPz30E7LyslCqWKlAN6VIKB5cHF2bdOXPg4iIiK5LDLpN0j2ie6CbUKQkpCeg27xuqBtWF483fDzQzSEiIiLyK+Z0k1/k5ecBAM6knPH6HFJK9FvbDwsOL/BVs4iIiIj8gj3dJpkaNRVZeVl4ufnLCA0JDXRzAi4hPQEAkC/zvT7HpjOb8O26bwEAsq/0RbOIiIiI/II93Sb5cNmH6L2wN9Jz0gPdlGtGbn5uoJvgkVNJpzD3wFxIyRsEIiKi6x17uumqocoNNqzUMMAtcc8NI28AAPz7/L/MYyciIrrO+b2nWwgxSQhxXgixT7NtqBDikBBijxDibyGEbl05IcQpIcReIUSUEGKn/1pN5L3Is5GBbgIREXlh4u6JGLdrXKCbQdeIQKSXTAHwsN22FQCaSilvBXAEwBdOjr9XShkhpWxtUvuoiMrMzQQAHL542Cfne3fxu+j5b0+fnIuIiK49ry14Db0X9rYWAyAqDL8H3VLK9QAS7bYtl1KqhN2tAGr5u11krjphdQAAJUNKen2O00mnfdUcAMDoHaMxKWoSLmdf9ul57VUtU9XU8xMRkTkEhOV/IQLcEroWFMWJlK8CWGLwnASwXAixSwjRy49tokIKEpa3WrkS5bw+R+XSlX3VHBuqbb72QrMXcFOFmxBRLcKU8xMRkbkkOBGefKdITaQUQnwFIBfAHwa73CWljBNCVAGwQghx6ErPud65egHoBQB16tQxpb3uYOUKiwqhFbDkxSUoHlzc63NUKlkJAHBzpZt90qaQoBDk5uciJMicP4M/njZ6GxMR0dVESgmws5sKqcgE3UKIHgA6A+goDSJVKWXclf/PCyH+BtAGgG7QLaUcB2AcALRu3drvkW/iZ4mud7qOXMq8hB82/YCqZarivhvuC3Rz/OJ44nFczrmMmyrchNLFSwe6OURE5KV8mY9gBAe6GXSVKxLpJUKIhwF8CuBxKaVuYWshRGkhRFn1NYAHAezT25eKnszcTKw5tQZbzmzx+hwpWSkAgCMXj/ikTarud2EW7HGmx7890Py35th9drcp5yciIqKrRyBKBs4AsAVAQyFErBCiJ4DRAMrCkjISJYT47cq+NYQQi68cWhXARiFENIDtABZJKZf6u/1kLD4tHouPLtYNMlOzUgEAp5O9nwwZlxrn9bFtxrdBxSEVcfTiUYfncvJzvD6vMxtjNgIA1p/WHYwhIiKi64jf00uklN10Nk802Pc/AI9c+foEgOYmNs2n7pt6H5KzkrHq5VUoH6pbdvyasylmE56d8yyebvw05nWdZ/Pc5RxzK4S4suO/HYbtMCunW8mTLDVFRER0vSsS6SXXouhz0dh9dvd1Vdtz+fHlAIC/Dv5lyvnrhtUt9DliU2KtX6tJnYKzY4iISIfqlGEVE/IFBt3kM2k5aR7t329tP0yNmur2/qEhoQCARuGNPHodLb05umZfTBnUExFdnXj9Jl8qMtVL6PpyLPEYvl33LQCge0T3gLQhOy8bQMGESiIiIkVKadqcH7o+saeb/CI5M9nmsTcrU567fA4AcOjCIZ+0iYiIyIi2slWxoGIBbAldKxh0B0hOXg4OXzgc6Gb4RFZuFv635n9OS+PNOTDH5rHKk6tSuorbr2MfuBd14aXCAQC3Vr01wC0hIiJvBYkgLgNPPsH0kgB5atZTWHR0EWY/OxtdmnQJdHMKZeS2kfhu/XdO95l/eH6hX0etRFm1dFWvz6G3lHxhVsl0ZlSnUYhJjuEy8EREVyFOniRfY9BtkpdvfRmXcy6jREgJ3ecXHV0EAJgaPfWqD7qPJR6zedy+TnuHfcqHlkdCeoL18aXMSwCA85fPu/06wUGW1cDKlSjncRvrV6yPY4nHrEvJA0CwCEaezEOQMGfA5/mmz5tyXiIi8p98mY/svGzTOmjo+sGg2yQ/PfxToJtgupUnVqJe+Xo22/rc0QdNqzR12Fdbqg+wrFBZWMcTj+PwxcN4pMEjLvdd9MIiZOdlo05YnUK/rruGbR6Gk0kn0adtH9xY4Ua/vS4RERWettqVWSsX0/WFQbef5OXnITYlFnXL29aa9mcQ6EuHLhzCA9MeAAC83vJ16/ZhDw1z63hvFqQ5nWRZzfJoomVVyfqj6gMAtvTcgjtq3eH02JOXTiIlKwV1wupYRx/UojXZedk+XSAnLz8PeTIPH6/4GADQ8YaODLqJiK5ieuVmTyWdQkxyDOqG1XX4bCfSw4mUJomKj8Ku/3ZZy9E9OetJ1BtZD0uOLgEAdGtqWZjzrjp3BayNhaHu+huHN8bwh4bjyDtH0LNFT4h+An3X9HXYPyM3w+axSvOoVqaa269ptKrlubRzLo/9cNmH6Dq3q0OPO+D7HozJUZNRYkBBWtH+hP0+PT8REQXepMhJ6DClA6ZGu7/eBF3fGHSbpOPvHdF6fGtrxY2FRxYCsARkANDvnn7Y0nMLHrzpwYC10VfKFC+DBpUaYGLkRABA//X9ne5/JvkMPlj2gcevUyLYNj9eTVB0Z7Tg4IWDAGwDdLXYTrAI9rgtzthXaqFr3+Xsy1h0ZBGycrMC3RQiciElKwVtxrfB/b/f73Q/X46AEgEMugOmXIlyCC8V7hBIFjW+WjimU/1O1q+/XvM1Zu+f7fE5tMN3tYbXQlR8lMfnSM1O9fgYT13KuGT6a1DR0v2f7ug8ozM+Xv5xoJtCRC5czr6MHf/twKqTq5zuJ4Swds7oVTJRVbv6r3Pe0USkMOj2M1Xrs8/yPmgwqoFPSukZuZRxCRfSLyAvP8+r4w8kHECx74rh69VfOzynKpYcvHAQI7aOgOjnvIbpO23esX5dv0J969fxafHWry+mX9TNm9MTlxpn/doo7cQVNZnzWlwGPiUrxe+veT2bd3AeAODPfX8GuCVE5Ip9uqMz7ly/OcmS3MWg209eaPYCSoaUxHNNngMA/LnX8uG887+dpr1my3EtUXloZcQkx3h1/JBNQwAA32/43uE5bQ/4gYQDLs9VsWRFp88vOrII4UPD8e6Sdz1sZeFXqPT2psTfpJRutbXvmr4IGxyGvw/+7YdWERFdm3Lzc60BulmlZen6wneRn/zx9B9I/yodTzd+2ma7qsRhhlNJpwAAF9IveHV86WKlDZ/bc26PR+c6mHDQ+rWq0Q0AlUtZFqv5YfMPAIBfdvxieI6jF/V/Vr7Oyfa1UsVK6W4ftnkY2k9uj38O/ePWeR6b8Ria/9bcZeCtcur/t/Z/njWUCi0QoxpEZA51rS0eXNyaZqKHi+iQuxh0XwOOJR7D6O2jkZOXo/t8WnaaV+d94EZLScAnGz3p8Fy/df08OteEyAnWr0dtH+Vy/7TsNKRlp9mkmxgtiuPJMut6QZHZy/s2r9Zcd/uxxGPYGLMRZ1PPunWejTEbsT9hv8u89EcbPAoA6HpLV88aSl6b/exs9GzRE9OemhbophCRjzCYJl9j0O0nL/71Iur/XB/Lji3z6LiMnAx8uPRDbDmzxXCfBqMa4N0l7zrtJTaL6ql2ZfOZzbrbVQDZqnorm/OVHVQWZQeVtdm3Vrlauudw58Ko0lsahje0blPDhSVDSro83l3jd423liWsG1YXSZ8l4e66d+vuezHjIgDfT+6sXa42ACC8VLhPz0vGujTpggmPT0CnBp1c70x0lVp/ej26zeuGi+kXA90Unzp/+bzT7yk7L1s3b/vt294GALzV+i3T2kbXFgbdJln18irsfH0nwkLD8F/qf/hz7584fum4x1U7RmwdgRHbRqDdpHYu9/0v9T9vm+s1vWVxiwUVc/t4NZmxWZVmAIBHb37UugiOu95a9JbLqhH33XAf2tZqa5jq4QupWanotbAXzqadxXtt3sPg+wcjLDTMsOyUKi2o8vvJdzJzM6+5wIAo0DpM6YCZ+2bii1VfBLophaL93MrLz0PVH6sifKjzTorL2Y4T9lUnka86OM5fPo+zqWc5MfMaxqDbJBHVItCqRiuEBIVgR9wO63b7Xs30nHQ0/605/rdGP/9WLane+ebOhq/1RMMnAADtarsOzD2hKoSsP73euk1KaVMZQ1tFRBn9yGin59WWD1QahjfEG63eQJPKTVBvZD3d47LzsnW37/hvh7X+uZE5XeZgc8/NNr3l6sKm7Sk/evEotsZuNcyD/3j5xxixdYTL9g1/aDi6zesG0U9gW+w2p21zV3KWpeZ7UmaS0/2m750OAFh9arVXr3Mm+Qw+X/m522kvRVGt4bUQPjTcb4H3pys+RVC/IAzdNNQvr0cUSOcuu16QrCgrU7wMBATKh5a3dvzocVVNq1ODThjdaTQeafCIT9rVaHQj1Bheg2Vnr2EMuv1MBXgqmE7KTMKec3us9T6LEhWgtq/T3rotMzcTYYPDbPZrWb2lzWNXFVns9weAGmVroGmVpg53+DYBsZNJp4kZiU5f8/X5r+OBaQ/g5KWTDs9pezBuHn0z2k5si35rHXPWTyWdwrAtw/Dhsg+dvhYAvPzPy9avd5/d7XJ/T7jqBVE5/Goirac6z+iMIZuGoMucLl4dXxSo1J195/f55fWGbh4KCYmhm80PupMyk7AtdhsOXzhs+muR96SUSM2ydLKcTT2LXf/tQlyKYyfF1USlAar5Pler8qHlkd83H5c+u4TgIMtEfL1RWy29NMbTSaexOXazz0aZVcpj74W9cf/v97PH+xrEoNskfZb1Qa8FvZCalapbauiR+o+gWZVmuLnSzW6dz9kdt+r5NFoNr0rpKm69hlvtsLvwVCxZEW+0fgOyb8H28bvHu32+GmVrAAAen/E43lnyDj5b+ZlvGmpn7em1WHlipe6kUr3fz+lkxxQXV1VStBMytSkj2mot/qDyC3s07+HV8aoyjZnlLIs6vVGVC+kX0GdZn0KXqPRGcmYyEi4nAAA2xWzCHRPvQJ/lffz2+lJKzNo3S/emlfQ9NuMxlBtcDscTj2Ni5ES0Ht8av+78NdDNckt6TjqenvU05uy3XV23fkXLGgtX+3yR3PxcRMVHYe+5vdbPVm8m2e85twd/7v3TZzf3qrNg3sF5WHVylWHFrmuVlBLPzX3uml5kjEG3SX6P/h3jd49HVl6WbmA95IEh2PPmHpfDUmtPrQUALDq6yHCfdafXAQAWH1tss73zzZ3RqnorVChZwcPWW5y4dAIAsPz4cq+ON6K3kuTe83tdHleYmwe1mM/JpIKgQZVE1Luw6vVqlCxmmXBZqWQlaw+WVliJMPzznHvl/4CC3PcGlRq4fQxgfAP28fKPdRcy8pSaiHlTxZsKfS49p5NOQ/QTLhdUCpRtsdtQYkAJh5Sv0dtH46etPzkd6XC3Es7jMx7HEzOfcLtN5YeUR5UfqyArN8s6grH46GLnB/nQ34f+xvPznseNP9/ot9e82qlr9twDcwPcEs+N2TEGfx/6G13nXpsVkJIyk9BibAvcO/Ve67Ve7283NCQUZYtbJvTrXXejzlk+y3ad3WVKOyuVqmTKec1wMf0i0nPSC3WOuNQ4zN4/G8O2DPNRq4oeBt1+oK2YoczcNxOfrvjU5cqBnlS2qFOujs3jBd0WYGevndbeZE9FxkcCcL56V2JGIi6mX8Sak2vcPq+2l8STYbmwEmGud3JB78Lp7iqYar+LGRdRbnA5h+85OCgYs/bPcjjOqHbzKxGvAADuv+F+t15fOZNyxmFbRk4Ghm0ZZrOQkbflrro37w4AeL7J814d74qzfNCNMRux9NjSQr/GDeVvQLAIRr3y9Tw+Vs0PsE/5UpOmbixfuMBTSokFRxZ4tRptZm6mWzeovubrFClncvNz0eOfHpixd4bfXtNsU6OnAsBV09OtyrDeUesOm+1qlEe7kvDVSHWaXMy4iKlRlt+NUW63sxvphUcWAgD+Pfyv26+dcDkBP27+EVOjpmL96fWIjo92+9iiKi07DeFDw1F+cPlCnUd1hJUP9ew8kyIn4eW/X74qFrpj0O1nagn0RUcXYejmoQgJCsGmVzchsnek1+dUdbTtc6XH7BiDgRsGmk5E7OgAACAASURBVD4p48tVX+K+3+9ze/8bKzgPWjK+KgjypZTYcmYLMnLcX7ZXK1/mY92pdbrPqeXj9YJTvUDcPuVALeijfa0Z+3wXKEgpEXk20uHDwD4AysvPsxmNGLNzDABg2h7f14zefGYzHpr+kHUUxNfaT26PTn900h1J8MSJ908g93+5qFu+rsfHqhKP3Zp28/hYsxbHUR9GKv/U3xqFNyrU8QmXE/DiXy8alg7VmntgLqZGT8ULf71QqNf0l6zcLPT4pwcWHF6g+3yNsjWsoxOu5p4UBetPr8dD0x8C4FhOtUmVJgCAvw7+5TRYXHF8he6IZlGhzZV+a7FxuT8ppc/zquPT4vHJik/w5eov0WFKB0SMjfDp+bUupl9Eo9GN0G6ib4ss2FNpZzn5+muFmK3n/J6YtmeaX0f/vMWg2w+OJx63fv1cU8sy8NP3WCpMLDyyEO1qt0NENf0/PDVhRVvrudu8bugwpYNDYGgfPA7bMgxfrf4qIBd6Vc91zA5LANiwkmNvv5ESwSWsX4/dNRbtJrXD4zMft1bv8MSvO37FPVPv8fg4vUDcPh/8xWYv2jz+edvPHr1G1yZd8eMDPyIkKER3YaOZ+2ai5biW1g9AI8O3DMeTsxwXMNIrceWOe+rdg2/u/gbt67Z3eO7OSXdi+fHleHj6w6ZO5CuKE4hUD31MSkxA2xGIVS/VaNk99e7RfT4vPw/tJrbDmwvf1H3+o+Uf4c+9f+LOSXe6fC1vb7hiU2INb7DtSSkxYP0Aa09lYYzfPR5To6fi8ZmPW7ep/HvA0smQm59b6Nfxl46/d3S5z4aYDYbB4tnUs3hw+oNoMbaF26+Zl5+H7XHbi9w8kss5l63XfV+Vm1WBoTujvMmZnn/maWXmZuLwxcPYEmu8zocvlClexifnUZ+7rip0GSlseos/MOj2A5VPDMAhuI5NicV7S97D4I2DdY8tEWIJQLWpFTP3zcT60+uRkG65sKteFPs/UNUbqTcp0B1NKlt6Nbz5kP927beYuW8m3l5sWTxA22u44sQK69eVSlay+YACgKD+lrfloI6DrBeolSdWOuznjh3/7bB5LISAlNKrgLRsCdvFeux/Ln8d/Ev3OKPe1r8O/oWPV3yM1xa8hrcWOfa2zNw/E4BtyUa9140+V9DjpK2R7m0O/IhtI/Dd+u/w0fKPDPc5mngUjX5p5NWsfWfvJ7XUcrFg92u96+k6pyvaT27vVfvUe0NNalJUbq5eoKa+p6plqro8vzcroKpRGWflzXxJSmkzVOvqGhAZH4ktsVvw267fdJ9XC0YBlvkuzhitPOtK7Z9q456p92DXf67za08lncI3a75Bn2WFn4yqbki09fg/WPaBw/O+kJqVano6gvYGYc0p2xS6c2muSwUalVs1IvoJhHwXgtsn3I4OUzp4dKwvOXuPly5WutDXJOWr1V/pbv9unWMFs8J2PnjTUeWN0sUtI3HuLpZnpLCj8r4sGmEWBt1+kJVXUFXE/oIUfS4ao7aP8mixATWxQwUoahhv7em1hWyprQYVLRP8nmr8lHWb0UIvrozYVlDbemPMRpvnJkVO0j1GQFhrkL8a8apXqQId6tpexI8nHscD0x5AmUEFd+banvXXW76O8qHl8fKtL8Oe+nkbCQvVzzlvVqUZUrJSnPbgTYicYPP4+/XfY3vcdgAFq2kqrWq0svlgvLfevTbP927VG4ClJ90be89Zcob18nhVrqfiTW+3s1xzZ5UE7MWlxOGjZR/pLqY058AcbIzZ6FXZxL8P/Q3AswnE+X3zIftKRL/hXkA08L6BGHjfQLfnEyh6IyJaZ5LP4OSlky73c6XdpHaoN7KeNfBWQbOa2G3PVQ6m9sOw+z/dne6rJvCq8nTuUsG69nprxJfD4JVKWia7addJKBVS0Cvq7UR2PRFjIxAxNsLw92C2VSdXudyncmlL4OVNAORuT6UZI2Huphlq1Q2zfCap8rqXMi65zHfPk7Z5x6pD7X9rHdfqUJP3veXp9eVqdUvlWwAw6L6uNa/WHC2rt3QoMzdz30yPzqMCrwVH9PMFfWFK1BQsOmJcHUWreHBxvHPbO9bH7paOMhouuphxEXXC6ug+9/mqz23K7TkbwvqorXGvrJYqxaSlrc867rFxuPTZJWsakDP21WIeukk/DWT87vEIGxyGcoNte/D+Oaxf6SQpMwlfr/naevF+8KYHARTcbHWY0gE3/WwJTE4nncb5y+etx/oimHA2MnJ3Hf0l7T3xx54/DJ9TAZM730eXOV0wfOtwdPrDeOn1ojqx5ov2X+Cjdh+hz7I+bqdEKHfVuQsA0Di8scNz7Se3x40/36i7aJUrp5JOocXYFvjr4F/YGrsVsSmx1qF19XfeukZr3WNVznm1MtV0n1fvYT0X0i9g3/l9eGj6Q04D8jn756D1uNY2veZa6jpin4fsjDeTjd0ZbdAG4KoEJwD8363/5/HraanRy2XHlhXqPEa8TUnTUjfMZgV8by96G2UHlfVq5NNbl3Mu684req3lawCAl299GVvObEHFHyqi+rDqHs1BcvYeVH9XRZ36fhPSE9B1TlcM3zLc43OcSjqle+NxrWHQbZJVL6/Crl67HHo5VHk/d+kFmqqiiertrFraMqR9R807HPZ1JT4tHq/8+wo6z3Bc8fKXHb8AcOzx06YzGPVIevJhVjustuFzq09aVlV0NSRvVGLIvvpLk8pNrEvOe8q+F8bZaofjOo+zfj1q+yjdfYxSH+xv1NTPWPu9xCTH4HL2ZdQbWQ9frv7Suj1IBFl7gfR6g04lncL60+sRk+ybvGQ1rOiJ/Qn7Xe5jVHNeS1XXOXjhoOE+EhKjto3yaFVQlVZlP6qjKjncUP4Gt8+14PACtJvYzubnnZefh8a/NEaJASUwYtsIhzkHcSlxmLB7gu7PIDgoGOVKlEOQCLLWTNZSN0zPzH7G7TYqby56E1HxUXhm9jPWD3tVw14NrbuqIGQUaDkLwD5b8Rma/doMy48vxz+H/sEtlW/Brl678PtTtmkoXed2xa6zuwxr+Kpaye7kT6tOAG3qn16bt8dtt6kwdeTiEZT8viR6/tsTgOV9qsqQ2qzcq7n+adP+apat6bJtgfTt2m9tHt9Z2zgH36ijw5v0KU+M2TkG6TnpNmsheMpoVNKe9vfo7GZra9xWtJtUcKM1MXIiRm4d6dZrOKtgZvbP0le0nSRzDsxxmppoLzYlFlOipuDOSXdaf6f2o7uuPNXoKfSI6OH27zWQGHQXcSpA1KvnrS4Ct9e6HYB3uYN6C8MoKp9PO4EwLz8PG2I2WB+rvHJPfHan+wvgLDtu6dGZGDkRK46vcLG3I/s86+LBxR0qQKiqJBk5GRi+ZTi6zOmCTTGbkC/z0XtBb0yJmgLAcYKXqhqjqJ5owPPfxehOo61f29+wqBsPe3ql96SU1sWJRm8f7fD8uF3j0GFKB+tEXk81rtwYneoX9Cy7k8OnDR5XnVjl1hC1O5695VkAlguukeXHl+O9pe/hjonu35CqFJrnmtiOdtxW4zYA+iMawf2DIfoJtBxrW0Ho8ZmPY0vsFry35D2b7fYL7GiDv9bjW+P1Ba+j+rDqOJhguaFQ760SwSXwWMPHkPe/PMzvZlxy0JsSf9r5AIq7H/rqGqHek7/u+BWTIydbn3+q8VP44i5LCp192tOkqIL0MiklziSfQatxrfDULP3fq6v0EXeqZmhHh4wsOroIt0+4Ha3HFfTuq5HHaXumYfT20Qj9PlR3ArU2jVC7cEqLavqTCydHTsYv23+x6WnOl/mG6RbOrtuFceDCAbf2e+nWl/Djgz/qPnc29SwA7z4blJjkGOTLfKcdG2r0JTM30+NiASVDSlrTJ92l15H0UduPcOmzS3i3zbs2299d8i4+WPYBtpxxPYFRXUNvquC4LoLeIl2BZPR+LMxEylt/vRWv/PtKoVb1nH94PqZETbkqqgMx6A4Q9YH+cP2H3dq/MEN1zi7QqlfV3TtLvQ+8925/D33ucH9CkrZ3vGLJim5Pnvh4ReFXqbLPnQYsF+2kzCSUGlgKHy3/CHMPzMXAjQOxI24Hxu0eh1f+fUX3XPaz2bU9IXojB0aaVWmGt9u8bX1s/7s+f/k8ft3hWN9X70InIa3D7PYlJLW8rRKw//x+LDm2BJ+0+wTH3j1mzWW0Fx0fjW2x2zBg/QCEfh+KJUeXAIBNIKW9SVHse1adubmiZdEplc+npzA9+ll5Wbhr0l34YdMPLvdVowr2N0KP3fwYANjcqOhpMKoBtsZuBVBQA/lS5iXcMsbyvWmD373n9qLnvz3x05af3PxO3NP55oL3rJq4qW40VYqE0Q2TNn0sKzcLby1+C6/Of9W6bfHRxRi0cRAAoHqZ6oZtSM1OtX6vRnm7ruZW+KqCgQr41M8CKBhV7FCvA95dYgm01IgLUDARTLuYmTZYUxPj7b06/1W8s+QdHL5YMEei4+8dUXpgaZvJi6+1eA1NqzS1+V35Uvs6thWLUrNTkZiRaO2t73JLFwCWVB51oxiTHIO5B+ZaR5P0vsf0nHS387Bn7J2BuiPqIrh/MMKHhjtMXFY3v2qkp/ZPtVHph0oeTcKbGDkRRxMdV3s8mHDQo8oZA9YPQIUhFQxHWu1Tof49ZFzP+9EGjzpsc7ctRml0vqq4AgD91/VH6YGlfb5Ynt6KzYkZiR5XA7taMOg2SeWhlSH6CSRcTtANaF+JeAWjO412OVlI3bkdSHDsgVDBq1pkw36YXQVfngyH63GWV1apZCU0qdIEwx6yveho8yr1ll5XShUr5XZg5MmH6YlLJ/D5ys8dPpwyczMdesKEENgUs8lmm5TSOjlM9Yi4miymzQ13xlVOqP33KSEdasmGlwo3XJZeTT49f/m8tddJUROw1GRBb+Xk5SAnPwd91/bFFyu/cEiFeH7e87hj4h34Zs03AApumLTfu96kXHUj4aqnNjM3E0M2DQHgfNKl0SiBM2fTLD+zuQfmYtOZTfhspWVkRgUZ2vQqe/ZtUe8ZbaBolHqlgm49aghaQiIuNQ6ToiZZR4EKKyMnA0M3DdVNtVA9bdqApvW41g75tGrynLbyiNHfw5ut9csKKipv2b49qqPiiYZPIOFyApr92gy/7XSslmL08935306sOrEKSZlJNr8no0mJajVAbcWpARsGALAtA6udvNVrYS8AQMcb9MvueTICodqlXe1w/OPjsffNvWhbu63uMWeSz2DG3hleTzS0n1+z59weVPqhEsoPsb32fb/hezzyh2X0dWPMRnSZ08U6WV69B9TNVWpWKsoPLo8Hpxnn9WtpJ90DxqmD6uZMjSq407P+2IzHcMeEOwzXU7hlzC3451DBXBtXN3iKUdDbdW5XTNhd0NGjl1qnvo+RnRzTUbST/I2cTjqNYt8V063Eoypuqcm+nrqcfRmrT65Gbn6u9YbwyMUjDvvZX/89eT01YmnfgfP+0vfdXihNLRjmzghWoDHo9gO9ZeAfqv8Q3m7ztsv8YlXpQzu5TQXB9iXs7APzQR0HYWznsU57sVVA7GxY5nLOZd2gHzBerGPSEwVDxvYVJLSTQgUEWtXwrEqBO9pPbo8hm4bgkxWfuLW/Xq+x/dC6/eN1p9bh0IVDmBQ5CVJKl0NsZYqXwcIjC1Hy+5IYummoterI3vN7PVoSvXxoeUvlCxd58ytOrHCoFFPYeq0rT64EYPlgbPxLYwzaOAiDNw12yKPVy1OUUtrk/ml7OD5b8Rmen/u89biOv3d0epP1w6YfrD2QO88a99qrCYWeVMIwmneheo2qlK6CqPgoLD++XPcir60c4io9Q7ti5rm0cy5HtLLzsq0TL70Juk8nncaF9AuQUuL1+a/jx80/ov+6/vh05acYunmow/56wduus7sM05O0N6ba70VbJrTRL84X2jGqTdymZhs83fhp1CpXC4M3Dsa+8/vw5qI30XJsS5veUKPJnO8vfR/3T7sf+8/vt+kBNKqepGgDdJW3rfK4AdsPehUkqKoWgG16iScrOao0J0/ywBuMaoAX/nrBmhJnJtVTPHv/bAAFRQL0Rupy8nNsfmbO2B+vvSlaf3q9tQzsjjjL/ypYc2cC7cIjC7Etbpt1xELPK/++Yv0bLh5cHBVCK+i2CwCmRE8B4Py6+vqC161fa68NX95lmYuj3j8PTHvA4Vh3qpf8uvNXSEj8tNVx5Kt8aHlEvxGNdT0cr2n5Mh+LjiwyLPG4+OhilBlUBh1/74hv135rrcijdzOtLU3YrWk3hzUsnFE/V70J0s4myevx5+RabzHo9gO9MjZvLHwDYYPDsO/8PjSp3ATPNPZ84pOiJn7ZDw2+0OwF9GrVyyE413K32sXdk/WrVpy/fB7/HvrXIWi8fcLthufS1uw+k3LGlMU+PMkPk1I61FeWkNYLpOr5tC+PF5cah8a/NEbP+T0x7+A8zDkwx+XrqAkmn6781CGHb9Y+yxLyrgK1l259CZ0adDIMSrW9Kb5Yrnn6nul4Y+Eb2HB6g24vB+CYdqT383fW6/zD5h8wa/8sm23Oeuu0S6Hr9Yb0v6e/zSqK5y6fw0t/v+S0hrPqrbqvnu3qquVKlMOxxGPWD8c6YXXw7dpv8dD0hxxGSOJS41B8QHHrIjGqJvXqU/rf+5aeW6wLXw3eNBjZedmY9aztzyEmOcba41a2eFmva+8mZyaj3sh6qDy0MvYn7MeEyAn4ZMUnGLxJf40AAPi/v/8PHyz9ABm5ttUYtsVt012VVEBYf2/aa4u2Z1g5mHAQHyz9wGG7UTpcn7Z9MK/rPNxV5y6bm7zI+Eg8NuMx62OjOt/qd5+UmYTqZQtSXIzSsFTevTZVxBXViaH9G9Z2Mqj5Fp7aFLMJdUfURfVh1dFodCPDURH1d+hs4vCOuB0Yt2uc7nOuJifqBc72eceqZ15dN/Wk56Rj4ZGFyMjJwDd3f2Pd/l6b9xzmymhpv693lliqaOkFa9Hx0fh4+ceGZVq1KUN6xu4aa/3a2fXYnc8Z7cJw36771vr1wI0DbfbzZLK3u/JlPvad34cRW0c4XCenRE1B5xmdbeYsaHWbV/A5fSDhgNvzO/585k/dXnsjrj6jFh5ZiKGbHDsE9HhTjcjfGHT7gXZyzMM3WXK4lxxbgpSsFASJIOx7ax/mdp2re6w7i200DLf8Udv3aHeY0gF1R9S1LtFaGPYLhWgtObbEYZs2ZcRV7UxfzdCOjo/GjrgdHpe9OpZ4zKEX41TSKRy/ZAkU1Afp1OipNvtoe8v2n9/vEJjYu5xz2eYGY3LUZJvnn5/3PP7c+6fLNJpR20eh2a/NDG9WtMHtltgtOJt6tlDDbr0W9MLYXWOx6cwmw31cTfjpcksXpzd/nrL/fdlfuL/p8A0eqV8w+TgxIxHT90xH17n6tcunRk1FyHchWHJ0CWqWs/QsqrSimyrchKdnPY1xuwsClX8PW3Izjco+2i8SE5eiX8Kv+rDqNlUv8mQeujbpigNvHbBOnq47wvP69H079HXYpg003F1kZ/OZzRi5baRDYDpr/yxr2UqgIPf0dPJp3Rt5+yDnw6UfouW4lhi5zfHDWRt0a3u9ey3ohRrDamDB4QU2QTNQsHIvAJcTMO2H+KWUkFLiqVlP4ZvVBQGg3o2COxIzEm1GIezT60Q/gVt/vdX+MAcqj/7zVZ/jsRmPISY5BvFp8Th88bA1pVDJl/m6N0F6bp9wO3ov7K2b6uLqBsPZ/AnA0tNov/iRaqv2b/b1Ba/jsRmP4d0l71p7kgFLioX2sT3795a251ib/xwxNgLDtgxD37WOfwcAXJb0++fQP3j0z0dx/+/3W0eBvf2cMprobZ86Yl9pC3BeicfVmgaHLhxC6IBQvPjXi5gQOcGh11jFBUYlYrUTxtvXaW+9YXS11HrH3zvqzoPacHoDBm0YhA2nNyAnLwfvLXkPK0+sdPq5AlhSgj5d+Skiz0Y63U/rQvoFLD66uEiubMyg2w+0k2O6NLFMRFFBqf2KifbUsPjjDQuWGFYfYPZD+PZ3eao0nLPJGJ6W5vHWx20LJkHa/yE46xX3RMTYCLSZ0MamdJM7Vp1c5RA02leXAByHee0/gNxZKEabM2m/SAIAvPjXizbDkUaSMpN0c6LtL+Q5+TmoMbwGqv7o+ubNXmhIKCLPRlpvJpwt4CSlxN5ze/HN6m9sbhpmPzsbsq/Et/d863Z+pHIw4SC6zumKoxcdJzypvHVlyMYh1q9TslLQ8feONnmbqk32vdhKj397AAD6LO9j7fHWTrTS/m39sbegzrirdBD1O1KjUYDrhX+OJx7HU7Oesqkm4u5EavX777eun3XbkYtHsOH0BmtbKpeq7PEiEi/+5Xy42NVNl/08ihHbRhgG/trgRjuX4cjFIzibdhYX0i84vBe16SvuVHzQXoP2J+xH9Llo/HPoHwzYMADxafFYdGQRos65roKip/OfnV32GGtHarRUKoX2ZmPpsaUOKXj274c3Fr5hcxOkarnraVbVktJoNCekMN5a/JZDENdnuSXXWNtLrn4+kyIn2dSUf3vR2047muy/7wajCiqQ6KW06U2WBOAy0MuX+Vh8dLF14nBYiTCvPyu172ftz9ydRZy0NwfazqQRW0cgfGg4jl48ihbVW1jbKKXE7P2zceTiEby/9H2nPb9qrsLTjZ92+jxge/1Tf8tSSpy8dBKnkk7ZpHStPrna4f2flZuFL1d/iS9Xf4lVJ1dhUuQkjNo+SjelxognlUmemf0MHv3zUcNVogOJQbcfaHu57Ic+I+MjETogFK3GeZ7XrHLY1BtLuwiDlt7sYEX1Krmqv6sNmj310t8v4cctBeWltHWlzWD0czDy2crPdHuXtcFRTl6OQ2+/9iK85NgSwwu8lrrA9WrZy3Afdy/uRrmo2nkCaulyRZty4aq3JzM3Ey3HGVdA0aoxvAZu/e1WDNgwAAM3FAybrjm1xiGv3F1tJrTBnANzHCaRAo55hSO2jbBO5gkbHIbVJ1frDm9LSOTm56LtxLZ4d3FBmS8176J78+4OCzRExkfa5OVqL/7qA/X929+3Oea+GyzBvZr8d1vN26zPGc2DUOqPqo/DFw9be9MbhTeyfkC//M/LNsFL7wW9rVU2ouOjrTmg4aXCrYFlw9ENcfeUu21W7vRVSteCwwuQl59ncz5vzq3NBddOwtK+d1SuvbsLhR29eFQ3AP9s5Wf4clXBNWhy1GSbHtPqw6qj84zOTie2mkWln9lPXHQ2GR1wTFvRrg+RlZuFB6c9iEf/fBQLDi8wHHVxx7ToaQ7btCOdcw/M9agykoS0mSg5ZucYp/nW9pwt5KXky3wcSDjgVu1/5cYKN9o8Ts5KxrwD8xzmNrnzXtem5BmlPhnpPKMzyg4qi+D+wSgzqIw1ReTDZR8iMSMRfdf2RdcmXSH7SiR9noSVJ1biubnPoeHohm7fqLtTW187cq1+5nkyDzf+fCPq/1zfISUsOy8bW2O3YuUJyxygtxe/bf1bzsrNsulwUhVxXNlzbg9e/fdV3b9pVXZx2h7L+1ONHv7fX4VbjMoMDLr9zL5uZ3xaPLLysgxntatexvmH51snPKg/XPs3utGS1+788bnKhVIl3EJDQm1e152SRL4uMWQGvQ9Y7aI9xQcUx687bcv2pWalYvELizH5icluVy5Rk2CdLejibpUW7SQ8LbWIi5bq5dQeU2qg5+Wk3r7tbZf7aEd2ft35K9pPbo+95/Z6/WFvP1cB0C+16c78hNTsVOz8bye2xm7F6B0FdczVB+Ps/bM9moyjPnRHPDzCOvENsAylbj6z2fCGQzuvwRXtiMbcA3NtcjPH7R6HAestFTXaTWpnHdW6kH7BodycqgaSkJ6gO+nKG4/PfBzPzX3OGqRULFnR4xrSbWq2sblpKezS14DlmnPz6Jtx31T9kQ11Q6PYl6XTMlpp1ognk5Xz8vMcOgm0KS6K/QjW4E2D8fXqr3XPufKllbi9pmX0cNWJVQj9PhQrTqzA4qOL8fjMx62dB67S4fQUNmf2QvoFl9c3pwsWOXl9balCFYQtPLIQwf2D0WRMEzz8h3vleQHLe9Les3OedejEUCPXzt7z2jKbdcs7poo5q1By6MIhpGWnWW+g7VOI7F9Xm6Kit3iWluo80F6vz18+b40XtFWa9KpduYor2k5siwemPYCUrBSb73HwpsHWylMd6nZwORdK6bO8DyZHTbbW494Rt8P681FFDJYeW2pzzXNnNMHfGHSbZNiDwzC281iHihZqpre7tDO3G//iuOyzlruBnxKXEoeI3yxDSNqhuf3n9zuUmvv+vu8BWP7ItUOXnr5mUaX3QeDqe5t/ZD46NeiEHhE90LRKU7de5+V/XgYAmwWG7DlboUxr85nNDtuy8rKc5rF5muJhz50h6VvCb3FIfXlu7nOGIy6u8u708jL1FkBxZ/hx9v7ZDt+D6o0BLEGBXm6lO/6vWUGvSk5+Du6cdKe1V2hK1BTcM+Ue66If2p5zV1z1pqlgX/v6gGWkYvqe6dbqDtqUEl8F3QAw7+A869dSSmsg4M57bVDHQXij1Rs2FRS01x5v6ww/NN0SKG86swnzD8/HR8uMV8jLl/nov76/V69jz+hGWM/ec3sR8l0Imv/W3Ga7Xlk5vYo632/4Xve80/ZMw7rT6xCTHOM0LWj32d3Izsv2Ou/Vnd+N/bkrD61ss1CU3qJv3rZn6bGl1hQMvfKuRp1SeowC4b5r++KBaQ9YJz1GVLV8ftr3jGtp/y711ibw5EYmLiXOZsGgGmVrICY5BgM3DMS3a7+1fna0rdXWeuNlRE3uVr33cw/MRdUfqyKofxBWnVjl9DNK2+48mee0QyU1K9VaflMpzPoJufm5GLRhENpMaIPGvzRG2UFlbUb/3C0OESgMuk3ycvOX0atVL4demzMpZzw6jxqmBgrqkao/LJUTqRbg0OZ9uyMzN9NheC4+LR5Nx1Xn2gAAIABJREFUf22KGsNtV1QM6h+k2wOYlZtlM9P7avX1Gv1eI2e0F1D7XvDCcDcdY8zOMbrb9fIVc/Nz8e+hf21q0HqqcXhjtz5os/KydGvD640mRMVHoeT3rns2v1//PYZttgxDbzmzxWHpdABuTU4DHBfe0eYVuvP3+UKzF6xf7/xvJ37a8hPeXPgmdsfvNlyJdNXJVVh3eh3eXvw2cvNzDXN69XqPjPZV3lr8FkIHhNpM9NSjaqb7WtMqTa1pNvY3VicuncBXq74yPPZs6lkM3jQYv+z4xbrtyVkF1SucrUjoridmPoHhW4cbPu9q1EH1XNuXMtQLsD0J7LR591qeTNjTe79MjZ6KLnO64NZfb9VdtVZ5e/HbKD2wNCr9UAmDNgzC3ANz8eBN7tXSBoBl/2eZLOosNbHvGscb5omRE61fa9N6FO2iSlrFvyvu9D38zZpvUGaQpZNLr2RdalYq/uvjXlUrNcdDz8oTKzE5ajJSs1LRMLwhXol4xWld6tE7RiPitwhM3zNdN5D1ZNXJgRsHInxouLW29W01bsP0PdPx1eqv0G9dP5sJjOGlwj1aKVK7dPv90+63eb+/GuH4O9G+9x6faRx7hASFGHYcGJVndebWqrc6vU4X9UV1HGdikc85u4hWK1PNackcvTtjRW8inrtSslJsegvVkrrOZuwvObYEzzV5zqbagjdDlFcLV2kGD970IMJ/CHda2SUQ9CaBArbBjL1TSacQmxLrEDSWLlbaOnG3bvm6LhcIAmAdOrQ3avsoh20fL//Y+qEz5pExuvnbQMFNUbdm3fDGojd090nOSnZrCXBniz25Q1sPeH/CfutEMXe4GsUwGqYODQk1nHjoqhKJ+nAsbI12I82rNsec/QVDxKoHLDM302Zyn56ftzv/gExIT8ANI2+wqU6ivf74gqsgNyUrBZm5mTZ51mWKl/EowPbkdT2Z/NVhSgesf0X/5+FOacnc/FwkZSa5Nc9G1cUGgO/u/c464vlM42cwKUp/fol2Lk9hedIjvPiYY4WNixkXPZ5AbCQ7LxvlBlvSPIc/OBxhJcKwLc645F/0uWi89PdLhs+vOrEKNcrWcLvU7e01b8e22G2G1Zi2xG7ByaSTGNxxsLW0ImBZCyD6XDTCS4Vbc+dVdZUnGz5p8/eo/WyvULICapWrhdiUWJuOQMXZaFzZEmUdysF6o3qZ6tZ5Os7+ZvXWGyhK2NNtkt+jf8e4XeNcTlZrHO48ZcQXtJNqlLDBYXh2zrMO251d2G4of4PTEkbXGle5ZgKiyAXcAPB80+c9PmbMjjFoP7m9Q5D09d0FIwBLjy11qNPb5ZYu2Pm664lTRjnsqlLBw/Ufxp117nR5nprDaxpOlC0ZUhItxrZwenywCEaDSg0g+0rIvt7lp2p76jzl7EO/b4e+uvnMN1W4yZrq9NNDnqWF1AmrY1MdwgxCCJsePFeVOzx1KumUTclLX//NuepNf7LRkw7D4a4mnrvDF+XMNsRsKNTESE+0mVCQ5/zNmm/w0xbLe9H+Zk5bdUcvQNPSVp1xxd3PnszcTGyP2677nFGHhKe0FcH6LO9jXTTMW/dPux9D7tfvrNCz+uRqfNXeeAQJAN5d8q5NwA0A1YZVw0PTH0Krca2s5TqDg4Kx5uQahxFArej4aGs9dJVSo+2hdzahNUgE2eSNe0v9veTLfMw7MM/F3kUXg26TfLT8I/Re2Btp2WkOi6BodW2if6eqaCdY2k8eU3lnaja//WQglcupJpU4o/JhPRmOutZph7z1LD9RNCeIqpXhPGE0xGk/B8E+lWjx0cVoPV5/cQV3qABNQDjktnrKnVEXvdEhT4bUC+vO2nfincXv6D63PW47bht/m8P2PJln7SH3ZKU3oHC5k+6atW+WTdqROyUvPWU/8dGXXK3sKSCw/7xtnrUni28Z8VU5s/aTHSca+0Of5X0wKXKSQ4/6oI6DrF9rS2X6i7N0taa/ujf3xhX7+QqezNEwcjDBeHK9vSXHlhiO+HnqQMIB3Pf7fTZVZOxpRzJUcO5uWqmnE6uNqFSpbbHbinzetjNML/EDZ5MsVE1gI9rcpSUvWkozlSpWCuk56Q5/+PbDrmc+dD9/XN1FqvSBumF1He5et8dtD0gZLXc1rNTQJ3fU7tJOcvWlJpWb6E6mMsOhC4fQsFJD3UVKAEu5PGdcrezmLr0FlsySm5+Lfw79g2ARjDyZ59fqOh8u+9DwOaOfgTaN4bv133n0emtPr/Vof2/k5Oe4XZ6sKCoeXNxpXu3fh/52qN7gbETQVcqgr7m7vLoZes7v6bBNu/aEs6ownijMXBQzmLHyof0Klb7k7D1uXwbRlSGbhuCViFfwyYpP3Np/xt4ZrnfygH3Neme0JXKLCgbdfqAtZaRyp5WkzCT8/PDPqFy6Mk4lnUKV0lUMJ6tdSL/gcLz981obTm9Aek467qpzF0oXdy+PtUbZGoh+IxrFgorhljG2i79MiZ7ikzt6s/gz4DaTP0cbXFXEuRZ1/6e7z1MgfClIBBmmHujlxTvjq6DHlU4NOmFC5AS/vJaveTKRzR3+DLiLIm3+rrPSqEYGdRzksPiR0SqjgeJpoBpovn6Pa8sguuJsUqo3tHNqXPHVegS+xPQSk729+G3c8ktB8Go/Uz7qXBTevf1dRFSLwA0jb0DD0Q1tnlcrUgJAlzmWmqCqvJ39H5L93fdrC17Dw388bM3FcoeUEpcyLnk0OYx8y9mEHCq8ohxwA77J9fU3Z0PTdG1Q6YpmczX6WxR4ugDbteZMsmdV2HzJk+o+3tz0mY1Bt8nmHJhj84vvUK+DzfPHEo/h9+jfrcPO9gFy5dIF+dj26Qz2Oaz2dYrVgh8qF2pS5CQ8MO0Bw8UJdp/djXaT2uGeqffYLMChFOVebiIKHL2a8XRt8aTzpjDurnu3X17HU8EiGP3v6Y/fHv3tmlmfwluDNw0O2Gt7kvteFLkddAshOgohOrjek5yxv4uPjo9G93+66wa5RtTM+ZrDa2LDaecF7IGCWqg95/fEyhMrMXan/gSIthPbGq6MSUREZLa7pxTNoDtP5uF/a/+H9nXbo/89vllMiTxnVMf9auFJT/dgANb1cIUQtwghNgshtgkhjAtQ6hBCTBJCnBdC7NNsqyiEWCGEOHrlf8c6d5b9ul/Z56gQorsnr1sUTNszzeaxqwkZRy8edfp8r4W9bB4P2jAIj/75qE1wb/8aRnV9fZ33RURERd/X7T1fHOx61WpcK5vJokSe8CTovhmAdqm84QCqAtgFYLwQorMH55oC4GG7bZ8DWCWlbABg1ZXHNoQQFQH0BXA7gDYA+hoF54GW8EkCZF/psFKVKu9npHUN2/Jr2nqgirZE06UM2xXgvlz9JRYfXYzVJ1c7fZ31PRwXVIioFuH0GCIiuvZsjSu6VamKmszcTMw7ePXWiabA8iTozgeQDgBCiKoA7gfQW0r5FoCBAL5wcqwNKeV6AIl2m58AMPXK11MB6C2f9xCAFVLKRCnlJQAr4Bi8X7UmPDbBocfBPr9twm7bCgF1y9fVPZd2QZwHpj2ATTEFS4NXKqW/ZK07q/kREdG1ZeWJwi3uQkTu8aRk4D4AdwFYC+B5AEmw9EgDwHoAhS13UVVKefbK1/Gw9KLbqwlAO2029sq2IqtF9RZuX9DKlSiHsFDnK53ZL3yiFsgBLCtGBgcF41jiMYcV0+6afJfNCnzPzX3OrTYRERERUeF5EnR/D+BvIURzWHqcp8iCFREqwdIT7hNSSimEKFT1eSFELwC9AKBOnTo+aZcn7v/9flzKvORR73HXuV3RsnpL7Oq1y7rNfgU9bX3MMsXLoGyJstbHZ9POul3WyX6lQSIiIiIyj9vpJVLKpQA6AbgEYDKArzRP3wPgSCHbck4IUR0Arvx/XmefOAC1NY9rXdmm195xUsrWUsrWlSu7Xgbd1/ac24PdZ3d7XHPXvnrIgsPGOeAjHx6JNjXaWB9n5mbiWOIxAJa870/bfWp97vWWr+Nc2jnEJMcYTqQkIiIiInN4VKdbSrlWStlLSvm+lDJV81QxALOMjnPTfACqGkl3AP/q7LMMwINCiApXJlA+eGXbNWn2/tn4bddvDtvVikw95/fE0uMFpQaDRMGv80L6BQx5YAjurH0nAEsaSrVh1VB3RF3DkoFEREREZA6300uEEB0B5Eop19k/J6V8w5MXFULMgKV3PFwIEQtLRZLBAGYLIXoCOA2g65V9WwN4Q0r5mpQyUQjxHQBVr6e/lNJ+QmaR1rZWW7f3HbNjjO52+0VxlNCQUOvCNzXL1sR7S97DpjOWCZQ7z+607me0OA4RERERmcOTnO7BsFQLWQdY6nQDmAAgGMBoKeU0J8fakFJ2M3iqo86+OwG8pnk8CcAk95tdtHRt0tXtfd1Z5W1rbEGpJ20wXapYKYzaPsr6+FTSKevXrmqDExEREZFvBapO93WrTpj/J3UCQHxafEBel4iIiIgCVKf7enbowqFCHW9ftzu8VLjuftqebXt/HfyrUG0gIiIiIs94EnSrOt2Afp3uJj5s11XvpVtf0t0+Y+8Mp8fdWOFGAJZUESGEw/P2OeGVS+lXZnHWs73r7C7D54iIiIjI9zwJur8H8JUQYg6A7wD8aVad7mvBsIeGIfFTxzme+xL2OT0uNCQUop9A6YGlkZ2X7fD8d/d+Z/P4dPJp3fMEBwV70FoiIiIiMlNh6nRr1yu/B4Wv033NqVCyAtrUbON6xyuOv3ccPVv0dLpP8QHFbR4/2ehJ3f3qV6zv9usSERERkbk8qV4CKeVaWJaBt+eLOt3XlOj4aOTm5+Jc2jmb7WtPrcXl7Mu6xzT+pTFy8nI8eh378ysZOfplBYmIiIjI/zwKuoUQYbD0dtcEEA9go5TytKd1uq8HD0x7AAnpCQ7bEzMSUWZQGd1j7NNJerXshXG7xzl9ndtr3m6zNLxy95S7dfYmIiIiokDwZHGcWwEsB1AZQAqAMABSCLEEQC8p5X/mNPH6lZaT5nKfgRsH+qElRET/3959x0dR538cf3+S0Ak9dAhVeo8UKYp0UFHPQpMiRcECIiqKgp7lLD88z4KIcnqop1iRQ4r1FDxRQZGuAgcoopwovYZ8f3/sZtlNdkMCTHYTXs/HYx/Z/c7szHe/mZ19z8x3ZgAApyInJ1I+IekbSUnOudKSiku6SL4Q/oWZVfKgfnnW6bgBzT9X/fM01AQAAADRlpPQ3VLS1PTbrjvnDjjn3pV0jqTv5LtjJfwOpR6KdhUAAAAQI3ISun+X79KAIZxzxyQ9Jl9fbwAAAAAZ5CR0z5Y0xcxKhxlmyuFJmfldQhzNAQAAAJ+chO4pkvZKWm1mt5vZ2WZWzczOle9mOYs9qSEAAMAZZkzKmNM2rWYVmp22aeHk5eTmOAclnSvpZUm3SloqabOkjyUdk3S9B/XLs96/6v1oVwEA4KHEgonZHvfToZ96WJOc6V23d67Ps2apmrk+z9OlWIFiuT7Pddet0587//m0TW/5qOWnbVqxqkn5JtGuwgnlZE+3nHOHnHO3SiovqY2kPpKaSEpxzv3oQf3yrBYVW0S7CoBnPhz8oWZeNDPa1TglA5sMjNq8R6eMDlseZ6Gr5GcvfFaFEwqftvlGe73UuHzjiMNmXTwrF2ty3M/jj1/tNmP7Z6Vf4366vnX29zV1TO4YeL7xxo0hwzbeuFF/3PZHYLn4dOinJ2yPZy98Vn3q9snWvINDY4G4Arqk/iXZrXYmSUWTVKFYBS0dvlQ7JuzQfZ3vy9b7No3dpL/2+OtJzzfd9Wdfr1237Yo4fHKnyTma3j8vzfoqYfEWr8d7PZ6pvHyx8mHHv6vTXdma7+uXvx62PG1ymtwUp/rl6p+Wq6Cli4+L18uXvpypfOHAhdl6/6luNL7Q94XA8/cGvXdK04rkqqZX6ZU/vRJ4fc9593gyn1ORo9Cdzjl31Dm3zDm30Dm3RlJ1M7vgNNctTzOzaFcBMST4x7FlpZZRrMnJybjCbVWpla5ucbUe6/HYKU+7ZKGSpzwNSepVJ2fncg9uNliXN7z8tMw72Il+9A/ccUDT+kzTvZ3vDSmf3me60lxaSNnZlc/WE72eOG11+2rkV6dtWtm1/ebtGt5iuJ7o9YQ+u/qziOP1rd9X9cvVz/Z0p3afqjJFypxy/SolVlLqXan68aYfVbxg+BuXDWgyIFPZS5e8pOtbX6+lw5eecB7/HftfSZKb4uSmONUqXUtFEopIki6pf4lqla6lUoVLaVqfaTo2+Zg6JndUp+TQG5zVKFVDD3V9KPB6RMsRmjdgnhomNTzh/IN/j47cdUT7jmS+B0RK5RRJ0siWI7Oc1vabt+uXCb+oTdU2SiqWpH6N+2UaZ8U1KzSv/7xM38mrml51wrrWLFVTt7W/LeLwv/b8q0oWLqkapWpkGvbJ0E80rMWwiO/9fPjnWjBwQUib9W/SP8v6VC9ZXbVK15IUutH48qUva/Xo1ZlC9ri249SqUqvA6+l9puv2Drfrp5t+CpQ1Kd9ElzW8LOz8gv9X5YqW04uXvKguNbtErF/RAkXDlqdNTstUNqDJAG26cZOKJBRRQlyC1l+3Xj3q9AgZZ9GgRVo8bLEGNR0UUr5j/46IdehSs4v23xH+Ttvprmh0hVZeu1KzLp6lbrW7qXThcKcHHpd6V6r23b4vZFl49U+vhoyT8QjE9zu/D1keM36HYsFJhe4wmkt65zRNK1+4edHN0a4CYsi8AfN0U9ubJElfb/86x+/vlNxJ9crWk6TAj/WJDtc2SmqU4/mEs3jYYnVM7qht47cFytLDYbGCmQ+7jk4ZrXXXrVPTCk1POO0uNbto18RdWjBwQbbrMyZljHrW6ZmpfP7A+XJTsr9nqFWlVqqSWCVT+ZZxW1ShWAVJvpC64poVkqR6ZeupQbkGIeOG22M4+dzJqlqiasT5Fing+//d2enOwPzrla2nUa1GafPYzSHjFi1QVCNajtBvt/wWcXojWoyIOCzY4z0fV3xcfOB1p+RO2T5sHimMZkfF4hX13EXP6frW12e51z6xYKIWD8veqUF1y9TV+HbjtfPWnVo9erU+GfpJyPDs7n1NFx8Xr6olqmrP4T2BskWDFmnJsCVaOnypnu/7fNj3VE6srDZV22hsm7ERpz3nyjlhA+LOW3dq/XXr9daVb4WUp+9tTy6VrJ/H/6y9t+/VnCvn6OtRXweWy2BrxqzJVFa6cOmQLo4X1bsoZPj3O78Ped2kfBMtGbZEG27YoGcueCbiZ0mpnBKyDEnS0bSjIa+3jtuqZhWbqc9ZfdS6SuuQYemBsnTh0vrtlt90//n3Z5rHf3f9Vw92DX8F4rZV2wYuUhBuI7tTcifVKFVDN7S+IeL7e9bpGZhv33p9Jfn29qZ/Fy9veLl+Hv+zVo1epb71+vrWK863Xilb5PgF3CoWr6hG5Rvpz53/rKN3HdXTfZ7Wo90fVdECRXVNq2sk+b6b16Rcowe6PKAqJaoEdlKkb0inb4SlTU7T7om7tfPWnZnqPKjpIH0w+IPA6w03bNDE9hMDryPtMTezwPyC+4bXLF1T++/Yr6N3HVW9cvUyva977e7qUL2DXrzkRb074N1Aebmi5TKNm1I5Ral3peqDwR+oUHyhsPUIrk+TCk10VTPfhtfvt/2uT4d+qlqla2nhwIU6NOn4ZZb7Ne6n+Lh4FStYTC+v8u2dr1aimtpXb6/kksmB8fYf9QX9h7s+rPrl6mvyuaE7PNL/b7HkdIVuZPCPb/8R7SqcEcL9GOZU8IrFS6asj350rtE55PWUc6cEns8fMF/rr1+vY5OP6ZtrvlG/xv1OGFRXj1kdCOhZCRdg07Wr2k4dqneQJFVOrKzFwxZrXv95Kl3Et5fi4NGDkkJXyNP6TFP9cvW14poVJ+xHWKdMHUnSucnn6pxq5+ihrg/pjg53aMmwJZkOhS4dvlTLRi7TU32eUsuKkY8WTOo4Kct5pitZuKSmnDclU3mJQiX06/5fJUkbft+gxuUba9dtu/TVyK+0cFDoodiapWpqzpVztHzUci0etlj/HvJvxcfFa8u4LdnqLrFtr29DZlSrUTIzVS9ZPTBs/XXrVbdsXUlS2aJlw25EbR23VdekXJPlPIY1H6axbcZqcLPBkqSPh3ysS+pfog+u+kBfjvwy0/hda3VVu6rt1Lxic0nSg10e1BcjvtDwFsO1bfy2kBOyzq95vi5tcKnuP/9+9ajdQxtu2KB5/eepSmIVzb5stg7feThk2gXiCmjHhB3aMSHzXjMzy/TD/uyFz4bszR7W3LcXMzhkNyrfSB2rd9SAJgNUp0wdPdLtEU3qNEl/3PZH4DB2QlyCPhz8oaTM37NIutfurvbV26tN1TYqGF9Qv93ym2ZfNjvsuD1qH99b+NXIr/Sfq/8TeB2pG0KRAkXChp5glRIrqXjB4upbv69KFykddq+yJO2YsENrxqzRU72fkiT9ceiPkP7msy6epY8Gf6QNN2yQJPVvHLp3d/K5k1UooZBql6ktMwssKz1q95Cb4rRq9Cp9e+23+nJE5uWlfrn6erCLLyTXLVNX1UpWCwy7qe1N6pTcKdC1ILFgohYNWqQ3r3hTZYuW1R0d74j42R/u+rCuaHRF4P/VMKmh5vabGxievhMinEkdJ6le2Xp6steTgfVo+p58SepWq5s23bgpsIHRo06PwAbC62tfV6XESmpcvrHm9Juj+uXqBzYsfj/4e2CDOvgIXUJcgq5NuVY3tbspZMMyY/eQsW3H6uhdR3VujXNDys1MJQqVyPLIzf479mv3xN2qXaa2xrcbL0m64KwLwv6upNexYHxBScp0BC27R+J71+2tLeO2aNXoVaqcWDlQnlQ0SZL0WI/HAhth8XHxmTYago9sHEs7lmn6HZM7auONG9WjTg8VSjge2oN3bsy4YIYSCyZq+gXTVbVEVa27bp2SSybrgfMf0PQ+03VXp7t0S/tbtO66dSHLniQ1SArdSRILuK6dRzIu5PDG+TXPD3k9osUIPffNc9l+//i249W7bm/dc949mvLvzAEsKzsm7FD5/wv9Qd06bqu27N6iEXNH6Lud34UMC15phVO7dG19vPnjwOtqJY6vQIoVLKZdh3bpgcUPqGShkiH91tJNOXeK7vkktA/by5e+rPsW35fl3vWXLnlJQ98ZqrX/W6tNf2wKGfbxkI9DXqcH8HSjzx6tKiWqqGP1jtp1aFfIoU4zC+lKc1/n+3Tvp/fq8LHjQSz9hK4iBYpk6nrQXu3VtVZX3fzezRrfdrxaVDreH3lih4n6cc+PenHli5k+z72d79WYs8fozbVv6saFN2YaPqjpIE3vM10JcQkqVbhUoHz2ZbOVVDQppGzngZ2Kj4tXycK+H9gjx46ETCvNpalv/b6Z5hFncRrQZICWb1+ubrW6ad+Rfer3ZvjAJB2/mZaZ6YcbfpB0fIMk3eoxq3Xw6EH9tOcnnfXkWZKkaiWrhex53HnrTv3ru39p6DtDdUPrGzS2zVjVKl0r5Ef2vBrn6bwa50nyLZMzL5qpb3/5Vo9/+bgqFq8YCKpjF47Vil9WqHBCYTVMaqjnLnou0H7fvv+tnrngGY1qNSow3fQAVbtMbf00/vih9GBmpqRiSSFlg5oO0tTuUwOv65Spow2/b1C9svU0ouUItazUUq1m+A7X/73v3/XMBc+oQHyBTNPNuJFWqnApdavdTZ8P/1x1ytTRyl9XBoZtunGTZq+ZrREts3eUQPJt+FzR6Ao1KNcg04977TK1A3VPD3dP9X5Ka/+3Vm2rts32PE6kUEIhHb7zcKa+50nFkpRULEkNkxqqSmIVlS9WXm2qttG8/vPUIKmB4uPi1bnm8Y2NjskdtWXcFtV9oq6OHDuizbs2h0zvhb4vqEpilcAGVlZ98SWpW+1umvjhRP3w+w8h5SULlwzZQCoQX0Dda3cPGad5xeZa8cuKTNO8pf0tvmk86PvujWszLtOyI/nWIfN/mB+yF7pC8Qpaf/16SdLRY0fVvGJznZt8POgWK1hMNQuGHil8qOtDWvbzMt193t2Z5tEpuZMGNxusyxpcpjHzT3xFkU7JnfTchc+F3ag62csJB69bk4ol6dCkQyoYX1CHUg+pcmJl/bz3+LkJ6d2Z0peTU8kjwTsCxrcdr1qla2lo86HavGuzGpUP3REQvNFQq3QtzbpkVmAdHRyqTyR4g6ZX3V7aPXF3YB1WpEARbR63Ocv3/37r7/rj0B+qWLxitueZWyyr3e9m9ouklZJWBT3WOOcOZRivr6S3nHPxmacSfSkpKW7ZsmW5Os9SD5bS7sO7c3We+U1CXIJS01IjDj9611ElxCXoitev0OtrfYfY3BQn55xeWvmSBs8ZfMJ5pHdHOJR6SA9/9rAeWPxAIBT2rttbySWT9fSyp8O+9+Ckgypy//E9yX3r9dWcfnMkSb/u+1XD5w7Xuz+8qxf6vqAhzYfoUOoh3fLeLfpTwz+p8z8y722rVLyS/tLlLxr6zlB1r91dw1sM15VvXBmo52dbP1OH5zuE1NvuOR6mJnWcpPsXHz9cG9zVYvGWxZrw/gTd1/k+3b/4fj3Y9UG1m9lOd3a8U/ee7+tbvHX3VjV9uqkmnDNBHat3VNmiZU/4Y5sdS39aqv/8+B/d1PYmOTnF/9m3mrj73LvD7mnO6bTbzWynx3o8prFtQw/xH0s7pnd/eFftq7XXPZ/co+olq6te2XrqVrtbyN6oJVuXaMuuLRrY9PiJlTOWz9DsNbP1r/7/CvmxO3j0oB7/4nFN/PD44d3sdGnZf2S/Gk5rqD51+2han2mB8kUbFumV1a9oWp9pEftmhvPq6ldVvWR1nVPtnLDDdx7YqbJFM93LLEu/7vtVpQqXCvw43jD/Bj351ZP6W8+/6cY2oRsvJzP9jL746Qu9vf5t3XPePSE/yPO+n6cFPyxQn7P6BDbK3tv4nuqUqRPoW3smSX+lAAAajUlEQVQyjhw7ol2HdqlAXIHAkZqMWjzTIhAAc9JVae/hvVqwYYGKFywelSuDnKxPNn+i51c8r7/1/Ftgw/Jk/OfH/6j939tLylm7Sb5QvGTrEr2x9g1NWzYt0zTS13GjU0aHfHeOpR1Talqq4ixOP+75UeWLlT+lblDZteKXFTp67KiaVmiaoyDpJeecrpt/nZ5e9rQ6Vu+oT4f5zsHp+VJPLdq4yDdOFv+XNs+10ZfbvjzheNmx88BOvfPdOxrQZIAKJxTWgaMHdCztmBILnfhKP0PmDNEba9/Q2jFrlVwq+YTjxyozW+6cSwk77ASh+3FJjeW7QklZSU5SmqRNCg3i1SQ9Sug+jtB96qqVqKakYkkR99KmrxwmfzxZ9356b0iZJDV4qoHW/7Y+y3lkXMEcSj2k19a8pgUbFmjmRTPV+R+dAyujdF+N/EoNkxqqSEIR9Xiph4oVLKanej91wj3ZwYLDcs86PbVww0Ld3O5mPdLtEa3asUr1ytZTfFy8hr0zTN1rdddVza4KG7ofWPyA5n43VyNbjlS32t2U/NjxFdXJrDydc56fBJz+2V+85MVMJ+ucjGNpxzL1M/Xa6h2rNfjtwXq428PqWqtrtt6TG217Oo361yg9+/WzYUN3fvX9zu81fO5w3df5vkxdABCZc04TP5ioFpVaROwCcyLrf1uvBk/5ugMEr7vi/xyvNJem5/s+r6HNh56O6uZLf1v6N41bNE43tL4hcLWV9LLza54f6F4VzvPfPK+r516tIc2G6IWLX8ilGudfJx26M0ykonzhO/jRUFL6LiNH6D6O0J19D5z/gO74yHdoeuZFM3V25bO169AuNSrfSKlpqarwf5lPHpKOr5g/3PShur7YVSULldSuiccvJfXLvl+07OdlalOljRILJeqFFS+odZXWmvn1TE1bNk2FEwrr4KSDWdZtyJwhmvWtr2/uW1e8peYVm6tm6VO/3mzlqZW1fd92SdLN7W7W1M+n6uGuDwcOqYYTLnRn9MDiBzTpo0mqWaqmNo3dFHacaFu9Y7X+vfnfGnP2mBxdog25a9+RfVqydYm61OySqTsH4IWXV76smqVrhhzB2bp7q5ZsXaJ+jfuxvsjCnsN7tPPATiUWSgycG3Es7ZiWbF2ilMopYU96T/f2urd16WuXamTLkZpx4YzcqnK+dVpCd4QJx0mqI6mppMbOubtPemIeInTHtk03btKBowe0fd/2sHsNyz1cTjsPHj9BY+u4rSpZuKRKFCoRKFu8ZbEaJDUIe4Z1RnsP79XUz6dqQJMBOqvsWVmOm5qWqmlfTdP+I/s1scPE07an8tXVr6r/m/31UNeHtGP/Dk39fKoe6faIJpwzIeJ7tu7eGtiTHSl0b/pjk2o/XjumQzcAIHY457R8+3I1Lt/4tN4X4EzlWejOK6IRujs930mLt2bv8ldnot51e2vj7xs1pNkQ3d7x9izHTXokSb8d8F0y7aPBH4WcEJSX7T28V4mFElXtr9X0056f1L12dy0atCjL93z8349VsXjFiGdlHzh6QEu2LlHhhMIxeY1SAADys6xCN1cv8cgHgz9Qofti4ySLWJSTy/RVSawSCN35JXBLCpxYkn6jivQrWGTlRJ+/aIGima4OAAAAoo8OUh5Jvz4mjku/YUD6NWCz64WLX1DVElX12mWveVGtqPvs6s90dfOrw96iFwAA5A90L/FQ8BUqznSlCpfS9pt9Jw4Wii+Up67iAAAAkB10L4mCSFfcyK+OTT4m55z6vtpX51Q7R7d3uF3rf1uvmxbdpPrl6mtq96m5flk3AACAWEHo9kj67bHzm/6N+2vhhoX649AfgbLb2t/mu5STSfMGzAuUN0hqkOm22QAAAGciQjdypGapmiG3sT1y5xGu4QsAAHACnEiJHPn94O8ht3MlcAMAAJwYodsje4/sjXYVPDF9+fTAVTYal28c5doAAADkDXQvQVhlipTRS5e8pG61uynNpan247X1056fVLpwabWt2lZvX/m2mlVoFu1qAgAA5AmEboS16cZNKlm4ZOD1woELNeH9CfpLl79Iki6uf3G0qgYAAJDnELo90qpSKy3fvjza1cixb675RsUKFAsJ3JLUqHwjLRi4IEq1AgAAyNvo0+2RYc2HRbsK2TawyUB1Su6kz67+TM0rNlfdsnWjXSUAAIB8hT3dHgm+rF4sa5TUSE/0ekKli5SOdlUAAADyrbyRDPOgF1e+GO0qZMvqMaujXQUAAIB8j9Dtkc9+/CzaVcjShWddqPbV2ke7GgAAAGcEQvcZYHCzwZr17azA64vrX6y3r3w7ijUCAAA4s3AipUeKFyye6/Mc2GSgjk0+FlI244IZ6lS9kyTfyZ1uiiNwAwAA5DJCt0cOpR7ydPoVilXQ5Q0vD7zuU7ePXrr0JcVZnDaP3aw3r3hTborTyFYj9cF/P5AkvbTyJU/rBAAAgPDoXuKR1LRUT6f/5hVvqn319pqxfIaumXeNhjYfGhiWXCpZyaWSA68f7f6oCsUX0tg2Yz2tEwAAAMIz51y06+C5lJQUt2zZslydp91jpzyNW8+5VZ2SO6lqiapq/kzzQPk51c7RZ1cfP1HzcOphFUoodMrzAwAAwMkzs+XOuZRww9jTHQN61+2t+T/Mz1T+ULeHMpVtGbdF1UtWDykjcAMAAMQ2+nR75NHuj2Z73IS4BO29fW9I2RO9ngh5/eyFz+rWc27NFLgBAAAQ+9jT7ZGiBYpme9wuNbuoeMHi2n/Hfv3ptT+pV51eur719SHjjGg54nRXEQAAALmE0B1lLSu11Jizx0jyBfUFAxdEuUYAAAA43WKme4mZ1TOzFUGPPWY2LsM455nZ7qBxJkervidy7bvXZmu85aOWKyGObR8AAID8LGbSnnPuO0nNJcnM4iVtkxTuLi6LnXMX5GbdTrf3Br2nWz+4VZfWvzTaVQEAAEAuiJnQnUEXSRudc1uiXZHTbfPYzUoulaxvan8T7aoAAAAgl8RM95IM+kl6JcKwdmb2rZktMLNGuVmpU1ElsYq2jd8WctMaAAAAnBliLnSbWUFJF0l6PczgryUlO+eaSXpC0pwspjPKzJaZ2bL//e9/3lQ2B9668i1VTqwc7WoAAAAgCmIudEvqJelr59yvGQc45/Y45/b5n8+XVMDMyoWbiHNuhnMuxTmXkpSU5G2Ns6F1ldbRrgIAAACiJBZDd39F6FpiZhXNzPzPW8tX/525WDcAAAAgx2LqREozKyapm6RrgsqulSTn3HRJl0kabWapkg5K6uecc9GoKwAAAJBdMRW6nXP7JZXNUDY96PmTkp7M7XqdqsblG0e7CgAAAIiiWOxeku+YLNpVAAAAQBQRunNBmkuLdhUAAAAQRYTuXLDmf2uiXQUAAABEEaEbAAAA8BihOxcMbzE82lUAAABAFBG6cwE3xgEAADizEbpzQZ+6faJdBQAAAEQRoTsXVE6sHO0qAAAAIIoI3bnAf+d6AAAAnKEI3QAAAIDHCN0AAACAxwjdAAAAgMcI3QAAAIDHCN0AAACAxwjdAAAAgMcI3QAAAIDHCN0AAACAxwjdAAAAgMcI3QAAAIDHCN0AAACAxwjdAAAAgMcI3QAAAIDHCN0AAACAxwjdAAAAgMcI3QAAAIDHCN0AAACAxwjdAAAAgMcI3R5rValVtKsAAACAKCN0e+ymtjdFuwoAAACIMkK3R+qWqStJurj+xVGuCQAAAKItIdoVyK/WXbdOh48dVtECRaNdFQAAAEQZodsj8XHxKhpH4AYAAADdSwAAAADPEboBAAAAjxG6AQAAAI8RugEAAACPEboBAAAAjxG6AQAAAI8RugEAAACPEboBAAAAjxG6AQAAAI8RugEAAACPEboBAAAAjxG6AQAAAI8RugEAAACPEboBAAAAjxG6AQAAAI8RugEAAACPxVzoNrPNZrbKzFaY2bIww83MHjezDWa20sxaRqOeAAAAQHYlRLsCEXR2zv0WYVgvSXX9jzaSnvb/BQAAAGJSzO3pzoa+kmY5n6WSSplZpWhXCgAAAIgkFkO3k/SemS03s1FhhleR9GPQ65/8ZQAAAEBMisXuJR2cc9vMrLyk981svXPu05xOxB/YR0lS9erVT3cdAQAAgGyLuT3dzrlt/r87JL0tqXWGUbZJqhb0uqq/LON0ZjjnUpxzKUlJSV5VFwAAADihmArdZlbMzBLTn0vqLml1htHmShrsv4pJW0m7nXPbc7mqAAAAQLbFWveSCpLeNjPJV7d/OucWmtm1kuScmy5pvqTekjZIOiBpWJTqCgAAAGRLTIVu59wmSc3ClE8Peu4kXZeb9QIAAABORUx1LwEAAADyI0I3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOAxQjcAAADgMUI3AAAA4DFCNwAAAOCxmAndZlbNzD42s7VmtsbMxoYZ5zwz221mK/yPydGoKwAAAJATCdGuQJBUSTc75742s0RJy83sfefc2gzjLXbOXRCF+gEAAAAnJWb2dDvntjvnvvY/3ytpnaQq0a0VAAAAcOpiJnQHM7MaklpI+iLM4HZm9q2ZLTCzRrlaMQAAAOAkxFL3EkmSmRWX9Kakcc65PRkGfy0p2Tm3z8x6S5ojqW6E6YySNEqSqlev7mGNAQAAgKzF1J5uMysgX+B+2Tn3Vsbhzrk9zrl9/ufzJRUws3LhpuWcm+GcS3HOpSQlJXlabwAAACArMRO6zcwkzZS0zjn3aIRxKvrHk5m1lq/+O3OvlgAAAEDOxVL3kvaSrpK0ysxW+MvukFRdkpxz0yVdJmm0maVKOiipn3PORaOyAAAAQHbFTOh2zi2RZCcY50lJT+ZOjQAAAIDTI2a6lwAAAAD5FaEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPAYoRsAAADwGKEbAAAA8BihGwAAAPBYTIVuM+tpZt+Z2QYzmxhmeCEzm+0f/oWZ1cj9WgIAAAA5EzOh28ziJT0lqZekhpL6m1nDDKMNl/SHc66OpL9Keih3awkAAADkXMyEbkmtJW1wzm1yzh2R9KqkvhnG6SvpH/7nb0jqYmaWi3UEAAAAciyWQncVST8Gvf7JXxZ2HOdcqqTdksrmSu0AAACAk5QQ7Qp4xcxGSRrlf7nPzL6LQjXKSfotCvPNq2ivnKG9cob2yhnaK2dor5yjzXKG9sqZaLVXcqQBsRS6t0mqFvS6qr8s3Dg/mVmCpJKSdoabmHNuhqQZHtQz28xsmXMuJZp1yEtor5yhvXKG9soZ2itnaK+co81yhvbKmVhsr1jqXvKVpLpmVtPMCkrqJ2luhnHmShrif36ZpI+ccy4X6wgAAADkWMzs6XbOpZrZ9ZIWSYqX9Hfn3Boz+7OkZc65uZJmSnrRzDZI+l2+YA4AAADEtJgJ3ZLknJsvaX6GsslBzw9Jujy363UKotq9JQ+ivXKG9soZ2itnaK+cob1yjjbLGdorZ2KuvYzeGQAAAIC3YqlPNwAAAJAvEbo9cqJb2udXZlbNzD42s7VmtsbMxvrL7zazbWa2wv/oHfSe2/3t9J2Z9QgqD9uG/pNtv/CXz/afeJtnmdlmM1vlb5dl/rIyZva+mf3g/1vaX25m9rj/s680s5ZB0xniH/8HMxsSVN7KP/0N/vfm2RtKmVm9oGVohZntMbNxLF+hzOzvZrbDzFYHlXm+TEWaR6yL0F6PmNl6f5u8bWal/OU1zOxg0LI2Peg9OWqXrNo+lkVoL8+/g2ZWyP96g394jdz5xKcmQnvNDmqrzWa2wl/O8hU5R+T9dZhzjsdpfsh3IuhGSbUkFZT0raSG0a5XLn32SpJa+p8nSvpeUkNJd0uaEGb8hv72KSSppr/d4rNqQ0mvSernfz5d0uhof+5TbLPNksplKHtY0kT/84mSHvI/7y1pgSST1FbSF/7yMpI2+f+W9j8v7R/2pX9c87+3V7Q/82lqt3hJv8h3TVSWr9DP3UlSS0mrc3OZijSPWH9EaK/ukhL8zx8Kaq8aweNlmE6O2iVS28f6I0J7ef4dlDRG0nT/836SZke7LU62vTIMnyppMstX4HNGyhF5fh3Gnm5vZOeW9vmSc267c+5r//O9ktYp851Fg/WV9Kpz7rBz7r+SNsjXfmHb0L81er6kN/zv/4eki735NFHVV77PJoV+xr6SZjmfpZJKmVklST0kve+c+90594ek9yX19A8r4Zxb6nxrkVnKP+3VRdJG59yWLMY5I5cv59yn8l3hKVhuLFOR5hHTwrWXc+4957vzsSQtle/eERGdZLtEavuYFmH5iuR0fgeD2/ENSV3S91DGsqzay1//KyS9ktU0zrDlK1KOyPPrMEK3N7JzS/t8z3/or4WkL/xF1/sP/fw96JBNpLaKVF5W0q6gH8P80LZO0ntmttx8d1KVpArOue3+579IquB/ntP2quJ/nrE8P+in0B8qlq+s5cYyFWkeed3V8u0NS1fTzL4xs0/MrKO/7GTaJb/9Vnj9HQy8xz98t3/8vKyjpF+dcz8ElbF8+WXIEXl+HUbohifMrLikNyWNc87tkfS0pNqSmkvaLt/hNPh0cM61lNRL0nVm1il4oH9LnMsMBfH38bxI0uv+IpavHMiNZSq/LLdmNklSqqSX/UXbJVV3zrWQNF7SP82sRHanl1/aJQy+gyenv0J3HrB8+YXJEQF5dR1G6PZGdm5pn2+ZWQH5vigvO+fekiTn3K/OuWPOuTRJz8p3aFGK3FaRynfKd+goIUN5nuWc2+b/u0PS2/K1za/phwH9f3f4R89pe21T6GHxPN9efr0kfe2c+1Vi+cqm3FimIs0jTzKzoZIukDTQ/wMsfzeJnf7ny+Xrl3yWTq5d8s1vRS59BwPv8Q8v6R8/T/J/hkslzU4vY/nyCZcjlA/WYYRub2Tnlvb5kr9/2kxJ65xzjwaVB/cju0RS+lnccyX1M99Z6TUl1ZXvBIewbej/4ftY0mX+9w+R9I6Xn8lLZlbMzBLTn8t38tZq+dol/Uzr4M84V9Jg/9nabSXt9h8KWySpu5mV9h/W7S5pkX/YHjNr6//fDFYebq8gIXuHWL6yJTeWqUjzyHPMrKekWyVd5Jw7EFSeZGbx/ue15FumNp1ku0Rq+zwnl76Dwe14maSP0jeG8qiuktY75wJdHVi+IucI5Yd1mIuBM1Xz40O+s2m/l28rdVK065OLn7uDfIdjVkpa4X/0lvSipFX+8rmSKgW9Z5K/nb5T0JU1IrWhfGe7fynfCTmvSyoU7c99Cu1VS76z9r+VtCb9c8rXT/FDST9I+kBSGX+5SXrK3yarJKUETetqf5tskDQsqDxFvh/AjZKelP+mWHn1IamYfHu3SgaVsXyFttEr8h2mPipff8XhubFMRZpHrD8itNcG+fqDpq/H0q+a8Sf/d3WFpK8lXXiy7ZJV28fyI0J7ef4dlFTY/3qDf3itaLfFybaXv/wFSddmGJflK3KOyPPrMO5ICQAAAHiM7iUAAACAxwjdAAAAgMcI3QAAAIDHCN0AAACAxwjdAAAAgMcI3QAAAIDHCN0AcIYws6vNbHf63f7M7Cwzu9t/cxIAgIcI3QBw5vhAUnvnXKr/dS9JY5xzR6JYJwA4IyREuwIAgNzhnNuaoaipjt+u+5SYWUHCOwBExp5uADgDmFmcme0zs5H+1zvku0VyZzNz/sf5/mGFzeweM9tgZgfNbJmZdQgzrXFm9riZ/U++WzUDACJgTzcAnBlqSSomaaWZmaSLJH0saaqkef5xVvj7e78rqYGkeyRtkjRC0nwzq+uc+zVoWrdKelvSAEns5QaALBC6AeDM0ERSmqTVzjlnZr9IKixpnnNuafpIZnabpNaSWjnnvveX/VvSVkmXSXrKPy1J+rtz7s7c+wgAkHcRugHgzNBU0ibn3P6g107SqvQRzCxO0s2SZknalH6VE/94GyRVD3rvAUn350K9ASBfoE83AJwZmkhaGfQ6YwhPHydJ0hhJRzM8OkjaEzTev51zB72uNADkF+zpBoAzQxNJrwS9birp2wzjVPL/7Sppd5hpbAma1muntXYAkM8RugEgnzOzIpLqKHRPd31J/8ow6nb/313OueUnmFbGwA4AyAKhGwDyv0bydScMDt17JHUys07yXXnkC0lr5Lv03z/N7H5Jm+XrbtJa0lrn3D+CpkXoBoAcoE83AOR/TSTtl7QxqGyipDKSPpQ0x/mkSrpQ0jJJD0paJOkRSVUkfZ7FtAAAJ2DOuWjXAQAAAMjX2NMNAAAAeIzQDQAAAHiM0A0AAAB4jNANAAAAeIzQDQAAAHiM0A0AAAB4jNANAAAAeIzQDQAAAHiM0A0AAAB47P8BK9ilXX8mD4gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}